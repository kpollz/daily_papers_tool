# ğŸ¤— Daily Hugging Face Paper Digest - 2026-01-08

BÃ¡o cÃ¡o Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng vÃ o lÃºc 2026-01-09 10:16:18 báº±ng mÃ´ hÃ¬nh `gemini-2.5-flash`.

## ğŸ“° Summary of Papers

--- 

## 1. Entropy-Adaptive Fine-Tuning: Resolving Confident Conflicts to Mitigate Forgetting

**TÃ¡c giáº£:** Muxi Diao, Lele Yang, Wuxuan Gong, Yutong Zhang, Zhonghao Yan, Yufei Han, Kongming Liang, Weiran Xu, Zhanyu Ma

**Xuáº¥t báº£n lÃºc:** 2026-01-05

**Tag:** Fine-tuning, Catastrophic Forgetting, LLM, Entropy, Supervised Fine-Tuning (SFT)
### Main Problem:
Supervised Fine-Tuning (SFT) lÃ  phÆ°Æ¡ng phÃ¡p tiÃªu chuáº©n Ä‘á»ƒ Ä‘iá»u chá»‰nh cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) cho cÃ¡c lÄ©nh vá»±c cá»¥ thá»ƒ, nhÆ°ng nÃ³ thÆ°á»ng gÃ¢y ra hiá»‡n tÆ°á»£ng "quÃªn tháº£m khá»‘c" (catastrophic forgetting), lÃ m suy giáº£m cÃ¡c kháº£ nÄƒng tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh. BÃ i bÃ¡o xÃ¡c Ä‘á»‹nh nguyÃªn nhÃ¢n lÃ  do "Xung Ä‘á»™t tá»± tin" (Confident Conflicts) -- cÃ¡c token cÃ³ xÃ¡c suáº¥t tháº¥p nhÆ°ng entropy tháº¥p, nÆ¡i mÃ´ hÃ¬nh ráº¥t tá»± tin vÃ o dá»± Ä‘oÃ¡n cá»§a mÃ¬nh nhÆ°ng bá»‹ buá»™c pháº£i há»c má»™t sá»± tháº­t khÃ¡c, dáº«n Ä‘áº¿n cÃ¡c cáº­p nháº­t gradient phÃ¡ há»§y.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t phÆ°Æ¡ng phÃ¡p Fine-Tuning thÃ­ch á»©ng vá»›i Entropy (Entropy-Adaptive Fine-Tuning - EAFT). KhÃ¡c vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p chá»‰ dá»±a vÃ o xÃ¡c suáº¥t dá»± Ä‘oÃ¡n, EAFT sá»­ dá»¥ng entropy á»Ÿ cáº¥p Ä‘á»™ token nhÆ° má»™t cÆ¡ cháº¿ cá»•ng Ä‘á»ƒ phÃ¢n biá»‡t giá»¯a sá»± khÃ´ng cháº¯c cháº¯n vá» nháº­n thá»©c (epistemic uncertainty) vÃ  xung Ä‘á»™t kiáº¿n thá»©c (knowledge conflict). Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh há»c tá»« cÃ¡c máº«u khÃ´ng cháº¯c cháº¯n trong khi ngÄƒn cháº·n cÃ¡c gradient gÃ¢y xung Ä‘á»™t trÃªn dá»¯ liá»‡u mÃ¢u thuáº«n. Cá»¥ thá»ƒ, EAFT Ä‘iá»u chá»‰nh Ä‘á»™ng máº¥t mÃ¡t huáº¥n luyá»‡n dá»±a trÃªn entropy cáº¥p Ä‘á»™ token, háº¡ tháº¥p trá»ng sá»‘ cÃ¡c token cÃ³ entropy tháº¥p Ä‘á»ƒ giáº£m thiá»ƒu cÃ¡c cáº­p nháº­t phÃ¡ há»§y vÃ  táº­p trung giÃ¡m sÃ¡t vÃ o cÃ¡c token cÃ³ entropy cao Ä‘á»ƒ thÃºc Ä‘áº©y thÃ­ch á»©ng.

### Main Results:
EAFT nháº¥t quÃ¡n Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t nhiá»‡m vá»¥ má»¥c tiÃªu tÆ°Æ¡ng Ä‘Æ°Æ¡ng hoáº·c vÆ°á»£t trá»™i so vá»›i SFT tiÃªu chuáº©n trong khi giáº£m Ä‘Ã¡ng ká»ƒ sá»± suy giáº£m cÃ¡c kháº£ nÄƒng tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh. CÃ¡c thá»­ nghiá»‡m trÃªn cÃ¡c dÃ²ng mÃ´ hÃ¬nh Qwen vÃ  GLM (tá»« 4B Ä‘áº¿n 32B tham sá»‘) trong cÃ¡c lÄ©nh vá»±c toÃ¡n há»c, y táº¿ vÃ  tÃ¡c tá»­ Ä‘Ã£ xÃ¡c nháº­n giáº£ thuyáº¿t. EAFT Ä‘áº¡t Ä‘Æ°á»£c cáº£i thiá»‡n Pareto: khá»›p hoáº·c vÆ°á»£t trá»™i cÃ¡c phÆ°Æ¡ng phÃ¡p cÆ¡ sá»Ÿ trÃªn cÃ¡c nhiá»‡m vá»¥ má»¥c tiÃªu Ä‘á»“ng thá»i giáº£m thiá»ƒu Ä‘Ã¡ng ká»ƒ sá»± quÃªn tháº£m khá»‘c trÃªn cÃ¡c chuáº©n tá»•ng quÃ¡t. PhÆ°Æ¡ng phÃ¡p Ä‘Æ°á»£c chá»©ng minh lÃ  máº¡nh máº½ vá»›i cÃ¡c biáº¿n thá»ƒ siÃªu tham sá»‘ vÃ  hiá»‡u quáº£ vá» máº·t tÃ­nh toÃ¡n.

### Conclusion & Future Works:
EAFT lÃ  má»™t giáº£i phÃ¡p hiá»‡u quáº£ vÃ  phá»• quÃ¡t Ä‘á»ƒ giáº£m thiá»ƒu hiá»‡n tÆ°á»£ng quÃªn tháº£m khá»‘c trong quÃ¡ trÃ¬nh Supervised Fine-Tuning, hoáº¡t Ä‘á»™ng thÃ nh cÃ´ng trÃªn nhiá»u há» mÃ´ hÃ¬nh vÃ  quy mÃ´ khÃ¡c nhau (4Bâ€“32B tham sá»‘). BÃ i bÃ¡o Ä‘Ã£ phÃ¡t hiá»‡n ra khoáº£ng cÃ¡ch phÃ¢n phá»‘i khÃ¡c biá»‡t giá»¯a dá»¯ liá»‡u SFT vÃ  dá»¯ liá»‡u RL on-policy, Ä‘á»“ng thá»i chá»‰ ra "Xung Ä‘á»™t tá»± tin" lÃ  nguyÃªn nhÃ¢n chÃ­nh gÃ¢y ra quÃªn tháº£m khá»‘c.

### Brainstorming Space:
#### 1. Publish Papers:
1.  NghiÃªn cá»©u á»©ng dá»¥ng EAFT Ä‘á»ƒ giáº£i quyáº¿t hiá»‡n tÆ°á»£ng quÃªn tháº£m khá»‘c trong cÃ¡c mÃ´ hÃ¬nh thá»‹ giÃ¡c mÃ¡y tÃ­nh khi fine-tuning cho cÃ¡c miá»n dá»¯ liá»‡u má»›i.
2.  KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p cÆ¡ cháº¿ EAFT vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ©n mÃ´ hÃ¬nh Ä‘á»ƒ táº¡o ra cÃ¡c LLM nhá» gá»n vÃ  hiá»‡u quáº£ hÆ¡n mÃ  váº«n duy trÃ¬ kháº£ nÄƒng tá»•ng quÃ¡t sau fine-tuning.
3.  PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng cá»§a cÃ¡c chiáº¿n lÆ°á»£c táº¡o dá»¯ liá»‡u huáº¥n luyá»‡n hoáº·c pháº£n há»“i (feedback) khÃ¡c nhau lÃªn "Xung Ä‘á»™t tá»± tin" vÃ  hiá»‡u quáº£ cá»§a EAFT.
#### 2. Patent:
1.  Má»™t há»‡ thá»‘ng fine-tuning mÃ´ hÃ¬nh AI cÃ¡ nhÃ¢n trÃªn thiáº¿t bá»‹ di Ä‘á»™ng, sá»­ dá»¥ng cÆ¡ cháº¿ thÃ­ch á»©ng entropy Ä‘á»ƒ cáº­p nháº­t cÃ¡c tÃ­nh nÄƒng trá»£ lÃ½ áº£o riÃªng biá»‡t mÃ  khÃ´ng lÃ m suy giáº£m kháº£ nÄƒng tá»•ng quÃ¡t cá»§a trá»£ lÃ½ Ä‘Ã³.
2.  Má»™t phÆ°Æ¡ng phÃ¡p tá»‘i Æ°u hÃ³a viá»‡c phÃ¢n phá»‘i vÃ  cáº­p nháº­t cÃ¡c mÃ´ hÃ¬nh AI ngÃ´n ngá»¯ trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, trong Ä‘Ã³ cÃ¡c báº£n vÃ¡ lá»—i hoáº·c tÃ­nh nÄƒng má»›i Ä‘Æ°á»£c fine-tune báº±ng EAFT Ä‘á»ƒ trÃ¡nh quÃªn cÃ¡c chá»©c nÄƒng cá»‘t lÃµi.
3.  Má»™t cÃ´ng nghá»‡ cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘iá»‡n thoáº¡i thÃ´ng minh tÃ¹y chá»‰nh giao diá»‡n hoáº·c tÆ°Æ¡ng tÃ¡c cá»§a chatbot báº±ng cÃ¡ch fine-tune má»™t pháº§n mÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»¥c bá»™, vá»›i EAFT Ä‘áº£m báº£o ráº±ng cÃ¡c kiáº¿n thá»©c Ä‘Ã£ cÃ³ khÃ´ng bá»‹ ghi Ä‘Ã¨ má»™t cÃ¡ch phÃ¡ há»§y.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.02151](https://huggingface.co/papers/2601.02151) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.02151](https://arxiv.org/abs/2601.02151) |
| PDF Download | [https://arxiv.org/pdf/2601.02151.pdf](https://arxiv.org/pdf/2601.02151.pdf) |
| Github Repository | [https://github.com/PRIS-CV/EAFT](https://github.com/PRIS-CV/EAFT) |

--- 

## 2. Evolving Programmatic Skill Networks

**TÃ¡c giáº£:** Haochen Shi, Xingdi Yuan, Bang Liu

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** Programmatic Skill Networks, Continual Learning, Embodied AI, Large Language Models

### Main Problem:
CÃ¡c tÃ¡c nhÃ¢n AI trong mÃ´i trÆ°á»ng má»Ÿ pháº£i liÃªn tá»¥c há»c há»i, tinh chá»‰nh vÃ  tÃ¡i sá»­ dá»¥ng cÃ¡c ká»¹ nÄƒng. CÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ gáº·p hai háº¡n cháº¿: (1) cÃ¡c ká»¹ nÄƒng thÆ°á»ng Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng thÆ° viá»‡n pháº³ng hoáº·c Ä‘á»“ thá»‹ tÄ©nh, thiáº¿u cÆ¡ cháº¿ nguyÃªn táº¯c Ä‘á»ƒ cáº£i tiáº¿n liÃªn tá»¥c, vÃ  (2) cÃ¡c tÃ¡c nhÃ¢n thiáº¿u khung thá»‘ng nháº¥t Ä‘á»ƒ phÃ¢n bá»• trÃ¡ch nhiá»‡m trong cÃ¡c cáº¥u trÃºc ká»¹ nÄƒng phÃ¢n cáº¥p, sá»­a chá»¯a chÆ°Æ¡ng trÃ¬nh biá»ƒu tÆ°á»£ng vÃ  tÃ¡i tá»• chá»©c cáº¥u trÃºc khi cÃ¡c tÃ¡c vá»¥ má»›i phÃ¡t sinh.

### Main Idea:
NghiÃªn cá»©u giá»›i thiá»‡u Programmatic Skill Network (PSN), má»™t framework cho phÃ©p cÃ¡c tÃ¡c nhÃ¢n liÃªn tá»¥c há»c há»i cÃ¡c ká»¹ nÄƒng trong mÃ´i trÆ°á»ng má»Ÿ. Trong PSN, má»—i ká»¹ nÄƒng lÃ  má»™t chÆ°Æ¡ng trÃ¬nh biá»ƒu tÆ°á»£ng cÃ³ thá»ƒ thá»±c thi (vÃ­ dá»¥: JavaScript, Python) táº¡o thÃ nh má»™t máº¡ng lÆ°á»›i tá»•ng há»£p phÃ¡t triá»ƒn qua kinh nghiá»‡m. PSN Ä‘á»‹nh nghÄ©a ba cÆ¡ cháº¿ cá»‘t lÃµi Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ´ng qua cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM): (1) REFLECT Ä‘á»ƒ Ä‘á»‹nh vá»‹ lá»—i cÃ³ cáº¥u trÃºc trong cÃ¡c thÃ nh pháº§n ká»¹ nÄƒng, (2) tá»‘i Æ°u hÃ³a lÅ©y tiáº¿n vá»›i cÆ¡ cháº¿ cáº­p nháº­t nháº­n biáº¿t Ä‘á»™ trÆ°á»Ÿng thÃ nh Ä‘á»ƒ á»•n Ä‘á»‹nh cÃ¡c ká»¹ nÄƒng Ä‘Ã¡ng tin cáº­y Ä‘á»“ng thá»i duy trÃ¬ tÃ­nh linh hoáº¡t cho nhá»¯ng ká»¹ nÄƒng chÆ°a cháº¯c cháº¯n, vÃ  (3) tÃ¡i cáº¥u trÃºc cáº¥u trÃºc chuáº©n theo cÆ¡ cháº¿ kiá»ƒm tra quay lui Ä‘á»ƒ duy trÃ¬ tÃ­nh nhá» gá»n cá»§a máº¡ng lÆ°á»›i. PSN duy trÃ¬ má»™t Ä‘á»“ thá»‹ tÃ­nh toÃ¡n rÃµ rÃ ng cá»§a cÃ¡c chÆ°Æ¡ng trÃ¬nh cÃ³ thá»ƒ thá»±c thi, há»— trá»£ phÃ¢n bá»• trÃ¡ch nhiá»‡m dá»±a trÃªn dáº¥u váº¿t, á»•n Ä‘á»‹nh nháº­n biáº¿t Ä‘á»™ trÆ°á»Ÿng thÃ nh vÃ  tÃ¡i cáº¥u trÃºc cáº¥u trÃºc theo nguyÃªn táº¯c.

### Main Results:
CÃ¡c thá»­ nghiá»‡m trÃªn MineDojo vÃ  Crafter cho tháº¥y PSN cÃ³ kháº£ nÄƒng tÃ¡i sá»­ dá»¥ng ká»¹ nÄƒng máº¡nh máº½, thÃ­ch á»©ng nhanh chÃ³ng vÃ  tá»•ng quÃ¡t hÃ³a tá»‘t trÃªn cÃ¡c phÃ¢n phá»‘i tÃ¡c vá»¥ má»Ÿ. Äá»™ng lá»±c há»c há»c táº­p cá»§a PSN cÅ©ng cho tháº¥y sá»± tÆ°Æ¡ng Ä‘á»“ng vá» cáº¥u trÃºc vá»›i quÃ¡ trÃ¬nh huáº¥n luyá»‡n máº¡ng nÆ¡-ron, gá»£i Ã½ ráº±ng cÃ¡c nguyÃªn táº¯c tá»‘i Æ°u hÃ³a máº¡ng nÆ¡-ron cÃ³ thá»ƒ má»Ÿ rá»™ng sang cÃ¡c há»‡ thá»‘ng há»c táº­p láº­p trÃ¬nh.

### Conclusion & Future Works:
Thiáº¿t káº¿ kiáº¿n trÃºc cá»§a PSN táº¡o ra Ä‘á»™ng lá»±c há»c há»c táº­p cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng vá» cáº¥u trÃºc vá»›i quÃ¡ trÃ¬nh huáº¥n luyá»‡n máº¡ng nÆ¡-ron, gá»£i Ã½ cÃ¡c nguyÃªn táº¯c chung cho viá»‡c há»c táº­p liÃªn tá»¥c trÃªn cÃ¡c mÃ´ hÃ¬nh biá»ƒu diá»…n khÃ¡c nhau. NhÃ³m nghiÃªn cá»©u cÃ³ káº¿ hoáº¡ch má»Ÿ mÃ£ nguá»“n cá»§a dá»± Ã¡n nÃ y.

### Brainstorming Space:
#### 1. Publish Papers:
1.  NghiÃªn cá»©u cÃ¡ch PSN cÃ³ thá»ƒ tÃ­ch há»£p vá»›i cÃ¡c há»‡ thá»‘ng há»c tÄƒng cÆ°á»ng sÃ¢u Ä‘á»ƒ xá»­ lÃ½ cÃ¡c quan sÃ¡t thÃ´ vÃ  hÃ nh Ä‘á»™ng cáº¥p tháº¥p má»™t cÃ¡ch hiá»‡u quáº£ hÆ¡n.
2.  KhÃ¡m phÃ¡ viá»‡c tá»± Ä‘á»™ng táº¡o ra hoáº·c há»c cÃ¡c Ä‘iá»u kiá»‡n tiÃªn quyáº¿t vÃ  háº­u Ä‘iá»u kiá»‡n cho ká»¹ nÄƒng thay vÃ¬ pháº£i xÃ¡c Ä‘á»‹nh thá»§ cÃ´ng, giÃºp má»Ÿ rá»™ng kháº£ nÄƒng tá»± chá»§ cá»§a tÃ¡c nhÃ¢n.
3.  Ãp dá»¥ng PSN trong cÃ¡c ká»‹ch báº£n há»£p tÃ¡c Ä‘a tÃ¡c nhÃ¢n, nÆ¡i cÃ¡c tÃ¡c nhÃ¢n cÃ¹ng xÃ¢y dá»±ng vÃ  chia sáº» máº¡ng lÆ°á»›i ká»¹ nÄƒng láº­p trÃ¬nh cá»§a mÃ¬nh.

#### 2. Patent:
1.  Há»‡ thá»‘ng trá»£ lÃ½ AI trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng tá»± Ä‘á»™ng há»c vÃ  tinh chá»‰nh cÃ¡c chuá»—i tÃ¡c vá»¥ phá»©c táº¡p cá»§a ngÆ°á»i dÃ¹ng thÃ´ng qua giao diá»‡n láº­p trÃ¬nh ná»™i bá»™, cáº£i thiá»‡n hiá»‡u quáº£ sá»­ dá»¥ng á»©ng dá»¥ng.
2.  PhÆ°Æ¡ng phÃ¡p tá»‘i Æ°u hÃ³a nÄƒng lÆ°á»£ng cho Ä‘iá»‡n thoáº¡i thÃ´ng minh báº±ng cÃ¡ch sá»­ dá»¥ng máº¡ng lÆ°á»›i ká»¹ nÄƒng láº­p trÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n vÃ  tá»‘i Æ°u hÃ³a cÃ¡c thao tÃ¡c ngÆ°á»i dÃ¹ng láº·p láº¡i, giáº£m táº£i xá»­ lÃ½ khÃ´ng cáº§n thiáº¿t.
3.  CÃ´ng nghá»‡ tÃ­ch há»£p trong Ä‘iá»‡n thoáº¡i di Ä‘á»™ng cho phÃ©p táº¡o vÃ  quáº£n lÃ½ cÃ¡c "macro thÃ´ng minh" Ä‘a á»©ng dá»¥ng, tá»± Ä‘á»™ng sá»­a lá»—i vÃ  tÃ¡i cáº¥u trÃºc cÃ¡c bÆ°á»›c thá»±c hiá»‡n dá»±a trÃªn pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ hoÃ n thÃ nh má»¥c tiÃªu.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03509](https://huggingface.co/papers/2601.03509) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03509](https://arxiv.org/abs/2601.03509) |
| PDF Download | [https://arxiv.org/pdf/2601.03509.pdf](https://arxiv.org/pdf/2601.03509.pdf) |
| Github Repository | N/A |

--- 

## 3. Atlas: Orchestrating Heterogeneous Models and Tools for Multi-Domain Complex Reasoning

**TÃ¡c giáº£:** Jinyang Wu, Guocheng Zhai, Ruihan Jin, Jiahao Yuan, Yuhao Shen, Shuai Zhang, Zhengqi Wen, Jianhua Tao

**Xuáº¥t báº£n lÃºc:** 2026-01-07

Summary generation failed.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03872](https://huggingface.co/papers/2601.03872) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03872](https://arxiv.org/abs/2601.03872) |
| PDF Download | [https://arxiv.org/pdf/2601.03872.pdf](https://arxiv.org/pdf/2601.03872.pdf) |
| Github Repository | N/A |

--- 

## 4. Benchmark^2: Systematic Evaluation of LLM Benchmarks

**TÃ¡c giáº£:** Qi Qian, Chengsong Huang, Jingwen Xu, Changze Lv, Muling Wu, Wenhao Liu, Xiaohua Wang, Zhenghua Wang, Zisu Huang, Muzhao Tian, Jianhan Xu, Kun Hu, He-Da Wang, Yao Hu, Xuanjing Huang, Xiaoqing Zheng

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** LLM Evaluation, Benchmark Quality, Metrics

### Main Problem:
Sá»± gia tÄƒng nhanh chÃ³ng cá»§a cÃ¡c benchmark dÃ¹ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘Ã£ táº¡o ra nhu cáº§u cáº¥p thiáº¿t vá» cÃ¡c phÆ°Æ¡ng phÃ¡p cÃ³ há»‡ thá»‘ng Ä‘á»ƒ tá»± Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cá»§a chÃ­nh cÃ¡c benchmark Ä‘Ã³. CÃ¡c váº¥n Ä‘á» chÃ­nh vá»›i cÃ¡c benchmark hiá»‡n táº¡i bao gá»“m sá»± khÃ´ng nháº¥t quÃ¡n trong viá»‡c xáº¿p háº¡ng cÃ¡c mÃ´ hÃ¬nh, kháº£ nÄƒng phÃ¢n biá»‡t tháº¥p giá»¯a cÃ¡c mÃ´ hÃ¬nh cÃ³ nÄƒng lá»±c khÃ¡c nhau, vÃ  sá»± tá»“n táº¡i cá»§a cÃ¡c trÆ°á»ng há»£p thá»­ nghiá»‡m cÃ³ váº¥n Ä‘á» nÆ¡i cÃ¡c mÃ´ hÃ¬nh máº¡nh hÆ¡n láº¡i tháº¥t báº¡i trong khi cÃ¡c mÃ´ hÃ¬nh yáº¿u hÆ¡n láº¡i thÃ nh cÃ´ng.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t BENCHMARK^2, má»™t khuÃ´n khá»• toÃ n diá»‡n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng benchmark, bao gá»“m ba chá»‰ sá»‘ bá»• sung:
1.  **Cross-Benchmark Ranking Consistency (CBRC):** Äo lÆ°á»ng má»©c Ä‘á»™ phÃ¹ há»£p trong xáº¿p háº¡ng mÃ´ hÃ¬nh cá»§a má»™t benchmark vá»›i cÃ¡c benchmark Ä‘á»“ng cáº¥p trong cÃ¹ng lÄ©nh vá»±c.
2.  **Discriminability Score (DS):** Äá»‹nh lÆ°á»£ng kháº£ nÄƒng cá»§a má»™t benchmark trong viá»‡c phÃ¢n biá»‡t rÃµ rÃ ng giá»¯a cÃ¡c mÃ´ hÃ¬nh cÃ³ nÄƒng lá»±c khÃ¡c nhau.
3.  **Capability Alignment Deviation (CAD):** XÃ¡c Ä‘á»‹nh cÃ¡c trÆ°á»ng há»£p kiá»ƒm thá»­ cÃ³ váº¥n Ä‘á» khi cÃ¡c mÃ´ hÃ¬nh máº¡nh hÆ¡n tháº¥t báº¡i nhÆ°ng cÃ¡c mÃ´ hÃ¬nh yáº¿u hÆ¡n láº¡i thÃ nh cÃ´ng trong cÃ¹ng má»™t há» mÃ´ hÃ¬nh, Ä‘áº£m báº£o tÃ­nh nháº¥t quÃ¡n theo thá»© báº­c nÄƒng lá»±c mong Ä‘á»£i.
CÃ¡c chá»‰ sá»‘ nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cá»§a cÃ¡c benchmark hiá»‡n cÃ³.

### Main Results:
-   CÃ¡c thÃ­ nghiá»‡m sÃ¢u rá»™ng trÃªn 15 benchmark thuá»™c cÃ¡c lÄ©nh vá»±c toÃ¡n há»c, suy luáº­n vÃ  tri thá»©c, Ä‘Ã¡nh giÃ¡ 11 LLM tá»« bá»‘n há» mÃ´ hÃ¬nh, Ä‘Ã£ cho tháº¥y sá»± biáº¿n Ä‘á»•i Ä‘Ã¡ng ká»ƒ vá» cháº¥t lÆ°á»£ng giá»¯a cÃ¡c benchmark hiá»‡n cÃ³.
-   PhÃ¢n tÃ­ch Ä‘Ã£ tiáº¿t lá»™ cÃ¡c Ä‘áº·c Ä‘iá»ƒm cháº¥t lÆ°á»£ng cá»§a benchmark, phÃ¢n biá»‡t rÃµ rÃ ng giá»¯a benchmark cháº¥t lÆ°á»£ng cao vÃ  cÃ¡c benchmark cÃ³ váº¥n Ä‘á».
-   Viá»‡c xÃ¢y dá»±ng benchmark cÃ³ chá»n lá»c, dá»±a trÃªn cÃ¡c chá»‰ sá»‘ cháº¥t lÆ°á»£ng Ä‘Æ°á»£c Ä‘á» xuáº¥t, cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t Ä‘Ã¡nh giÃ¡ tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i cÃ¡c bá»™ dá»¯ liá»‡u thá»­ nghiá»‡m Ä‘áº§y Ä‘á»§ nhÆ°ng vá»›i kÃ­ch thÆ°á»›c giáº£m Ä‘Ã¡ng ká»ƒ (chá»‰ 35% dá»¯ liá»‡u gá»‘c).

### Conclusion & Future Works:
BÃ i bÃ¡o Ä‘Ã£ hÃ¬nh thá»©c hÃ³a váº¥n Ä‘á» Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng benchmark vÃ  Ä‘á» xuáº¥t má»™t bá»™ ba chá»‰ sá»‘ bá»• sung Ä‘á»ƒ náº¯m báº¯t cÃ¡c khÃ­a cáº¡nh khÃ¡c nhau cá»§a Ä‘á»™ tin cáº­y benchmark. ÄÃ¢y lÃ  má»™t Ä‘Ã¡nh giÃ¡ cÃ³ há»‡ thá»‘ng quy mÃ´ lá»›n Ä‘áº§u tiÃªn vá» cháº¥t lÆ°á»£ng benchmark, cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t thá»±c nghiá»‡m quan trá»ng vá» tÃ¬nh tráº¡ng Ä‘Ã¡nh giÃ¡ LLM. Kháº£ nÄƒng á»©ng dá»¥ng thá»±c tiá»…n cá»§a khuÃ´n khá»• nÃ y Ä‘Æ°á»£c chá»©ng minh qua viá»‡c xÃ¢y dá»±ng cÃ¡c benchmark rÃºt gá»n nhÆ°ng váº«n duy trÃ¬ hiá»‡u suáº¥t Ä‘Ã¡nh giÃ¡, cho tháº¥y tiá»m nÄƒng trong viá»‡c tá»‘i Æ°u hÃ³a quy trÃ¬nh Ä‘Ã¡nh giÃ¡ LLM. BÃ i bÃ¡o khÃ´ng trÃ¬nh bÃ y cá»¥ thá»ƒ vá» cÃ¡c hÆ°á»›ng nghiÃªn cá»©u trong tÆ°Æ¡ng lai.

### Brainstorming Space:
#### 1. Publish Papers:
-   NghiÃªn cá»©u sá»± tÆ°Æ¡ng quan giá»¯a cÃ¡c chá»‰ sá»‘ cháº¥t lÆ°á»£ng benchmark Ä‘Æ°á»£c Ä‘á» xuáº¥t vÃ  kháº£ nÄƒng cá»§a benchmark trong viá»‡c dá»± Ä‘oÃ¡n hiá»‡u suáº¥t LLM trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿.
-   PhÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p tá»± Ä‘á»™ng Ä‘á»ƒ táº¡o ra cÃ¡c trÆ°á»ng há»£p kiá»ƒm thá»­ má»›i cÃ³ kháº£ nÄƒng phÃ¢n biá»‡t cao hoáº·c cÃ³ tÃ­nh nháº¥t quÃ¡n xáº¿p háº¡ng tá»‘t dá»±a trÃªn phÃ¢n tÃ­ch cá»§a BENCHMARK^2.
-   Má»Ÿ rá»™ng khuÃ´n khá»• BENCHMARK^2 Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c khÃ­a cáº¡nh khÃ¡c cá»§a benchmark nhÆ° Ä‘á»™ bá»n vá»¯ng (robustness) trÆ°á»›c cÃ¡c nhiá»…u hoáº·c tÃ­nh cÃ´ng báº±ng (fairness) Ä‘á»‘i vá»›i cÃ¡c nhÃ³m dá»¯ liá»‡u khÃ¡c nhau.

#### 2. Patent:
-   Má»™t há»‡ thá»‘ng pháº§n má»m tÃ­ch há»£p vÃ o há»‡ Ä‘iá»u hÃ nh Ä‘iá»‡n thoáº¡i thÃ´ng minh, cho phÃ©p tá»± Ä‘á»™ng Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng cá»§a cÃ¡c benchmark Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm tra cÃ¡c mÃ´ hÃ¬nh AI trÃªn thiáº¿t bá»‹, giÃºp nhÃ  phÃ¡t triá»ƒn tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t LLM cho Ä‘iá»‡n thoáº¡i.
-   Má»™t á»©ng dá»¥ng di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng thá»±c hiá»‡n cÃ¡c bÃ i kiá»ƒm tra ngáº¯n cho LLM trÃªn Ä‘iá»‡n thoáº¡i cá»§a há», Ä‘á»“ng thá»i thu tháº­p dá»¯ liá»‡u vá» cÃ¡c chá»‰ sá»‘ CBRC, DS vÃ  CAD Ä‘á»ƒ cung cáº¥p pháº£n há»“i vá» cháº¥t lÆ°á»£ng benchmark cho cá»™ng Ä‘á»“ng.
-   Má»™t thuáº­t toÃ¡n nÃ©n benchmark Ä‘á»™c Ä‘Ã¡o dÃ nh cho thiáº¿t bá»‹ di Ä‘á»™ng, sá»­ dá»¥ng cÃ¡c chá»‰ sá»‘ BENCHMARK^2 Ä‘á»ƒ chá»n lá»c cÃ¡c cÃ¢u há»i kiá»ƒm tra hiá»‡u quáº£ nháº¥t, cho phÃ©p cÃ¡c LLM trÃªn Ä‘iá»‡n thoáº¡i Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ nhanh chÃ³ng mÃ  khÃ´ng cáº§n káº¿t ná»‘i máº¡ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03986](https://huggingface.co/papers/2601.03986) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03986](https://arxiv.org/abs/2601.03986) |
| PDF Download | [https://arxiv.org/pdf/2601.03986.pdf](https://arxiv.org/pdf/2601.03986.pdf) |
| Github Repository | N/A |

--- 

## 5. ROI-Reasoning: Rational Optimization for Inference via Pre-Computation Meta-Cognition

**TÃ¡c giáº£:** Muyang Zhao, Qi Qi, Hao Sun

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** LLMs, Budgeted Reasoning, Meta-Cognition, Resource Allocation, Reinforcement Learning, Knapsack Problem

### Main Problem:
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) hiá»‡n nay cÃ³ kháº£ nÄƒng suy luáº­n máº¡nh máº½ nhÆ°ng khÃ´ng thá»ƒ tá»± Æ°á»›c tÃ­nh lÆ°á»£ng tÃ i nguyÃªn tÃ­nh toÃ¡n (tokens) mÃ  má»™t tÃ¡c vá»¥ yÃªu cáº§u. Äiá»u nÃ y dáº«n Ä‘áº¿n viá»‡c thiáº¿u kháº£ nÄƒng phÃ¢n bá»• tÃ i nguyÃªn má»™t cÃ¡ch chiáº¿n lÆ°á»£c trÃªn nhiá»u tÃ¡c vá»¥ dÆ°á»›i má»™t giá»›i háº¡n ngÃ¢n sÃ¡ch toÃ n cáº§u nghiÃªm ngáº·t, gÃ¢y ra lÃ£ng phÃ­ tÃ i nguyÃªn vÃ  hiá»‡u suáº¥t khÃ´ng tá»‘i Æ°u, Ä‘áº·c biá»‡t khi pháº£i Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tuáº§n tá»± dÆ°á»›i sá»± khÃ´ng cháº¯c cháº¯n.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t ROI-Reasoning, má»™t khuÃ´n khá»• hai giai Ä‘oáº¡n nháº±m trang bá»‹ cho LLM kháº£ nÄƒng ra quyáº¿t Ä‘á»‹nh ná»™i táº¡i, há»£p lÃ½ vÃ  nháº­n biáº¿t ngÃ¢n sÃ¡ch trong quÃ¡ trÃ¬nh suy luáº­n.
1.  **Meta-Cognitive Fine-Tuning (MFT):** Giai Ä‘oáº¡n nÃ y huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n chi phÃ­ suy luáº­n (lÆ°á»£ng token) vÃ  lá»£i Ã­ch dá»± kiáº¿n cá»§a viá»‡c suy luáº­n trÆ°á»›c khi táº¡o ra báº¥t ká»³ pháº£n há»“i nÃ o. Äiá»u nÃ y cho phÃ©p mÃ´ hÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh rÃµ rÃ ng vá» viá»‡c "giáº£i quyáº¿t" hay "bá» qua" má»™t váº¥n Ä‘á».
2.  **Rationality-Aware Reinforcement Learning (RARL):** Giai Ä‘oáº¡n nÃ y tá»‘i Æ°u hÃ³a quÃ¡ trÃ¬nh ra quyáº¿t Ä‘á»‹nh tuáº§n tá»± cá»§a mÃ´ hÃ¬nh dÆ°á»›i giá»›i háº¡n token toÃ n cáº§u. MÃ´ hÃ¬nh há»c cÃ¡ch láº­p káº¿ hoáº¡ch vÃ  phÃ¢n bá»• tÃ­nh toÃ¡n trÃªn nhiá»u váº¥n Ä‘á» Ä‘á»ƒ tá»‘i Ä‘a hÃ³a hiá»‡u suáº¥t tá»•ng thá»ƒ trong dÃ i háº¡n.
Váº¥n Ä‘á» Ä‘Æ°á»£c chÃ­nh thá»©c hÃ³a nhÆ° má»™t "Ordered Stochastic Multiple-Choice Knapsack Problem (OS-MCKP)" Ä‘á»ƒ lÃ m ná»•i báº­t yÃªu cáº§u vá» kháº£ nÄƒng siÃªu nháº­n thá»©c.

### Main Results:
TrÃªn cÃ¡c bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ suy luáº­n toÃ¡n há»c cÃ³ ngÃ¢n sÃ¡ch giá»›i háº¡n, ROI-Reasoning liÃªn tá»¥c cáº£i thiá»‡n Ä‘iá»ƒm tá»•ng thá»ƒ. Quan trá»ng hÆ¡n, nÃ³ giáº£m Ä‘Ã¡ng ká»ƒ sá»± há»‘i tiáº¿c (regret) khi hoáº¡t Ä‘á»™ng dÆ°á»›i cÃ¡c ngÃ¢n sÃ¡ch tÃ­nh toÃ¡n cháº·t cháº½.

### Conclusion & Future Works:
ROI-Reasoning thÃ nh cÃ´ng trang bá»‹ cho LLM kháº£ nÄƒng láº­p káº¿ hoáº¡ch nháº­n thá»©c báº­c cao vÃ  Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh thÃ­ch á»©ng, cho phÃ©p phÃ¢n bá»• tÃ i nguyÃªn tÃ­nh toÃ¡n trong thá»i gian suy luáº­n má»™t cÃ¡ch há»£p lÃ½ vÃ  nháº­n biáº¿t lá»£i tá»©c Ä‘áº§u tÆ° (ROI). Báº£n trÃ­ch dáº«n khÃ´ng Ä‘á» cáº­p rÃµ rÃ ng Ä‘áº¿n cÃ¡c hÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo.

### Brainstorming Space:
#### 1. Publish Papers:
1. NghiÃªn cá»©u má»Ÿ rá»™ng ROI-Reasoning cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘a phÆ°Æ¡ng thá»©c, xem xÃ©t nhiá»u loáº¡i tÃ i nguyÃªn tÃ­nh toÃ¡n khÃ¡c nhau (vÃ­ dá»¥: thá»‹ giÃ¡c, Ã¢m thanh).
2. Ãp dá»¥ng khung ROI-Reasoning vÃ o lÄ©nh vá»±c AI Ä‘Ã m thoáº¡i thá»i gian thá»±c, nÆ¡i cáº§n tá»‘i Æ°u hÃ³a pháº£n há»“i trong Ä‘iá»u kiá»‡n ngÃ¢n sÃ¡ch Ä‘á»™ng vÃ  tÆ°Æ¡ng tÃ¡c liÃªn tá»¥c.
3. PhÃ¡t triá»ƒn cÃ¡c chiáº¿n lÆ°á»£c phÃ¢n bá»• ngÃ¢n sÃ¡ch thÃ­ch á»©ng, cÃ³ kháº£ nÄƒng Ä‘iá»u chá»‰nh linh hoáº¡t dá»±a trÃªn pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng hoáº·c sá»± thay Ä‘á»•i cá»§a mÃ´i trÆ°á»ng hoáº¡t Ä‘á»™ng.

#### 2. Patent:
1. Má»™t há»‡ thá»‘ng quáº£n lÃ½ tÃ i nguyÃªn tÃ­nh toÃ¡n tÃ­ch há»£p trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, cho phÃ©p á»©ng dá»¥ng AI phÃ¢n bá»• nÄƒng lÆ°á»£ng xá»­ lÃ½ vÃ  bá»™ nhá»› má»™t cÃ¡ch thÃ´ng minh dá»±a trÃªn Æ°á»›c tÃ­nh lá»£i tá»©c Ä‘áº§u tÆ° cho tá»«ng tÃ¡c vá»¥.
2. PhÆ°Æ¡ng phÃ¡p tá»‘i Æ°u hÃ³a thá»i lÆ°á»£ng pin cho cÃ¡c tÃ¡c vá»¥ suy luáº­n phá»©c táº¡p cá»§a LLM trÃªn thiáº¿t bá»‹ di Ä‘á»™ng báº±ng cÃ¡ch dá»± Ä‘oÃ¡n chi phÃ­ token vÃ  lá»£i Ã­ch cá»§a cÃ¡c lá»±a chá»n mÃ´ hÃ¬nh khÃ¡c nhau trÆ°á»›c khi thá»±c hiá»‡n.
3. Má»™t giao diá»‡n ngÆ°á»i dÃ¹ng trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¡c Æ°u tiÃªn ngÃ¢n sÃ¡ch cho tÃ¡c vá»¥ AI, Ä‘á»ƒ há»‡ thá»‘ng tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh má»©c Ä‘á»™ chi tiáº¿t cá»§a suy luáº­n LLM nháº±m Ä‘áº¡t hiá»‡u quáº£ cao nháº¥t trong giá»›i háº¡n Ä‘Ã£ cho.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03822](https://huggingface.co/papers/2601.03822) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03822](https://arxiv.org/abs/2601.03822) |
| PDF Download | [https://arxiv.org/pdf/2601.03822.pdf](https://arxiv.org/pdf/2601.03822.pdf) |
| Github Repository | N/A |

--- 

## 6. Klear: Unified Multi-Task Audio-Video Joint Generation

**TÃ¡c giáº£:** Jun Wang, Chunyu Qiang, Yuxin Guo, Yiran Wang, Xijuan Zeng, Chen Zhang, Pengfei Wan

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** Diffusion, Generative AI, Audio-Video Generation, Multimodal, Transformer, DiT, Flow Matching

### Main Problem:
CÃ¡c mÃ´ hÃ¬nh táº¡o sinh Ã¢m thanh-video hiá»‡n táº¡i gáº·p pháº£i nhiá»u thÃ¡ch thá»©c, bao gá»“m sá»± khÃ´ng Ä‘á»“ng bá»™ vá» máº·t ngá»¯ nghÄ©a vÃ  thá»i gian giá»¯a Ã¢m thanh vÃ  video, cháº¥t lÆ°á»£ng suy giáº£m khi táº¡o sinh Ä‘Æ¡n phÆ°Æ¡ng thá»©c (unimodal), sá»± thiáº¿u há»¥t dá»¯ liá»‡u cháº¥t lÆ°á»£ng cao cÃ³ chÃº thÃ­ch dÃ y Ä‘áº·c, vÃ  kháº£ nÄƒng khÃ¡i quÃ¡t hÃ³a háº¡n cháº¿ ra cÃ¡c tÃ¬nh huá»‘ng ngoÃ i phÃ¢n phá»‘i (OOD). Háº§u háº¿t cÃ¡c kiáº¿n trÃºc hiá»‡n cÃ³, Ä‘áº·c biá»‡t lÃ  cÃ¡c thiáº¿t káº¿ dual-tower hoáº·c single-tower vá»›i cross-attention nÃ´ng, khÃ´ng thá»ƒ tÃ­ch há»£p sÃ¢u sáº¯c cÃ¡c Ä‘áº·c trÆ°ng Ä‘a phÆ°Æ¡ng thá»©c Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± cÄƒn chá»‰nh cháº·t cháº½.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t Klear, má»™t framework táº¡o sinh Ã¢m thanh-video Ä‘a tÃ¡c vá»¥ thá»‘ng nháº¥t, giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» trÃªn thÃ´ng qua ba cáº£i tiáº¿n chÃ­nh:
1.  **Kiáº¿n trÃºc thá»‘ng nháº¥t:** Sá»­ dá»¥ng thiáº¿t káº¿ single-tower vá»›i cÃ¡c khá»‘i Diffusion Transformer (DiT) thá»‘ng nháº¥t vÃ  cÆ¡ cháº¿ Omni-Full Attention. CÆ¡ cháº¿ nÃ y cho phÃ©p chÃº Ã½ Ä‘á»“ng thá»i tá»›i bá»‘n luá»“ng (video, chÃº thÃ­ch video, Ã¢m thanh, chÃº thÃ­ch Ã¢m thanh/lá»i nÃ³i), thÃºc Ä‘áº©y sá»± há»£p nháº¥t Ä‘a phÆ°Æ¡ng thá»©c cháº·t cháº½ vÃ  kháº£ nÄƒng má»Ÿ rá»™ng máº¡nh máº½.
2.  **Chiáº¿n lÆ°á»£c huáº¥n luyá»‡n tiáº¿n hÃ³a:** Ãp dá»¥ng cháº¿ Ä‘á»™ huáº¥n luyá»‡n Ä‘a tÃ¡c vá»¥ tiáº¿n hÃ³a vá»›i ká»¹ thuáº­t máº·t náº¡ ngáº«u nhiÃªn tá»«ng phÆ°Æ¡ng thá»©c (random modality masking) vÃ  má»™t chÆ°Æ¡ng trÃ¬nh huáº¥n luyá»‡n Ä‘a giai Ä‘oáº¡n (multistage curriculum). Äiá»u nÃ y Ä‘áº£m báº£o tá»‘i Æ°u hÃ³a chung giá»¯a cÃ¡c tÃ¡c vá»¥ (Text to Audio-Video, Image to Audio-Video, Image to Video, Text to Video, Text to Audio), táº¡o ra cÃ¡c biá»ƒu diá»…n máº¡nh máº½, khai thÃ¡c kiáº¿n thá»©c tháº¿ giá»›i cÄƒn chá»‰nh A-V vÃ  ngÄƒn cháº·n sá»± suy giáº£m cháº¥t lÆ°á»£ng Ä‘Æ¡n phÆ°Æ¡ng thá»©c.
3.  **XÃ¢y dá»±ng dá»¯ liá»‡u quy mÃ´ lá»›n:** Giá»›i thiá»‡u bá»™ dá»¯ liá»‡u Ã¢m thanh-video quy mÃ´ lá»›n Ä‘áº§u tiÃªn vá»›i 81 triá»‡u máº«u cÃ³ chÃº thÃ­ch dÃ y Ä‘áº·c chÃ­nh xÃ¡c, cÃ¹ng vá»›i má»™t pipeline xÃ¢y dá»±ng dá»¯ liá»‡u tá»± Ä‘á»™ng hiá»‡u quáº£, lá»c vÃ  chÃº thÃ­ch hÃ ng triá»‡u cáº·p Ã¢m thanh-video-chÃº thÃ­ch cháº¥t lÆ°á»£ng cao vÃ  Ä‘Æ°á»£c cÄƒn chá»‰nh cháº·t cháº½.

### Main Results:
Klear Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y vÃ  ngang báº±ng vá»›i cÃ¡c há»‡ thá»‘ng thÆ°Æ¡ng máº¡i nhÆ° Veo 3 trong sá»‘ cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ. Cá»¥ thá»ƒ, nÃ³:
*   Cung cáº¥p kháº£ nÄƒng táº¡o sinh Ä‘á»™ chÃ¢n thá»±c cao (high fidelity) vá»›i sá»± cÄƒn chá»‰nh ngá»¯ nghÄ©a vÃ  thá»i gian máº¡nh máº½ giá»¯a Ã¢m thanh vÃ  video.
*   Thá»±c hiá»‡n Ä‘Ã¡ng tin cáº­y viá»‡c tuÃ¢n thá»§ cÃ¡c hÆ°á»›ng dáº«n (instruction following) trong cáº£ cÃ i Ä‘áº·t táº¡o sinh chung (joint) vÃ  Ä‘Æ¡n phÆ°Æ¡ng thá»©c (unimodal).
*   KhÃ¡i quÃ¡t hÃ³a máº¡nh máº½ ra cÃ¡c ká»‹ch báº£n ngoÃ i phÃ¢n phá»‘i (OOD generalization).
*   VÆ°á»£t trá»™i hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n trÆ°á»›c Ä‘Ã¢y trÃªn cÃ¡c benchmark Ä‘Æ¡n phÆ°Æ¡ng thá»©c vÃ  benchmark táº¡o sinh chung AV.

### Conclusion & Future Works:
Klear Ä‘áº¡i diá»‡n cho má»™t bÆ°á»›c tiáº¿n quan trá»ng trong táº¡o sinh Ã¢m thanh-video Ä‘a tÃ¡c vá»¥, cung cáº¥p má»™t framework thá»‘ng nháº¥t vÃ  cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng Ä‘á»ƒ táº¡o ra ná»™i dung Ä‘a phÆ°Æ¡ng tiá»‡n cháº¥t lÆ°á»£ng cao, cÄƒn chá»‰nh cháº·t cháº½. Vá»›i cÃ¡c cáº£i tiáº¿n vá» kiáº¿n trÃºc, chiáº¿n lÆ°á»£c huáº¥n luyá»‡n vÃ  dá»¯ liá»‡u, nÃ³ má»Ÿ ra con Ä‘Æ°á»ng cho tháº¿ há»‡ tiáº¿p theo cá»§a cÃ¡c há»‡ thá»‘ng tá»•ng há»£p Ã¢m thanh-video. BÃ i bÃ¡o khÃ´ng Ä‘á» cáº­p cá»¥ thá»ƒ vá» cÃ¡c cÃ´ng viá»‡c tÆ°Æ¡ng lai, nhÆ°ng ngá»¥ Ã½ ráº±ng phÆ°Æ¡ng phÃ¡p nÃ y lÃ  má»™t "con Ä‘Æ°á»ng thá»‘ng nháº¥t, cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng hÆ°á»›ng tá»›i tá»•ng há»£p Ã¢m thanh-video tháº¿ há»‡ tiáº¿p theo".

### Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u sÃ¢u hÆ¡n vá» cÆ¡ cháº¿ Omni-Full Attention Ä‘á»ƒ phÃ¢n tÃ­ch kháº£ nÄƒng Ä‘Ã³ng gÃ³p cá»§a tá»«ng luá»“ng Ä‘a phÆ°Æ¡ng thá»©c vÃ  má»‘i tÆ°Æ¡ng tÃ¡c cá»§a chÃºng.
*   PhÃ¡t triá»ƒn cÃ¡c chiáº¿n lÆ°á»£c huáº¥n luyá»‡n tá»± giÃ¡m sÃ¡t hoáº·c tá»± há»c máº¡nh máº½ hÆ¡n Ä‘á»ƒ khai thÃ¡c dá»¯ liá»‡u khÃ´ng cÃ³ nhÃ£n hoáº·c Ã­t nhÃ£n cho táº¡o sinh Ã¢m thanh-video.
*   Má»Ÿ rá»™ng framework Klear Ä‘á»ƒ tÃ­ch há»£p cÃ¡c phÆ°Æ¡ng thá»©c Ä‘áº§u vÃ o khÃ¡c nhÆ° cáº£m biáº¿n xÃºc giÃ¡c hoáº·c dá»¯ liá»‡u sinh tráº¯c há»c Ä‘á»ƒ táº¡o ra tráº£i nghiá»‡m Ä‘a phÆ°Æ¡ng tiá»‡n toÃ n diá»‡n hÆ¡n.

#### 2. Patent:
*   Há»‡ thá»‘ng á»©ng dá»¥ng di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng táº¡o video ngáº¯n cÃ³ Ã¢m thanh vÃ  lá»i nÃ³i Ä‘Æ°á»£c Ä‘á»“ng bá»™ hÃ³a cháº·t cháº½ chá»‰ tá»« má»™t mÃ´ táº£ vÄƒn báº£n hoáº·c hÃ¬nh áº£nh Ä‘áº§u vÃ o.
*   CÃ´ng nghá»‡ chá»‰nh sá»­a video tá»± Ä‘á»™ng trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, trong Ä‘Ã³ AI cÃ³ thá»ƒ táº¡o hoáº·c sá»­a Ä‘á»•i Ã¢m thanh vÃ  lá»i nÃ³i trong video Ä‘á»ƒ phÃ¹ há»£p vá»›i ká»‹ch báº£n hoáº·c thay Ä‘á»•i hÃ¬nh áº£nh Ä‘Æ°á»£c ngÆ°á»i dÃ¹ng thá»±c hiá»‡n.
*   PhÆ°Æ¡ng phÃ¡p nÃ©n vÃ  truyá»n táº£i dá»¯ liá»‡u Ä‘a phÆ°Æ¡ng tiá»‡n (Ã¢m thanh, video, chÃº thÃ­ch) má»™t cÃ¡ch hiá»‡u quáº£ trÃªn cÃ¡c thiáº¿t bá»‹ di Ä‘á»™ng, sá»­ dá»¥ng cÃ¡c biá»ƒu diá»…n latent há»c Ä‘Æ°á»£c tá»« mÃ´ hÃ¬nh Klear Ä‘á»ƒ tá»‘i Æ°u hÃ³a bÄƒng thÃ´ng vÃ  cháº¥t lÆ°á»£ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.04151](https://huggingface.co/papers/2601.04151) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.04151](https://arxiv.org/abs/2601.04151) |
| PDF Download | [https://arxiv.org/pdf/2601.04151.pdf](https://arxiv.org/pdf/2601.04151.pdf) |
| Github Repository | N/A |

--- 

## 7. Choreographing a World of Dynamic Objects

**TÃ¡c giáº£:** Yanzhe Lyu, Chen Geng, Karthik Dharmarajan, Yunzhi Zhang, Hadi Alzayer, Shangzhe Wu, Jiajun Wu

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** Generative Models, 4D Scene Dynamics, Object Interaction, Video Distillation, Robotics
### Main Problem:
Táº¡o ra cÃ¡c chuyá»ƒn Ä‘á»™ng 4D (biáº¿n dáº¡ng vÃ  tÆ°Æ¡ng tÃ¡c) chÃ¢n thá»±c vÃ  Ä‘a dáº¡ng cho nhiá»u Ä‘á»‘i tÆ°á»£ng trong má»™t cáº£nh lÃ  má»™t thÃ¡ch thá»©c lá»›n. CÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»“ há»a truyá»n thá»‘ng tá»‘n nhiá»u cÃ´ng sá»©c vÃ  khÃ´ng má»Ÿ rá»™ng Ä‘Æ°á»£c, trong khi cÃ¡c phÆ°Æ¡ng phÃ¡p há»c sÃ¢u Ä‘Ã²i há»i táº­p dá»¯ liá»‡u lá»›n hiáº¿m cÃ³ vÃ  thÆ°á»ng chá»‰ táº­p trung vÃ o biáº¿n dáº¡ng cá»§a má»™t Ä‘á»‘i tÆ°á»£ng Ä‘Æ¡n láº». NgoÃ i ra, viá»‡c xá»­ lÃ½ cÃ¡c biáº¿n dáº¡ng 4D cÃ³ chiá»u khÃ´ng gian cao vÃ  khÃ´ng Ä‘á»u vá» thá»i gian, cÃ¹ng vá»›i sá»± khÃ´ng tÆ°Æ¡ng thÃ­ch cá»§a kiáº¿n trÃºc mÃ´ hÃ¬nh táº¡o video hiá»‡n Ä‘áº¡i vá»›i cÃ¡c thuáº­t toÃ¡n chÆ°ng cáº¥t hiá»‡n cÃ³, cÃ ng lÃ m tÄƒng Ä‘á»™ khÃ³ cá»§a váº¥n Ä‘á».

### Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u CHORD, má»™t pipeline táº¡o sinh phá»• quÃ¡t Ä‘á»ƒ "biÃªn Ä‘áº¡o" cÃ¡c Ä‘á»‘i tÆ°á»£ng vÃ  cáº£nh Ä‘á»™ng báº±ng cÃ¡ch chÆ°ng cáº¥t thÃ´ng tin chuyá»ƒn Ä‘á»™ng tá»« cÃ¡c mÃ´ hÃ¬nh táº¡o video. PhÆ°Æ¡ng phÃ¡p nÃ y tá»‘i Æ°u láº·p láº¡i cÃ¡c biáº¿n dáº¡ng Lagrangian cáº¥p tháº¥p cá»§a tá»«ng Ä‘á»‘i tÆ°á»£ng. á» má»—i bÆ°á»›c, CHORD biáº¿n dáº¡ng cáº£nh 3D, dá»±ng hÃ¬nh tá»« cÃ¡c gÃ³c nhÃ¬n khÃ¡c nhau, vÃ  sá»­ dá»¥ng mÃ´ hÃ¬nh táº¡o video Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ­nh há»£p lÃ½ cá»§a biáº¿n dáº¡ng. Äá»ƒ giáº£i quyáº¿t cÃ¡c thÃ¡ch thá»©c, CHORD Ä‘á» xuáº¥t: (1) má»™t biá»ƒu diá»…n chuyá»ƒn Ä‘á»™ng 4D thÃ´-Ä‘áº¿n-tinh theo cáº¥p báº­c, káº¿t há»£p cÃ¡c Ä‘iá»ƒm kiá»ƒm soÃ¡t hai cáº¥p Ä‘á»™ cho khÃ´ng gian vÃ  cáº¥u trÃºc dá»±a trÃªn cÃ¢y Fenwick cho thá»i gian, nháº±m Ä‘áº£m báº£o tÃ­nh máº¡ch láº¡c vÃ  kháº£ nÄƒng há»c há»i chuyá»ƒn Ä‘á»™ng dÃ i háº¡n; vÃ  (2) má»™t chiáº¿n lÆ°á»£c chÆ°ng cáº¥t má»›i cho cÃ¡c mÃ´ hÃ¬nh táº¡o video dá»±a trÃªn rectified flow, bao gá»“m má»™t má»¥c tiÃªu Score Distillation Sampling (SDS) má»›i vÃ  chiáº¿n lÆ°á»£c láº¥y máº«u nhiá»…u thÃ­ch nghi Ä‘á»ƒ cung cáº¥p hÆ°á»›ng dáº«n hiá»‡u quáº£.

### Main Results:
CHORD cho tháº¥y hiá»‡u quáº£ vÆ°á»£t trá»™i so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡n cÃ³ trong viá»‡c táº¡o ra má»™t loáº¡t cÃ¡c Ä‘á»™ng lá»±c há»c 4D Ä‘a Ä‘á»‘i tÆ°á»£ng chÃ¢n thá»±c, mÃ  khÃ´ng yÃªu cáº§u cáº¥u trÃºc Ä‘á»™ng há»c cá»¥ thá»ƒ theo danh má»¥c hay táº­p dá»¯ liá»‡u 4D lá»›n. ÄÃ¢y lÃ  phÆ°Æ¡ng phÃ¡p Ä‘áº§u tiÃªn giáº£i quyáº¿t viá»‡c táº¡o chuyá»ƒn Ä‘á»™ng 4D cáº¥p Ä‘á»™ cáº£nh mÃ  khÃ´ng dá»±a vÃ o báº¥t ká»³ thiÃªn kiáº¿n quy náº¡p cá»¥ thá»ƒ nÃ o. NgoÃ i viá»‡c táº¡o sinh hÃ¬nh áº£nh, pipeline nÃ y cÃ²n táº¡o ra cÃ¡c quá»¹ Ä‘áº¡o biáº¿n dáº¡ng Lagrangian cÃ³ cÆ¡ sá»Ÿ váº­t lÃ½ cho cÃ¡c Ä‘á»‘i tÆ°á»£ng trong tháº¿ giá»›i thá»±c, cho phÃ©p robot thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ thao tÃ¡c Ä‘á»‘i tÆ°á»£ng Ä‘a dáº¡ng theo kiá»ƒu zero-shot.

### Conclusion & Future Works:
CHORD cung cáº¥p má»™t giáº£i phÃ¡p máº¡nh máº½ vÃ  hiá»‡u quáº£ cho váº¥n Ä‘á» táº¡o chuyá»ƒn Ä‘á»™ng 4D nháº¥t quÃ¡n cho cÃ¡c Ä‘á»‘i tÆ°á»£ng Ä‘á»™ng trong má»™t cáº£nh. CÃ¡c Ä‘Ã³ng gÃ³p chÃ­nh bao gá»“m má»™t biá»ƒu diá»…n chuyá»ƒn Ä‘á»™ng 4D má»›i káº¿t há»£p cáº¥u trÃºc thá»i gian tÃ­ch lÅ©y dá»±a trÃªn cÃ¢y Fenwick vá»›i tham sá»‘ hÃ³a DoF phÃ¢n cáº¥p, má»™t chiáº¿n lÆ°á»£c chÆ°ng cáº¥t cáº£i tiáº¿n cho cÃ¡c mÃ´ hÃ¬nh táº¡o video dá»±a trÃªn rectified flow, vÃ  má»™t khuÃ´n khá»• linh hoáº¡t cÃ³ kháº£ nÄƒng táº¡o chuyá»ƒn Ä‘á»™ng 4D cÃ³ cÆ¡ sá»Ÿ váº­t lÃ½, cÃ³ thá»ƒ Ã¡p dá»¥ng cho viá»‡c há»c cÃ¡c chÃ­nh sÃ¡ch thao tÃ¡c robot trong tháº¿ giá»›i thá»±c.

### Brainstorming Space:
#### 1. Publish Papers:
1.  NghiÃªn cá»©u má»Ÿ rá»™ng CHORD Ä‘á»ƒ tÃ­ch há»£p cÃ¡c rÃ ng buá»™c váº­t lÃ½ phá»©c táº¡p hÆ¡n, cho phÃ©p mÃ´ phá»ng cÃ¡c váº­t liá»‡u dá»… biáº¿n dáº¡ng hoáº·c cÃ¡c tÆ°Æ¡ng tÃ¡c lá»±c phá»©c táº¡p trong mÃ´i trÆ°á»ng 4D.
2.  KhÃ¡m phÃ¡ viá»‡c sá»­ dá»¥ng CHORD trong viá»‡c táº¡o ra cÃ¡c mÃ´i trÆ°á»ng huáº¥n luyá»‡n Ä‘a dáº¡ng vÃ  chÃ¢n thá»±c cho cÃ¡c tÃ¡c nhÃ¢n AI nháº­p vai, táº­p trung vÃ o kháº£ nÄƒng há»c táº­p tÄƒng cÆ°á»ng trong cÃ¡c tÃ¬nh huá»‘ng tÆ°Æ¡ng tÃ¡c váº­t lÃ½.
3.  PhÃ¡t triá»ƒn má»™t phÆ°Æ¡ng phÃ¡p tá»± Ä‘á»™ng Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng vÃ  Ä‘á»™ chÃ¢n thá»±c váº­t lÃ½ cá»§a chuyá»ƒn Ä‘á»™ng 4D Ä‘Æ°á»£c táº¡o ra, sá»­ dá»¥ng cÃ¡c metric dá»±a trÃªn mÃ´ phá»ng váº­t lÃ½ vÃ  pháº£n há»“i cá»§a con ngÆ°á»i.
#### 2. Patent:
1.  Má»™t há»‡ thá»‘ng á»©ng dá»¥ng di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng quay video 2D cá»§a má»™t váº­t thá»ƒ vÃ  sá»­ dá»¥ng cÃ´ng nghá»‡ CHORD Ä‘á»ƒ tá»± Ä‘á»™ng táº¡o ra mÃ´ hÃ¬nh 3D Ä‘á»™ng cá»§a váº­t thá»ƒ Ä‘Ã³, cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿ áº£o hoáº·c tÄƒng cÆ°á»ng trÃªn Ä‘iá»‡n thoáº¡i.
2.  CÃ´ng nghá»‡ tÃ­ch há»£p vÃ o camera Ä‘iá»‡n thoáº¡i Ä‘á»ƒ phÃ¢n tÃ­ch cáº£nh thá»±c táº¿ vÃ  táº¡o ra cÃ¡c hiá»‡u á»©ng Ä‘á»™ng 4D theo thá»i gian thá»±c (vÃ­ dá»¥: má»™t váº­t thá»ƒ trong video cÃ³ thá»ƒ tá»± Ä‘á»™ng biáº¿n dáº¡ng hoáº·c tÆ°Æ¡ng tÃ¡c vá»›i mÃ´i trÆ°á»ng áº£o theo ká»‹ch báº£n do ngÆ°á»i dÃ¹ng nháº­p text), cáº£i thiá»‡n tráº£i nghiá»‡m quay video.
3.  Má»™t phÆ°Æ¡ng phÃ¡p táº¡o ra cÃ¡c hoáº¡t áº£nh biá»ƒu cáº£m cho cÃ¡c emoji hoáº·c avatar 3D trÃªn Ä‘iá»‡n thoáº¡i, trong Ä‘Ã³ chuyá»ƒn Ä‘á»™ng vÃ  tÆ°Æ¡ng tÃ¡c cá»§a chÃºng Ä‘Æ°á»£c "biÃªn Ä‘áº¡o" bá»Ÿi CHORD dá»±a trÃªn vÄƒn báº£n hoáº·c Ã¢m thanh Ä‘áº§u vÃ o cá»§a ngÆ°á»i dÃ¹ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.04194](https://huggingface.co/papers/2601.04194) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.04194](https://arxiv.org/abs/2601.04194) |
| PDF Download | [https://arxiv.org/pdf/2601.04194.pdf](https://arxiv.org/pdf/2601.04194.pdf) |
| Github Repository | N/A |

--- 

## 8. Agentic Rubrics as Contextual Verifiers for SWE Agents

**TÃ¡c giáº£:** Mohit Raghavendra, Anisha Gunjal, Bing Liu, Yunzhong He

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** Agentic Rubrics, SWE Agents, Verification, LLMs, Software Engineering

### Main Problem:
Váº¥n Ä‘á» cá»‘t lÃµi mÃ  bÃ i bÃ¡o Ä‘á» cáº­p lÃ  viá»‡c xÃ¡c minh (verification) cÃ¡c báº£n vÃ¡ lá»—i cá»§a cÃ¡c tÃ¡c nhÃ¢n ká»¹ thuáº­t pháº§n má»m (SWE agents) hiá»‡n táº¡i thÆ°á»ng dá»±a vÃ o viá»‡c thá»±c thi mÃ£, vá»‘n khÃ³ má»Ÿ rá»™ng do chi phÃ­ thiáº¿t láº­p mÃ´i trÆ°á»ng cao. CÃ¡c giáº£i phÃ¡p thay tháº¿ khÃ´ng thá»±c thi mÃ£ thÃ¬ kÃ©m Ä‘Ã¡ng tin cáº­y, khÃ³ diá»…n giáº£i vÃ  Ã­t dá»±a vÃ o ngá»¯ cáº£nh cá»§a codebase.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t "Agentic Rubrics," má»™t phÆ°Æ¡ng phÃ¡p trong Ä‘Ã³ má»™t tÃ¡c nhÃ¢n chuyÃªn gia (expert agent) tÆ°Æ¡ng tÃ¡c vá»›i kho lÆ°u trá»¯ mÃ£ Ä‘á»ƒ táº¡o ra má»™t danh sÃ¡ch tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ (rubric checklist) cÃ³ ngá»¯ cáº£nh. Sau Ä‘Ã³, cÃ¡c báº£n vÃ¡ á»©ng cá»­ viÃªn sáº½ Ä‘Æ°á»£c cháº¥m Ä‘iá»ƒm dá»±a trÃªn danh sÃ¡ch nÃ y mÃ  khÃ´ng cáº§n thá»±c thi mÃ£. Äiá»u nÃ y giÃºp cung cáº¥p má»™t tÃ­n hiá»‡u xÃ¡c minh hiá»‡u quáº£, cÃ³ thá»ƒ má»Ÿ rá»™ng vÃ  chi tiáº¿t cho cÃ¡c tÃ¡c nhÃ¢n SWE.

### Main Results:
TrÃªn bá»™ dá»¯ liá»‡u SWE-Bench Verified dÆ°á»›i Ä‘Ã¡nh giÃ¡ TTS song song, Agentic Rubrics Ä‘áº¡t 54.2% trÃªn Qwen3-Coder-30B-A3B vÃ  40.6% trÃªn Qwen3-32B, vá»›i má»©c tÄƒng Ã­t nháº¥t 3.5 Ä‘iá»ƒm pháº§n trÄƒm so vá»›i baseline máº¡nh nháº¥t. PhÃ¢n tÃ­ch cho tháº¥y Ä‘iá»ƒm rubric phÃ¹ há»£p vá»›i cÃ¡c bÃ i kiá»ƒm tra ground-truth vÃ  cÅ©ng phÃ¡t hiá»‡n ra cÃ¡c váº¥n Ä‘á» mÃ  cÃ¡c bÃ i kiá»ƒm tra khÃ´ng náº¯m báº¯t Ä‘Æ°á»£c. CÃ¡c thÃ­ nghiá»‡m chá»©ng minh ráº±ng viá»‡c thu tháº­p ngá»¯ cáº£nh theo kiá»ƒu agentic lÃ  cáº§n thiáº¿t Ä‘á»ƒ táº¡o ra cÃ¡c tiÃªu chÃ­ cá»¥ thá»ƒ, rÃµ rÃ ng cho codebase.

### Conclusion & Future Works:
Agentic Rubrics cung cáº¥p má»™t tÃ­n hiá»‡u xÃ¡c minh hiá»‡u quáº£, cÃ³ thá»ƒ má»Ÿ rá»™ng vÃ  chi tiáº¿t cho cÃ¡c tÃ¡c nhÃ¢n ká»¹ thuáº­t pháº§n má»m. NgoÃ i ra, viá»‡c táº¡o rubric theo kiá»ƒu agentic cÃ³ thá»ƒ Ä‘Æ°á»£c cháº¯t lá»c (distilled) thÃ nh cÃ¡c mÃ´ hÃ¬nh mÃ£ nguá»“n má»Ÿ nhá» hÆ¡n, cho phÃ©p triá»ƒn khai quy mÃ´ lá»›n.

### Brainstorming Space:
#### 1. Publish Papers:
- NghiÃªn cá»©u viá»‡c Ã¡p dá»¥ng Agentic Rubrics cho viá»‡c xÃ¡c minh cÃ¡c nhiá»‡m vá»¥ ká»¹ thuáº­t pháº§n má»m phá»©c táº¡p hÆ¡n, cháº³ng háº¡n nhÆ° thiáº¿t káº¿ kiáº¿n trÃºc hoáº·c refactoring quy mÃ´ lá»›n.
- PhÃ¡t triá»ƒn má»™t phÆ°Æ¡ng phÃ¡p tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh trá»ng sá»‘ cá»§a cÃ¡c tiÃªu chÃ­ rubric dá»±a trÃªn má»©c Ä‘á»™ quan trá»ng Ä‘Æ°á»£c suy ra tá»« cÃ¡c thay Ä‘á»•i cá»§a codebase hoáº·c pháº£n há»“i cá»§a nhÃ  phÃ¡t triá»ƒn.
- KhÃ¡m phÃ¡ kháº£ nÄƒng tÃ­ch há»£p Agentic Rubrics vá»›i cÃ¡c quy trÃ¬nh kiá»ƒm thá»­ liÃªn tá»¥c Ä‘á»ƒ cung cáº¥p pháº£n há»“i nhanh chÃ³ng vÃ  ngá»¯ cáº£nh trong giai Ä‘oáº¡n phÃ¡t triá»ƒn.
#### 2. Patent:
- Há»‡ thá»‘ng tÃ­ch há»£p Agentic Rubrics vÃ o má»™t mÃ´i trÆ°á»ng phÃ¡t triá»ƒn di Ä‘á»™ng (IDE) trÃªn Ä‘iá»‡n thoáº¡i Ä‘á»ƒ cung cáº¥p pháº£n há»“i cháº¥t lÆ°á»£ng mÃ£ theo thá»i gian thá»±c cho cÃ¡c nhÃ  phÃ¡t triá»ƒn á»©ng dá»¥ng di Ä‘á»™ng.
- CÃ´ng nghá»‡ AI trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng sá»­ dá»¥ng Agentic Rubrics Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  xÃ¡c minh cÃ¡c báº£n vÃ¡ lá»—i báº£o máº­t hoáº·c cáº­p nháº­t há»‡ thá»‘ng trÆ°á»›c khi cÃ i Ä‘áº·t, Ä‘áº£m báº£o tÃ­nh tÆ°Æ¡ng thÃ­ch vÃ  an toÃ n cho thiáº¿t bá»‹.
- á»¨ng dá»¥ng di Ä‘á»™ng há»— trá»£ láº­p trÃ¬nh cÃ¡ nhÃ¢n hÃ³a, sá»­ dá»¥ng Agentic Rubrics Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ vÃ  Ä‘Æ°a ra pháº£n há»“i chi tiáº¿t, cÃ³ ngá»¯ cáº£nh cho cÃ¡c Ä‘oáº¡n mÃ£ do ngÆ°á»i dÃ¹ng viáº¿t trá»±c tiáº¿p trÃªn smartphone.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.04171](https://huggingface.co/papers/2601.04171) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.04171](https://arxiv.org/abs/2601.04171) |
| PDF Download | [https://arxiv.org/pdf/2601.04171.pdf](https://arxiv.org/pdf/2601.04171.pdf) |
| Github Repository | N/A |

--- 

## 9. MDAgent2: Large Language Model for Code Generation and Knowledge Q&A in Molecular Dynamics

**TÃ¡c giáº£:** Zhuofan Shi, Hubao A, Yufei Shao, Mengyan Dai, Yadong Yu, Pan Xiang, Dongliang Huang, Hongxu An, Chunxiao Xin, Haiyang Shen, Zhenyu Wang, Yunshan Na, Gang Huang, Xiang Jing

**Xuáº¥t báº£n lÃºc:** 2026-01-05

**Tag:** Large Language Model, Code Generation, Knowledge Q&A, Molecular Dynamics, LAMMPS, Multi-Agent System, Reinforcement Learning

### Main Problem:
Viá»‡c thá»±c hiá»‡n cÃ¡c mÃ´ phá»ng Ä‘á»™ng lá»±c há»c phÃ¢n tá»­ (MD) lÃ  thiáº¿t yáº¿u nhÆ°ng viá»‡c viáº¿t cÃ¡c táº­p lá»‡nh LAMMPS Ä‘Ã²i há»i chuyÃªn mÃ´n cao vÃ  tá»‘n thá»i gian. CÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLMs) hiá»‡n táº¡i bá»‹ háº¡n cháº¿ trong ká»‹ch báº£n MD do thiáº¿u dá»¯ liá»‡u miá»n, chi phÃ­ triá»ƒn khai cao cá»§a cÃ¡c LLMs tiÃªn tiáº¿n, kháº£ nÄƒng thá»±c thi mÃ£ tháº¥p, thiáº¿u cÃ¡c bá»™ tiÃªu chuáº©n Ä‘Ã¡nh giÃ¡ cho LAMMPS vÃ  cÃ¡c cÆ¡ cháº¿ tá»‘i Æ°u hÃ³a vÃ²ng láº·p kÃ­n cho viá»‡c táº¡o mÃ£.

### Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u MDAgent2, framework Ä‘áº§u cuá»‘i Ä‘áº§u tiÃªn cÃ³ kháº£ nÄƒng thá»±c hiá»‡n cáº£ Há»i & ÄÃ¡p kiáº¿n thá»©c vÃ  táº¡o mÃ£ trong lÄ©nh vá»±c Ä‘á»™ng lá»±c há»c phÃ¢n tá»­. NÃ³ xÃ¢y dá»±ng má»™t pipeline táº¡o dá»¯ liá»‡u chuyÃªn biá»‡t cháº¥t lÆ°á»£ng cao, táº¡o ra ba táº­p dá»¯ liá»‡u Ä‘á»™c Ä‘Ã¡o bao gá»“m kiáº¿n thá»©c MD, Há»i & ÄÃ¡p, vÃ  táº¡o mÃ£. Dá»±a trÃªn cÃ¡c táº­p dá»¯ liá»‡u nÃ y, MDAgent2 Ã¡p dá»¥ng chiáº¿n lÆ°á»£c háº­u huáº¥n luyá»‡n ba giai Ä‘oáº¡n (tiáº¿p tá»¥c tiá»n huáº¥n luyá»‡n CPT, tinh chá»‰nh cÃ³ giÃ¡m sÃ¡t SFT, vÃ  há»c tÄƒng cÆ°á»ng RL) Ä‘á»ƒ huáº¥n luyá»‡n hai mÃ´ hÃ¬nh thÃ­ch á»©ng miá»n lÃ  MD-Instruct vÃ  MD-Code. HÆ¡n ná»¯a, nÃ³ giá»›i thiá»‡u MD-GRPO, má»™t phÆ°Æ¡ng phÃ¡p RL vÃ²ng láº·p kÃ­n táº­n dá»¥ng káº¿t quáº£ mÃ´ phá»ng lÃ m tÃ­n hiá»‡u thÆ°á»Ÿng vÃ  tÃ¡i cháº¿ cÃ¡c quá»¹ Ä‘áº¡o thÆ°á»Ÿng tháº¥p Ä‘á»ƒ tinh chá»‰nh liÃªn tá»¥c. BÃ i bÃ¡o cÅ©ng xÃ¢y dá»±ng MDAgent2-RUNTIME, má»™t há»‡ thá»‘ng Ä‘a tÃ¡c nhÃ¢n cÃ³ kháº£ nÄƒng triá»ƒn khai tÃ­ch há»£p táº¡o mÃ£, thá»±c thi, Ä‘Ã¡nh giÃ¡ vÃ  tá»± sá»­a lá»—i.

### Main Results:
MDAgent2, cÃ¹ng vá»›i MD-EvalBench (bá»™ tiÃªu chuáº©n Ä‘áº§u tiÃªn cho viá»‡c táº¡o mÃ£ vÃ  Há»i & ÄÃ¡p LAMMPS), Ä‘áº¡t hiá»‡u suáº¥t vÆ°á»£t trá»™i so vá»›i nhiá»u baseline máº¡nh. CÃ¡c mÃ´ hÃ¬nh vÃ  há»‡ thá»‘ng nÃ y thá»ƒ hiá»‡n kháº£ nÄƒng thÃ­ch á»©ng vÃ  khÃ¡i quÃ¡t hÃ³a máº¡nh máº½ cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n trong cÃ¡c tÃ¡c vá»¥ mÃ´ phá»ng cÃ´ng nghiá»‡p. Cá»¥ thá»ƒ, MD-Instruct-8B Ä‘áº¡t tá»•ng Ä‘iá»ƒm 74.67 trong kháº£ nÄƒng Há»i & ÄÃ¡p, vÆ°á»£t qua Qwen3-8b (70.50), vÃ  MDAgent2-RUNTIME hiá»‡u quáº£ trong viá»‡c tÄƒng cÆ°á»ng kháº£ nÄƒng táº¡o mÃ£ LAMMPS chÃ­nh xÃ¡c vÃ  cÃ³ thá»ƒ thá»±c thi Ä‘Æ°á»£c.

### Conclusion & Future Works:
CÃ´ng trÃ¬nh nÃ y chá»©ng minh má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng kháº£ nÄƒng thÃ­ch á»©ng vÃ  khÃ¡i quÃ¡t hÃ³a cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n trong cÃ¡c tÃ¡c vá»¥ mÃ´ phá»ng cÃ´ng nghiá»‡p, Ä‘áº·t ná»n táº£ng phÆ°Æ¡ng phÃ¡p luáº­n cho viá»‡c táº¡o mÃ£ tá»± Ä‘á»™ng trong AI cho Khoa há»c vÃ  cÃ¡c mÃ´ phá»ng quy mÃ´ cÃ´ng nghiá»‡p. BÃ i bÃ¡o khÃ´ng Ä‘i sÃ¢u vÃ o cÃ¡c hÆ°á»›ng nghiÃªn cá»©u cá»¥ thá»ƒ tiáº¿p theo mÃ  táº­p trung vÃ o viá»‡c nháº¥n máº¡nh thÃ nh tá»±u hiá»‡n táº¡i.

### Brainstorming Space:
#### 1. Publish Papers:
NghiÃªn cá»©u vá» viá»‡c má»Ÿ rá»™ng MDAgent2 Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a cÃ¡c loáº¡i mÃ´ phá»ng khoa há»c khÃ¡c ngoÃ i Ä‘á»™ng lá»±c há»c phÃ¢n tá»­, nhÆ° mÃ´ phá»ng váº­t lÃ½ cháº¥t ráº¯n hoáº·c sinh há»c.
PhÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p há»c tÄƒng cÆ°á»ng tiÃªn tiáº¿n hÆ¡n Ä‘á»ƒ tá»‘i Æ°u hÃ³a mÃ£ Ä‘Æ°á»£c táº¡o ra, cÃ³ thá»ƒ bao gá»“m pháº£n há»“i tá»« cÃ¡c thá»­ nghiá»‡m thá»±c táº¿ thay vÃ¬ chá»‰ mÃ´ phá»ng.
KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p cÃ¡c mÃ´ hÃ¬nh kiáº¿n thá»©c miá»n sÃ¢u rá»™ng hÆ¡n vÃ o kiáº¿n trÃºc LLM Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng lÃ½ luáº­n vÃ  táº¡o mÃ£ cho cÃ¡c ká»‹ch báº£n mÃ´ phá»ng phá»©c táº¡p.
#### 2. Patent:
Má»™t á»©ng dá»¥ng di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng nháº­p cÃ¡c yÃªu cáº§u mÃ´ phá»ng Ä‘á»™ng lá»±c há»c phÃ¢n tá»­ báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn vÃ  nháº­n vá» mÃ£ LAMMPS Ä‘Ã£ táº¡o, cÃ¹ng vá»›i kháº£ nÄƒng xem trÆ°á»›c káº¿t quáº£ trÃªn Ä‘iá»‡n thoáº¡i.
Há»‡ thá»‘ng AI tÃ­ch há»£p vÃ o Ä‘iá»‡n thoáº¡i thÃ´ng minh cÃ³ thá»ƒ sá»­ dá»¥ng dá»¯ liá»‡u tá»« cáº£m biáº¿n cá»§a Ä‘iá»‡n thoáº¡i Ä‘á»ƒ gá»£i Ã½ hoáº·c táº¡o cÃ¡c ká»‹ch báº£n mÃ´ phá»ng MD liÃªn quan Ä‘áº¿n cÃ¡c váº­t liá»‡u xung quanh ngÆ°á»i dÃ¹ng.
Má»™t dá»‹ch vá»¥ Ä‘Ã¡m mÃ¢y Ä‘Æ°á»£c truy cáº­p thÃ´ng qua á»©ng dá»¥ng Ä‘iá»‡n thoáº¡i, cung cáº¥p kháº£ nÄƒng táº¡o mÃ£ LAMMPS chuyÃªn nghiá»‡p theo yÃªu cáº§u, cháº¡y mÃ´ phá»ng trÃªn cÃ¡c cá»¥m mÃ¡y tÃ­nh máº¡nh máº½ vÃ  gá»­i káº¿t quáº£ phÃ¢n tÃ­ch vá» Ä‘iá»‡n thoáº¡i.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.02075](https://huggingface.co/papers/2601.02075) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.02075](https://arxiv.org/abs/2601.02075) |
| PDF Download | [https://arxiv.org/pdf/2601.02075.pdf](https://arxiv.org/pdf/2601.02075.pdf) |
| Github Repository | N/A |

--- 

## 10. E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models

**TÃ¡c giáº£:** Shengjun Zhang, Zhang Zhang, Chensheng Dai, Yueqi Duan

**Xuáº¥t báº£n lÃºc:** 2026-01-01

**Tag:** Reinforcement Learning, Flow Models, SDE, GRPO, Entropy-aware, Generative Models
### Main Problem:
CÃ¡c phÆ°Æ¡ng phÃ¡p há»c tÄƒng cÆ°á»ng hiá»‡n cÃ³ dá»±a trÃªn GRPO Ä‘á»ƒ tá»‘i Æ°u hÃ³a mÃ´ hÃ¬nh dÃ²ng cháº£y (flow models) gáº·p pháº£i tÃ­n hiá»‡u pháº§n thÆ°á»Ÿng thÆ°a thá»›t vÃ  mÆ¡ há»“ khi tá»‘i Æ°u hÃ³a qua nhiá»u bÆ°á»›c khá»­ nhiá»…u. Äiá»u nÃ y cáº£n trá»Ÿ sá»± cÄƒn chá»‰nh hiá»‡u quáº£ vá»›i sá»Ÿ thÃ­ch cá»§a con ngÆ°á»i, Ä‘áº·c biá»‡t lÃ  do cÃ¡c bÆ°á»›c cÃ³ entropy tháº¥p táº¡o ra káº¿t quáº£ khÃ´ng phÃ¢n biá»‡t, trong khi chá»‰ cÃ¡c bÆ°á»›c cÃ³ entropy cao má»›i Ä‘Ã³ng gÃ³p Ä‘Ã¡ng ká»ƒ vÃ o Ä‘á»™ng lá»±c huáº¥n luyá»‡n.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t E-GRPO (Entropy-aware Group Relative Policy Optimization) Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» trÃªn. Ã tÆ°á»Ÿng chÃ­nh lÃ  tÄƒng entropy cá»§a cÃ¡c bÆ°á»›c láº¥y máº«u SDE báº±ng cÃ¡ch há»£p nháº¥t cÃ¡c bÆ°á»›c cÃ³ entropy tháº¥p liÃªn tiáº¿p thÃ nh má»™t bÆ°á»›c SDE cÃ³ entropy cao duy nháº¥t, trong khi Ã¡p dá»¥ng láº¥y máº«u ODE cho cÃ¡c bÆ°á»›c cÃ²n láº¡i. Äiá»u nÃ y giÃºp má»Ÿ rá»™ng kháº£ nÄƒng khÃ¡m phÃ¡ cÃ³ Ã½ nghÄ©a vÃ  loáº¡i bá» sá»± mÆ¡ há»“ trong viá»‡c phÃ¢n bá»• pháº§n thÆ°á»Ÿng. HÆ¡n ná»¯a, E-GRPO giá»›i thiá»‡u lá»£i tháº¿ nhÃ³m Ä‘Æ°á»£c chuáº©n hÃ³a Ä‘a bÆ°á»›c (multi-step group normalized advantage), tÃ­nh toÃ¡n lá»£i tháº¿ tÆ°Æ¡ng Ä‘á»‘i trong nhÃ³m cho cÃ¡c máº«u chia sáº» cÃ¹ng má»™t bÆ°á»›c khá»­ nhiá»…u SDE Ä‘Ã£ há»£p nháº¥t.

### Main Results:
CÃ¡c thÃ­ nghiá»‡m trÃªn cáº£ cÃ i Ä‘áº·t pháº§n thÆ°á»Ÿng Ä‘Æ¡n láº» vÃ  Ä‘a pháº§n thÆ°á»Ÿng, cÅ©ng nhÆ° Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c ma tráº­n trong vÃ  ngoÃ i miá»n, Ä‘Ã£ chá»©ng minh tÃ­nh hiá»‡u quáº£ vÃ  hiá»‡u suáº¥t cá»§a E-GRPO. Cá»¥ thá»ƒ, E-GRPO Ä‘Ã£ vÆ°á»£t trá»™i hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y má»™t cÃ¡ch nháº¥t quÃ¡n, xÃ¡c nháº­n tÃ­nh hiá»‡u quáº£ vÃ  máº¡nh máº½ cá»§a viá»‡c tá»‘i Æ°u hÃ³a ngáº«u nhiÃªn Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi entropy. PhÃ¢n tÃ­ch dá»±a trÃªn entropy cho tháº¥y viá»‡c tá»‘i Æ°u hÃ³a Ä‘á»™c quyá»n á»Ÿ cÃ¡c bÆ°á»›c cÃ³ entropy cao mang láº¡i sá»± cÄƒn chá»‰nh hiá»‡u quáº£.

### Conclusion & Future Works:
E-GRPO cung cáº¥p má»™t phÃ¢n tÃ­ch toÃ n diá»‡n dá»±a trÃªn entropy vá» cÃ¡c bÆ°á»›c khá»­ nhiá»…u trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n GRPO, cho tháº¥y sá»± cÄƒn chá»‰nh hiá»‡u quáº£ cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch tá»‘i Æ°u hÃ³a riÃªng cÃ¡c bÆ°á»›c cÃ³ entropy cao. PhÆ°Æ¡ng phÃ¡p nÃ y má»Ÿ rá»™ng kháº£ nÄƒng khÃ¡m phÃ¡ cÃ³ Ã½ nghÄ©a vÃ  loáº¡i bá» sá»± mÆ¡ há»“ trong viá»‡c phÃ¢n bá»• pháº§n thÆ°á»Ÿng báº±ng cÃ¡ch há»£p nháº¥t cÃ¡c bÆ°á»›c cÃ³ entropy tháº¥p thÃ nh má»™t bÆ°á»›c SDE cÃ³ entropy cao. CÃ¡c thá»­ nghiá»‡m rá»™ng rÃ£i xÃ¡c nháº­n E-GRPO liÃªn tá»¥c vÆ°á»£t trá»™i hÆ¡n cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã¢y. BÃ i bÃ¡o khÃ´ng Ä‘á» cáº­p cá»¥ thá»ƒ Ä‘áº¿n hÆ°á»›ng nghiÃªn cá»©u trong tÆ°Æ¡ng lai, nhÆ°ng má»Ÿ ra tiá»m nÄƒng cho cÃ¡c chiáº¿n lÆ°á»£c tá»‘i Æ°u hÃ³a ngáº«u nhiÃªn Ä‘Æ°á»£c hÆ°á»›ng dáº«n bá»Ÿi entropy trong cÃ¡c mÃ´ hÃ¬nh táº¡o ná»™i dung.

### Brainstorming Space:
#### 1. Publish Papers:
- NghiÃªn cá»©u chiáº¿n lÆ°á»£c há»£p nháº¥t bÆ°á»›c SDE thÃ­ch á»©ng dá»±a trÃªn pháº£n há»“i pháº§n thÆ°á»Ÿng theo thá»i gian thá»±c Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t E-GRPO trong cÃ¡c mÃ´i trÆ°á»ng Ä‘á»™ng.
- Má»Ÿ rá»™ng á»©ng dá»¥ng cá»§a E-GRPO sang cÃ¡c mÃ´ hÃ¬nh táº¡o sinh khÃ¡c nhÆ° Diffusion Models cho cÃ¡c tÃ¡c vá»¥ táº¡o hÃ¬nh áº£nh cÃ³ Ä‘iá»u kiá»‡n vÃ  khÃ´ng Ä‘iá»u kiá»‡n.
- PhÃ¡t triá»ƒn má»™t khuÃ´n khá»• lÃ½ thuyáº¿t Ä‘á»ƒ Ä‘á»‹nh lÆ°á»£ng sá»‘ lÆ°á»£ng vÃ  vá»‹ trÃ­ tá»‘i Æ°u cá»§a cÃ¡c bÆ°á»›c SDE Ä‘Æ°á»£c há»£p nháº¥t cho cÃ¡c phÃ¢n phá»‘i dá»¯ liá»‡u vÃ  Ä‘á»™ phá»©c táº¡p tÃ¡c vá»¥ khÃ¡c nhau.
#### 2. Patent:
- Há»‡ thá»‘ng tÃ¹y chá»‰nh hÃ¬nh áº£nh trÃªn Ä‘iá»‡n thoáº¡i sá»­ dá»¥ng E-GRPO Ä‘á»ƒ táº¡o ra cÃ¡c biáº¿n thá»ƒ hÃ¬nh áº£nh dá»±a trÃªn sá»Ÿ thÃ­ch ngÆ°á»i dÃ¹ng, chá»‰ táº­p trung vÃ o cÃ¡c chi tiáº¿t cÃ³ Ä‘á»™ biáº¿n thiÃªn cao Ä‘á»ƒ tinh chá»‰nh hiá»‡u quáº£.
- PhÆ°Æ¡ng phÃ¡p tá»‘i Æ°u hÃ³a táº¡o áº£nh Ä‘áº¡i diá»‡n (avatar) cÃ¡ nhÃ¢n trÃªn á»©ng dá»¥ng di Ä‘á»™ng, nÆ¡i E-GRPO tá»± Ä‘á»™ng tinh chá»‰nh cÃ¡c Ä‘áº·c Ä‘iá»ƒm khuÃ´n máº·t "quan trá»ng" (high entropy) Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± hÃ i lÃ²ng cá»§a ngÆ°á»i dÃ¹ng nhanh hÆ¡n.
- CÃ´ng nghá»‡ nÃ©n video thÃ´ng minh cho Ä‘iá»‡n thoáº¡i, sá»­ dá»¥ng E-GRPO Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vÃ  báº£o toÃ n cÃ¡c khung hÃ¬nh hoáº·c vÃ¹ng cÃ³ Ä‘á»™ phá»©c táº¡p cao (high entropy) trong video, giÃºp giáº£m dung lÆ°á»£ng mÃ  váº«n giá»¯ Ä‘Æ°á»£c cháº¥t lÆ°á»£ng nháº­n thá»©c.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.00423](https://huggingface.co/papers/2601.00423) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.00423](https://arxiv.org/abs/2601.00423) |
| PDF Download | [https://arxiv.org/pdf/2601.00423.pdf](https://arxiv.org/pdf/2601.00423.pdf) |
| Github Repository | [https://github.com/shengjun-zhang/VisualGRPO](https://github.com/shengjun-zhang/VisualGRPO) |

--- 

## 11. EpiQAL: Benchmarking Large Language Models in Epidemiological Question Answering for Enhanced Alignment and Reasoning

**TÃ¡c giáº£:** Mingyang Wei, Dehai Min, Zewen Liu, Yuzhang Xie, Guanchen Wu, Carl Yang, Max S. Y. Lau, Qi He, Lu Cheng, Wei Jin

**Xuáº¥t báº£n lÃºc:** 2026-01-06

**Tag:** Benchmarking, LLMs, Epidemiological QA, NLP, Y táº¿ cÃ´ng cá»™ng, LÃ½ luáº­n dá»‹ch tá»… há»c.
### Main Problem:
CÃ¡c bá»™ dá»¯ liá»‡u há»i Ä‘Ã¡p y táº¿ hiá»‡n cÃ³ chá»§ yáº¿u táº­p trung vÃ o kiáº¿n thá»©c lÃ¢m sÃ ng hoáº·c lÃ½ luáº­n cáº¥p Ä‘á»™ bá»‡nh nhÃ¢n, bá» qua viá»‡c Ä‘Ã¡nh giÃ¡ cÃ³ há»‡ thá»‘ng suy luáº­n dá»‹ch tá»… há»c dá»±a trÃªn báº±ng chá»©ng á»Ÿ cáº¥p Ä‘á»™ quáº§n thá»ƒ. Äiá»u nÃ y táº¡o ra má»™t khoáº£ng trá»‘ng trong viá»‡c Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) trong viá»‡c tá»•ng há»£p báº±ng chá»©ng nghiÃªn cá»©u Ä‘á»ƒ suy luáº­n vá» gÃ¡nh náº·ng bá»‡nh táº­t, Ä‘á»™ng lá»±c lÃ¢y truyá»n vÃ  hiá»‡u quáº£ can thiá»‡p á»Ÿ cáº¥p Ä‘á»™ dÃ¢n sá»‘.

### Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u EpiQAL, bá»™ dá»¯ liá»‡u chuáº©n Ä‘oÃ¡n Ä‘áº§u tiÃªn cho há»i Ä‘Ã¡p dá»‹ch tá»… há»c trÃªn nhiá»u loáº¡i bá»‡nh khÃ¡c nhau, Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« tÃ i liá»‡u truy cáº­p má»Ÿ. EpiQAL bao gá»“m ba táº­p con: EpiQAL-A Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng nhá»› láº¡i thÃ´ng tin thá»±c táº¿ cÃ³ trong vÄƒn báº£n, EpiQAL-B Ä‘Ã¡nh giÃ¡ suy luáº­n Ä‘a bÆ°á»›c liÃªn káº¿t báº±ng chá»©ng tÃ i liá»‡u vá»›i cÃ¡c nguyÃªn táº¯c dá»‹ch tá»… há»c, vÃ  EpiQAL-C Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng tÃ¡i táº¡o káº¿t luáº­n khi pháº§n Tháº£o luáº­n bá»‹ che giáº¥u. QuÃ¡ trÃ¬nh xÃ¢y dá»±ng káº¿t há»£p hÆ°á»›ng dáº«n phÃ¢n loáº¡i tá»« chuyÃªn gia, xÃ¡c minh Ä‘a mÃ´ hÃ¬nh vÃ  kiá»ƒm soÃ¡t Ä‘á»™ khÃ³ dá»±a trÃªn truy xuáº¥t.

### Main Results:
CÃ¡c thá»­ nghiá»‡m trÃªn mÆ°á»i mÃ´ hÃ¬nh má»Ÿ cho tháº¥y cÃ¡c LLMs hiá»‡n táº¡i cÃ³ hiá»‡u suáº¥t háº¡n cháº¿ trong lÃ½ luáº­n dá»‹ch tá»… há»c, vá»›i suy luáº­n Ä‘a bÆ°á»›c lÃ  thÃ¡ch thá»©c lá»›n nháº¥t. Thá»© háº¡ng cá»§a cÃ¡c mÃ´ hÃ¬nh thay Ä‘á»•i trÃªn cÃ¡c táº­p con vÃ  quy mÃ´ mÃ´ hÃ¬nh khÃ´ng dá»± Ä‘oÃ¡n Ä‘Æ°á»£c thÃ nh cÃ´ng. Ká»¹ thuáº­t gá»£i Ã½ Chain-of-Thought mang láº¡i lá»£i Ã­ch cho suy luáº­n Ä‘a bÆ°á»›c nhÆ°ng cho káº¿t quáº£ trÃ¡i chiá»u á»Ÿ cÃ¡c lÄ©nh vá»±c khÃ¡c.

### Conclusion & Future Works:
EpiQAL cung cáº¥p cÃ¡c tÃ­n hiá»‡u cháº©n Ä‘oÃ¡n chi tiáº¿t vá» viá»‡c tÃ¬m kiáº¿m báº±ng chá»©ng, lÃ½ luáº­n suy luáº­n vÃ  tÃ¡i táº¡o káº¿t luáº­n trong lÄ©nh vá»±c dá»‹ch tá»… há»c. Bá»™ dá»¯ liá»‡u nÃ y giÃºp lÃ m rÃµ nhá»¯ng háº¡n cháº¿ hiá»‡n táº¡i cá»§a LLMs trong viá»‡c xá»­ lÃ½ cÃ¡c nhiá»‡m vá»¥ lÃ½ luáº­n phá»©c táº¡p, hÆ°á»›ng tá»›i viá»‡c nÃ¢ng cao kháº£ nÄƒng cÄƒn chá»‰nh vÃ  lÃ½ luáº­n cá»§a LLMs trong lÄ©nh vá»±c y táº¿ cÃ´ng cá»™ng.

### Brainstorming Space:
#### 1. Publish Papers:
*   PhÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p tinh chá»‰nh (fine-tuning) LLMs má»›i hoáº·c kiáº¿n trÃºc mÃ´ hÃ¬nh lai (hybrid models) Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t suy luáº­n Ä‘a bÆ°á»›c trÃªn EpiQAL-B.
*   NghiÃªn cá»©u á»©ng dá»¥ng cÃ¡c ká»¹ thuáº­t Retrieval-Augmented Generation (RAG) nÃ¢ng cao Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng thu tháº­p báº±ng chá»©ng vÃ  giáº£m "áº£o giÃ¡c" cá»§a LLMs trong cÃ¡c cÃ¢u há»i dá»‹ch tá»… há»c phá»©c táº¡p.
*   PhÃ¢n tÃ­ch sÃ¢u hÆ¡n cÃ¡c loáº¡i lá»—i cá»¥ thá»ƒ mÃ  LLMs máº¯c pháº£i trong cÃ¡c táº­p con cá»§a EpiQAL Ä‘á»ƒ xÃ¡c Ä‘á»‹nh cÃ¡c Ä‘iá»ƒm yáº¿u cá»‘t lÃµi trong lÃ½ luáº­n nhÃ¢n quáº£ vÃ  thá»‘ng kÃª.
#### 2. Patent:
*   Má»™t á»©ng dá»¥ng di Ä‘á»™ng tÃ­ch há»£p LLMs Ä‘Æ°á»£c tinh chá»‰nh báº±ng EpiQAL Ä‘á»ƒ cung cáº¥p thÃ´ng tin sá»©c khá»e cá»™ng Ä‘á»“ng Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c minh vÃ  giáº£i thÃ­ch rÃµ rÃ ng dá»±a trÃªn cÃ¡c nghiÃªn cá»©u dá»‹ch tá»… há»c cho ngÆ°á»i dÃ¹ng.
*   Má»™t há»‡ thá»‘ng kiá»ƒm tra thÃ´ng tin sai lá»‡ch tá»± Ä‘á»™ng trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, sá»­ dá»¥ng ná»n táº£ng EpiQAL Ä‘á»ƒ Ä‘á»‘i chiáº¿u cÃ¡c tin tá»©c hoáº·c bÃ i Ä‘Äƒng trÃªn máº¡ng xÃ£ há»™i vá» dá»‹ch bá»‡nh vá»›i báº±ng chá»©ng khoa há»c Ä‘Ã¡ng tin cáº­y.
*   Má»™t tÃ­nh nÄƒng trá»£ lÃ½ nghiÃªn cá»©u dá»‹ch tá»… há»c trÃªn Ä‘iá»‡n thoáº¡i, cho phÃ©p cÃ¡c chuyÃªn gia y táº¿ truy váº¥n nhanh cÃ¡c tÃ i liá»‡u khoa há»c vÃ  nháº­n tÃ³m táº¯t cÃ¡c káº¿t luáº­n quan trá»ng tá»« dá»¯ liá»‡u trong EpiQAL.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03471](https://huggingface.co/papers/2601.03471) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03471](https://arxiv.org/abs/2601.03471) |
| PDF Download | [https://arxiv.org/pdf/2601.03471.pdf](https://arxiv.org/pdf/2601.03471.pdf) |
| Github Repository | N/A |

--- 

## 12. RedBench: A Universal Dataset for Comprehensive Red Teaming of Large Language Models

**TÃ¡c giáº£:** Quy-Anh Dang, Chris Ngo, Truong-Son Hy

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** Red Teaming, LLMs, Dataset, Vulnerability Assessment, Safety, Robustness

### Main Problem:
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) ngÃ y cÃ ng Ä‘Æ°á»£c tÃ­ch há»£p vÃ o cÃ¡c á»©ng dá»¥ng quan trá»ng vá» an toÃ n, nhÆ°ng viá»‡c Ä‘áº£m báº£o tÃ­nh bá»n vá»¯ng cá»§a chÃºng trÆ°á»›c cÃ¡c "prompts" Ä‘á»‘i khÃ¡ng lÃ  vÃ´ cÃ¹ng quan trá»ng. CÃ¡c bá»™ dá»¯ liá»‡u "red teaming" hiá»‡n cÃ³ gáº·p pháº£i cÃ¡c váº¥n Ä‘á» nhÆ° phÃ¢n loáº¡i rá»§i ro khÃ´ng nháº¥t quÃ¡n, pháº¡m vi bao phá»§ miá»n háº¡n cháº¿ vÃ  Ä‘Ã¡nh giÃ¡ lá»—i thá»i, gÃ¢y cáº£n trá»Ÿ viá»‡c Ä‘Ã¡nh giÃ¡ lá»— há»•ng má»™t cÃ¡ch cÃ³ há»‡ thá»‘ng. Äiá»u nÃ y dáº«n Ä‘áº¿n sá»± thiáº¿u há»¥t má»™t bá»™ dá»¯ liá»‡u phá»• quÃ¡t cung cáº¥p phÃ¢n loáº¡i rá»§i ro nháº¥t quÃ¡n vÃ  Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n trÃªn cÃ¡c miá»n Ä‘a dáº¡ng, cÅ©ng nhÆ° viá»‡c thiáº¿u cÃ¡c Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t cá»§a cÃ¡c LLM hiá»‡n Ä‘áº¡i dÆ°á»›i cÃ¡c bÃ i kiá»ƒm tra "red teaming".

### Main Idea:
NghiÃªn cá»©u nÃ y giá»›i thiá»‡u RedBench, má»™t bá»™ dá»¯ liá»‡u phá»• quÃ¡t má»›i Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ nÃ¢ng cao "red teaming" cho LLM. RedBench tá»•ng há»£p vÃ  hÃ i hÃ²a 37 bá»™ dá»¯ liá»‡u hiá»‡n cÃ³ tá»« cÃ¡c há»™i nghá»‹ vÃ  bÃ i bÃ¡o cÃ³ áº£nh hÆ°á»Ÿng, cung cáº¥p má»™t khung tiÃªu chuáº©n Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c lá»— há»•ng cá»§a LLM. Bá»™ dá»¯ liá»‡u nÃ y bao gá»“m 29.362 máº«u trÃªn cÃ¡c "prompts" táº¥n cÃ´ng vÃ  tá»« chá»‘i. RedBench sá»­ dá»¥ng má»™t phÃ¢n loáº¡i tiÃªu chuáº©n vá»›i 22 loáº¡i rá»§i ro vÃ  19 miá»n, cho phÃ©p Ä‘Ã¡nh giÃ¡ nháº¥t quÃ¡n vÃ  toÃ n diá»‡n. QuÃ¡ trÃ¬nh chÃº thÃ­ch (annotation) cÃ¡c loáº¡i rá»§i ro vÃ  miá»n sá»­ dá»¥ng quy trÃ¬nh bÃ¡n tá»± Ä‘á»™ng káº¿t há»£p hiá»‡u quáº£ cá»§a cÃ¡c LLM hiá»‡n Ä‘áº¡i vá»›i Ä‘á»™ tin cáº­y cá»§a sá»± giÃ¡m sÃ¡t cá»§a con ngÆ°á»i.

### Main Results:
*   RedBench lÃ  má»™t bá»™ dá»¯ liá»‡u phá»• quÃ¡t cá»§ng cá»‘ 37 bá»™ dá»¯ liá»‡u "red teaming" hiá»‡n cÃ³, cung cáº¥p phÃ¢n loáº¡i rá»§i ro nháº¥t quÃ¡n vÃ  bao phá»§ toÃ n diá»‡n cÃ¡c miá»n Ä‘á»ƒ cho phÃ©p Ä‘Ã¡nh giÃ¡ LLM tiÃªu chuáº©n.
*   BÃ i nghiÃªn cá»©u cung cáº¥p phÃ¢n tÃ­ch chi tiáº¿t cÃ¡c loáº¡i rá»§i ro vÃ  miá»n trong cÃ¡c bá»™ dá»¯ liá»‡u hiá»‡n cÃ³, lÃ m ná»•i báº­t nhá»¯ng khoáº£ng trá»‘ng vÃ  cÆ¡ há»™i cho nghiÃªn cá»©u "red teaming" trong tÆ°Æ¡ng lai.
*   Thiáº¿t láº­p cÃ¡c Ä‘Æ°á»ng cÆ¡ sá»Ÿ Ä‘Ã¡nh giÃ¡ cho cÃ¡c LLM hiá»‡n Ä‘áº¡i nhÆ° Qwen2.5, Llama 3.1 vÃ  Gemma2, Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ­nh bá»n vá»¯ng cá»§a chÃºng trÆ°á»›c cÃ¡c "prompts" Ä‘á»‘i khÃ¡ng vÃ  thÃºc Ä‘áº©y cÃ¡c nghiÃªn cá»©u so sÃ¡nh.
*   Bá»™ dá»¯ liá»‡u RedBench vÃ  mÃ£ Ä‘Ã¡nh giÃ¡ liÃªn quan Ä‘Æ°á»£c cung cáº¥p mÃ£ nguá»“n má»Ÿ Ä‘á»ƒ thÃºc Ä‘áº©y tÃ­nh minh báº¡ch, kháº£ nÄƒng tÃ¡i táº¡o vÃ  sá»± phÃ¡t triá»ƒn cá»§a cá»™ng Ä‘á»“ng trong lÄ©nh vá»±c "red teaming" LLM.

### Conclusion & Future Works:
Nhá»¯ng Ä‘Ã³ng gÃ³p cá»§a RedBench táº¡o Ä‘iá»u kiá»‡n thuáº­n lá»£i cho cÃ¡c so sÃ¡nh máº¡nh máº½, thÃºc Ä‘áº©y nghiÃªn cá»©u trong tÆ°Æ¡ng lai vÃ  khuyáº¿n khÃ­ch sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c LLM an toÃ n vÃ  Ä‘Ã¡ng tin cáº­y Ä‘á»ƒ triá»ƒn khai trong tháº¿ giá»›i thá»±c.

### Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u tÃ¡c Ä‘á»™ng cá»§a viá»‡c tinh chá»‰nh LLM báº±ng cÃ¡c máº«u "refusal prompts" tá»« RedBench Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng tá»« chá»‘i cÃ¡c yÃªu cáº§u khÃ´ng phÃ¹ há»£p mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c yÃªu cáº§u há»£p phÃ¡p.
*   PhÃ¢n tÃ­ch sá»± tiáº¿n hÃ³a cá»§a cÃ¡c lá»— há»•ng LLM qua cÃ¡c phiÃªn báº£n mÃ´ hÃ¬nh khÃ¡c nhau báº±ng cÃ¡ch sá»­ dá»¥ng RedBench lÃ m cÃ´ng cá»¥ Ä‘Ã¡nh giÃ¡ nháº¥t quÃ¡n.
*   KhÃ¡m phÃ¡ cÃ¡c ká»¹ thuáº­t táº¡o "adversarial prompts" má»›i dá»±a trÃªn cáº¥u trÃºc phÃ¢n loáº¡i rá»§i ro vÃ  miá»n Ä‘a dáº¡ng cá»§a RedBench.
#### 2. Patent:
*   Há»‡ thá»‘ng kiá»ƒm Ä‘á»‹nh an toÃ n LLM tÃ­ch há»£p trÃªn Ä‘iá»‡n thoáº¡i, tá»± Ä‘á»™ng quÃ©t vÃ  phÃ¢n loáº¡i cÃ¡c "prompts" cá»§a ngÆ°á»i dÃ¹ng dá»±a trÃªn phÃ¢n loáº¡i rá»§i ro cá»§a RedBench trÆ°á»›c khi gá»­i Ä‘áº¿n LLM.
*   á»¨ng dá»¥ng di Ä‘á»™ng sá»­ dá»¥ng bá»™ dá»¯ liá»‡u RedBench Ä‘á»ƒ cung cáº¥p huáº¥n luyá»‡n tÆ°Æ¡ng tÃ¡c cho ngÆ°á»i dÃ¹ng vá» cÃ¡ch xÃ¢y dá»±ng "prompts" an toÃ n vÃ  hiá»‡u quáº£, giáº£m thiá»ƒu rá»§i ro tá»« cÃ¡c pháº£n há»“i khÃ´ng mong muá»‘n cá»§a LLM.
*   Giáº£i phÃ¡p pháº§n má»m trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng Ä‘á»ƒ giÃ¡m sÃ¡t vÃ  bÃ¡o cÃ¡o cÃ¡c lá»— há»•ng LLM theo thá»i gian thá»±c, sá»­ dá»¥ng cÃ¡c máº«u "attack" vÃ  "refusal" cá»§a RedBench Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vÃ  cáº£nh bÃ¡o vá» cÃ¡c hÃ nh vi khÃ´ng an toÃ n.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03699](https://huggingface.co/papers/2601.03699) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03699](https://arxiv.org/abs/2601.03699) |
| PDF Download | [https://arxiv.org/pdf/2601.03699.pdf](https://arxiv.org/pdf/2601.03699.pdf) |
| Github Repository | [https://github.com/knoveleng/redeval](https://github.com/knoveleng/redeval) |

--- 

## 13. Why LLMs Aren't Scientists Yet: Lessons from Four Autonomous Research Attempts

**TÃ¡c giáº£:** Dhruv Trehan, Paras Chopra

**Xuáº¥t báº£n lÃºc:** 2026-01-06

**Tag:** LLM Agents, Autonomous Research, AI Scientist, Machine Learning, Failure Modes
### Main Problem:
BÃ i bÃ¡o nghiÃªn cá»©u kháº£ nÄƒng cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) hiá»‡n Ä‘áº¡i trong viá»‡c tá»± Ä‘á»™ng hoÃ n thÃ nh quy trÃ¬nh nghiÃªn cá»©u khoa há»c tá»« Ã½ tÆ°á»Ÿng Ä‘áº¿n bÃ i bÃ¡o khoa há»c, vá»›i má»©c Ä‘á»™ tá»± chá»§ cao vÃ  sá»± can thiá»‡p tá»‘i thiá»ƒu cá»§a con ngÆ°á»i. Váº¥n Ä‘á» cá»‘t lÃµi lÃ  liá»‡u LLM cÃ³ thá»ƒ hoáº¡t Ä‘á»™ng nhÆ° cÃ¡c nhÃ  khoa há»c Ä‘á»™c láº­p hay khÃ´ng, Ä‘áº·c biá»‡t khi cÃ¡c há»‡ thá»‘ng AI-Scientist hiá»‡n cÃ³ thÆ°á»ng yÃªu cáº§u sá»± Ä‘á»‹nh nghÄ©a trÆ°á»›c vá» quy trÃ¬nh lÃ m viá»‡c hoáº·c cÃ¡c sá»‘ liá»‡u xÃ¡c minh cá»¥ thá»ƒ tá»« con ngÆ°á»i.

### Main Idea:
CÃ¡c nhÃ  nghiÃªn cá»©u Ä‘Ã£ phÃ¡t triá»ƒn má»™t há»‡ thá»‘ng gá»“m sÃ¡u tÃ¡c tá»­ LLM riÃªng biá»‡t, má»—i tÃ¡c tá»­ phá»¥ trÃ¡ch má»™t giai Ä‘oáº¡n trong quy trÃ¬nh nghiÃªn cá»©u khoa há»c (tá»« táº¡o Ã½ tÆ°á»Ÿng, táº¡o giáº£ thuyáº¿t, lÃªn káº¿ hoáº¡ch thÃ­ nghiá»‡m, Ä‘Ã¡nh giÃ¡ káº¿t quáº£, sá»­a Ä‘á»•i, Ä‘áº¿n phÃ¡c tháº£o bÃ i bÃ¡o). Há»‡ thá»‘ng nÃ y chá»§ yáº¿u sá»­ dá»¥ng Gemini 2.5 Pro cho cÃ¡c tÃ¡c tá»­ vÃ  Claude Code Ä‘á»ƒ thá»±c hiá»‡n thÃ­ nghiá»‡m vÃ  viáº¿t bÃ i. Má»¥c tiÃªu lÃ  khÃ¡m phÃ¡ giá»›i háº¡n cá»§a LLM mÃ  khÃ´ng cáº§n nhiá»u cáº¥u trÃºc Ä‘á»‹nh sáºµn hoáº·c Ä‘áº§u vÃ o chuyÃªn sÃ¢u tá»« con ngÆ°á»i, sá»­ dá»¥ng má»™t kho lÆ°u trá»¯ chung Ä‘á»ƒ duy trÃ¬ ngá»¯ cáº£nh.

### Main Results:
Trong bá»‘n ná»— lá»±c nghiÃªn cá»©u tá»± Ä‘á»™ng hoÃ n toÃ n, ba ná»— lá»±c Ä‘Ã£ tháº¥t báº¡i trong giai Ä‘oáº¡n triá»ƒn khai hoáº·c Ä‘Ã¡nh giÃ¡. Má»™t ná»— lá»±c duy nháº¥t (AS-1, trong lÄ©nh vá»±c AI Safety) Ä‘Ã£ thÃ nh cÃ´ng vÃ  Ä‘Æ°á»£c cháº¥p nháº­n táº¡i há»™i nghá»‹ Agents4Science 2025, nÆ¡i há»‡ thá»‘ng AI Ä‘Æ°á»£c yÃªu cáº§u lÃ  tÃ¡c giáº£ chÃ­nh vÃ  vÆ°á»£t qua cáº£ Ä‘Ã¡nh giÃ¡ cá»§a con ngÆ°á»i vÃ  nhiá»u AI.
BÃ i bÃ¡o Ä‘Ã£ xÃ¡c Ä‘á»‹nh sÃ¡u cháº¿ Ä‘á»™ tháº¥t báº¡i láº·p Ä‘i láº·p láº¡i: thiÃªn vá»‹ dá»¯ liá»‡u huáº¥n luyá»‡n máº·c Ä‘á»‹nh, sai lá»‡ch thá»±c hiá»‡n dÆ°á»›i Ã¡p lá»±c, suy giáº£m bá»™ nhá»› vÃ  ngá»¯ cáº£nh trong cÃ¡c tÃ¡c vá»¥ dÃ i háº¡n, quÃ¡ hÆ°ng pháº¥n tuyÃªn bá»‘ thÃ nh cÃ´ng, thiáº¿u trÃ­ tuá»‡ chuyÃªn mÃ´n vÃ  gu khoa há»c yáº¿u trong thiáº¿t káº¿ thÃ­ nghiá»‡m. Äá»‘i vá»›i ná»— lá»±c thÃ nh cÃ´ng, há»‡ thá»‘ng Ä‘áº¡t má»©c Ä‘á»™ tá»± chá»§ ráº¥t cao (trÃªn 95% AI) trong thiáº¿t káº¿ thÃ­ nghiá»‡m, thá»±c thi vÃ  viáº¿t bÃ i, vá»›i sá»± can thiá»‡p cá»§a con ngÆ°á»i chá»§ yáº¿u á»Ÿ giai Ä‘oáº¡n phÃ¡t triá»ƒn giáº£ thuyáº¿t ban Ä‘áº§u.

### Conclusion & Future Works:
BÃ i bÃ¡o káº¿t luáº­n báº±ng viá»‡c tháº£o luáº­n vá» bá»‘n nguyÃªn táº¯c thiáº¿t káº¿ cho cÃ¡c há»‡ thá»‘ng AI-Scientist máº¡nh máº½ hÆ¡n vÃ  nhá»¯ng Ã½ nghÄ©a Ä‘á»‘i vá»›i khÃ¡m phÃ¡ khoa há»c tá»± Ä‘á»™ng. CÃ¡c tÃ¡c giáº£ cÅ©ng cÃ´ng bá»‘ táº¥t cáº£ cÃ¡c cÃ¢u lá»‡nh, táº¡o tÃ¡c vÃ  Ä‘áº§u ra Ä‘á»ƒ há»— trá»£ nghiÃªn cá»©u trong tÆ°Æ¡ng lai. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo sáº½ táº­p trung vÃ o viá»‡c giáº£i quyáº¿t sÃ¡u cháº¿ Ä‘á»™ tháº¥t báº¡i Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ tin cáº­y vÃ  kháº£ nÄƒng tá»± chá»§ cá»§a cÃ¡c há»‡ thá»‘ng AI-Scientist.

### Brainstorming Space:
#### 1. Publish Papers:
1. NghiÃªn cá»©u vá» cÃ¡c chiáº¿n lÆ°á»£c giáº£m thiá»ƒu thiÃªn vá»‹ dá»¯ liá»‡u huáº¥n luyá»‡n trong cÃ¡c há»‡ thá»‘ng tÃ¡c tá»­ LLM tá»± Ä‘á»™ng Ä‘á»ƒ cáº£i thiá»‡n tÃ­nh má»›i vÃ  Ä‘á»™ chÃ­nh xÃ¡c cá»§a káº¿t quáº£ nghiÃªn cá»©u.
2. PhÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p quáº£n lÃ½ bá»™ nhá»› vÃ  ngá»¯ cáº£nh Ä‘á»™ng cho cÃ¡c tÃ¡c vá»¥ nghiÃªn cá»©u dÃ i háº¡n, táº­p trung vÃ o cÆ¡ cháº¿ truy xuáº¥t thÃ´ng tin chá»n lá»c vÃ  tÃ³m táº¯t ngá»¯ cáº£nh tá»± Ä‘á»™ng.
3. Thiáº¿t káº¿ cÃ¡c chá»‰ sá»‘ vÃ  quy trÃ¬nh Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng Ä‘á»ƒ Ä‘o lÆ°á»ng "gu khoa há»c" vÃ  ngÄƒn cháº·n viá»‡c tuyÃªn bá»‘ thÃ nh cÃ´ng quÃ¡ sá»›m trong cÃ¡c há»‡ thá»‘ng nghiÃªn cá»©u AI tá»± chá»§.

#### 2. Patent:
1. Há»‡ thá»‘ng trá»£ lÃ½ nghiÃªn cá»©u AI tá»± Ä‘á»™ng trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng, cho phÃ©p ngÆ°á»i dÃ¹ng nháº­p Ã½ tÆ°á»Ÿng vÃ  nháº­n cÃ¡c káº¿ hoáº¡ch thÃ­ nghiá»‡m, mÃ£ nguá»“n, vÃ  báº£n nhÃ¡p bÃ i bÃ¡o hoÃ n chá»‰nh, sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh LLM Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho thiáº¿t bá»‹ di Ä‘á»™ng.
2. Giao diá»‡n á»©ng dá»¥ng di Ä‘á»™ng tÃ­ch há»£p cÆ¡ cháº¿ pháº£n há»“i ngá»¯ cáº£nh thÃ´ng minh, giÃºp ngÆ°á»i dÃ¹ng Ä‘iá»u chá»‰nh hÃ nh vi cá»§a cÃ¡c tÃ¡c tá»­ LLM trÃªn Ä‘iá»‡n thoáº¡i Ä‘á»ƒ trÃ¡nh thiÃªn vá»‹ dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  sai lá»‡ch thá»±c hiá»‡n trong cÃ¡c dá»± Ã¡n nghiÃªn cá»©u cÃ¡ nhÃ¢n.
3. Há»‡ thá»‘ng quáº£n lÃ½ dá»± Ã¡n nghiÃªn cá»©u AI trÃªn Ä‘Ã¡m mÃ¢y vá»›i á»©ng dá»¥ng di Ä‘á»™ng, tá»± Ä‘á»™ng theo dÃµi tiáº¿n Ä‘á»™, phÃ¡t hiá»‡n cÃ¡c cháº¿ Ä‘á»™ lá»—i tiá»m áº©n (nhÆ° suy giáº£m bá»™ nhá»›) vÃ  Ä‘á» xuáº¥t Ä‘iá»u chá»‰nh cho cÃ¡c tÃ¡c vá»¥ nghiÃªn cá»©u dÃ i háº¡n trá»±c tiáº¿p tá»« Ä‘iá»‡n thoáº¡i cá»§a ngÆ°á»i dÃ¹ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03315](https://huggingface.co/papers/2601.03315) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03315](https://arxiv.org/abs/2601.03315) |
| PDF Download | [https://arxiv.org/pdf/2601.03315.pdf](https://arxiv.org/pdf/2601.03315.pdf) |
| Github Repository | N/A |

--- 

## 14. ThinkRL-Edit: Thinking in Reinforcement Learning for Reasoning-Centric Image Editing

**TÃ¡c giáº£:** Hengjia Li, Liming Jiang, Qing Yan, Yizhi Song, Hao Kang, Zichuan Liu, Xin Lu, Boxi Wu, Deng Cai

**Xuáº¥t báº£n lÃºc:** 2026-01-06

**Tag:** Reinforcement Learning (RL), Image Editing, Reasoning, Chain-of-Thought (CoT), Vision-Language Models (VLMs), Generative Models, Decoupled Optimization.

### Main Problem:
Máº·c dÃ¹ cÃ¡c mÃ´ hÃ¬nh sinh áº£nh Ä‘a phÆ°Æ¡ng thá»©c Ä‘Ã£ cÃ³ nhá»¯ng tiáº¿n bá»™ nhanh chÃ³ng trong chá»‰nh sá»­a áº£nh dá»±a trÃªn hÆ°á»›ng dáº«n, kháº£ nÄƒng suy luáº­n thá»‹ giÃ¡c cÆ¡ báº£n cá»§a chÃºng cÃ²n háº¡n cháº¿, dáº«n Ä‘áº¿n hiá»‡u suáº¥t chÆ°a tá»‘i Æ°u trÃªn cÃ¡c tÃ¡c vá»¥ chá»‰nh sá»­a yÃªu cáº§u suy luáº­n sÃ¢u. CÃ¡c phÆ°Æ¡ng phÃ¡p Há»c tÄƒng cÆ°á»ng (RL) hiá»‡n cÃ³ Ä‘á»ƒ cáº£i thiá»‡n cháº¥t lÆ°á»£ng chá»‰nh sá»­a áº£nh Ä‘á»‘i máº·t vá»›i ba thÃ¡ch thá»©c chÃ­nh: (1) khÃ¡m phÃ¡ suy luáº­n bá»‹ giá»›i háº¡n trong sá»± ngáº«u nhiÃªn cá»§a quÃ¡ trÃ¬nh khá»­ nhiá»…u, (2) tá»•ng há»£p pháº§n thÆ°á»Ÿng bá»‹ thiÃªn vá»‹, vÃ  (3) pháº§n thÆ°á»Ÿng hÆ°á»›ng dáº«n dá»±a trÃªn VLM khÃ´ng á»•n Ä‘á»‹nh.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t **ThinkRL-Edit**, má»™t khung RL táº­p trung vÃ o suy luáº­n, tÃ¡ch rá»i quÃ¡ trÃ¬nh suy luáº­n thá»‹ giÃ¡c khá»i quÃ¡ trÃ¬nh tá»•ng há»£p áº£nh vÃ  má»Ÿ rá»™ng khÃ¡m phÃ¡ suy luáº­n vÆ°á»£t ra ngoÃ i khá»­ nhiá»…u. Cá»¥ thá»ƒ:
1.  Giá»›i thiá»‡u **láº¥y máº«u suy luáº­n dá»±a trÃªn Chain-of-Thought (CoT)** vá»›i cÃ¡c giai Ä‘oáº¡n láº­p káº¿ hoáº¡ch (planning) vÃ  pháº£n Ã¡nh (reflection) trÆ°á»›c khi táº¡o áº£nh trong quÃ¡ trÃ¬nh láº¥y máº«u trá»±c tuyáº¿n. Äiá»u nÃ y buá»™c mÃ´ hÃ¬nh khÃ¡m phÃ¡ nhiá»u giáº£ thuyáº¿t ngá»¯ nghÄ©a vÃ  xÃ¡c nháº­n tÃ­nh há»£p lÃ½ cá»§a chÃºng trÆ°á»›c khi Ä‘Æ°a ra káº¿t quáº£ thá»‹ giÃ¡c.
2.  Äá» xuáº¥t má»™t **chiáº¿n lÆ°á»£c nhÃ³m Æ°u tiÃªn chuá»—i khÃ´ng thiÃªn vá»‹** trÃªn nhiá»u chiá»u pháº§n thÆ°á»Ÿng Ä‘á»ƒ trÃ¡nh tháº¥t báº¡i cá»§a viá»‡c tá»•ng há»£p pháº§n thÆ°á»Ÿng cÃ³ trá»ng sá»‘. Thay vÃ¬ gá»™p pháº§n thÆ°á»Ÿng thÃ nh má»™t giÃ¡ trá»‹ vÃ´ hÆ°á»›ng, phÆ°Æ¡ng phÃ¡p nÃ y sáº¯p xáº¿p chung cÃ¡c chuá»—i Ä‘Æ°á»£c láº¥y máº«u theo tá»«ng nhÃ³m vÃ  chá»‰ cáº­p nháº­t gradient tá»« cÃ¡c chuá»—i táº¡o thÃ nh má»™t thá»© tá»± tá»•ng thá»ƒ nháº¥t quÃ¡n.
3.  Thay tháº¿ Ä‘iá»ƒm sá»‘ VLM dá»±a trÃªn khoáº£ng giÃ¡ trá»‹ báº±ng má»™t **danh sÃ¡ch kiá»ƒm tra nhá»‹ phÃ¢n** Ä‘á»ƒ cÃ³ pháº§n thÆ°á»Ÿng chÃ­nh xÃ¡c hÆ¡n, Ã­t biáº¿n Ä‘á»™ng hÆ¡n vÃ  dá»… hiá»ƒu hÆ¡n cho cÃ¡c tÃ¡c vá»¥ suy luáº­n phá»©c táº¡p. CÃ¡c cÃ¢u há»i nhá»‹ phÃ¢n Ä‘Æ°á»£c suy ra tá»« áº£nh gá»‘c vÃ  lá»i nháº¯c, VLM tráº£ lá»i cÃ³/khÃ´ng, vÃ  sá»‘ lÆ°á»£ng "cÃ³" Ä‘Æ°á»£c dÃ¹ng lÃ m Ä‘iá»ƒm cÄƒn chá»‰nh.
4.  TÃ¡ch rá»i vÃ  tá»‘i Æ°u hÃ³a cÃ¡c module suy luáº­n, hiá»ƒu vÃ  táº¡o áº£nh Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng suy luáº­n mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng tá»•ng há»£p.

### Main Results:
PhÆ°Æ¡ng phÃ¡p nÃ y vÆ°á»£t trá»™i Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c cÃ´ng trÃ¬nh trÆ°á»›c Ä‘Ã¢y trong chá»‰nh sá»­a áº£nh táº­p trung vÃ o suy luáº­n, táº¡o ra cÃ¡c chá»‰nh sá»­a trung thÃ nh vá»›i hÆ°á»›ng dáº«n, máº¡ch láº¡c vá» máº·t thá»‹ giÃ¡c vÃ  cÃ³ cÆ¡ sá»Ÿ ngá»¯ nghÄ©a vá»¯ng cháº¯c. CÃ¡c thÃ­ nghiá»‡m cho tháº¥y pháº§n thÆ°á»Ÿng suy luáº­n chi tiáº¿t (danh sÃ¡ch kiá»ƒm tra nhá»‹ phÃ¢n) mang láº¡i káº¿t quáº£ chÃ­nh xÃ¡c hÆ¡n, Ä‘á»™ biáº¿n Ä‘á»™ng tháº¥p hÆ¡n vÃ  dá»… giáº£i thÃ­ch hÆ¡n.

### Conclusion & Future Works:
**Conclusion:** ThinkRL-Edit lÃ  má»™t khung RL hiá»‡u quáº£ cho chá»‰nh sá»­a áº£nh yÃªu cáº§u suy luáº­n, giáº£i quyáº¿t cÃ¡c háº¡n cháº¿ cá»§a cÃ¡c phÆ°Æ¡ng phÃ¡p trÆ°á»›c Ä‘Ã³ báº±ng cÃ¡ch tÃ¡ch rá»i suy luáº­n vÃ  tá»•ng há»£p, sá»­ dá»¥ng CoT Ä‘á»ƒ má»Ÿ rá»™ng khÃ¡m phÃ¡, Ã¡p dá»¥ng chiáº¿n lÆ°á»£c nhÃ³m Æ°u tiÃªn chuá»—i khÃ´ng thiÃªn vá»‹ vÃ  sá»­ dá»¥ng danh sÃ¡ch kiá»ƒm tra nhá»‹ phÃ¢n cho pháº§n thÆ°á»Ÿng VLM. Äiá»u nÃ y dáº«n Ä‘áº¿n cÃ¡c chá»‰nh sá»­a chÃ­nh xÃ¡c, máº¡ch láº¡c vÃ  cÃ³ cÆ¡ sá»Ÿ ngá»¯ nghÄ©a sÃ¢u sáº¯c.
**Future Works:** BÃ i bÃ¡o khÃ´ng Ä‘á» cáº­p cá»¥ thá»ƒ Ä‘áº¿n cÃ¡c hÆ°á»›ng nghiÃªn cá»©u trong tÆ°Æ¡ng lai trong pháº§n vÄƒn báº£n Ä‘Æ°á»£c trÃ­ch xuáº¥t.

### Brainstorming Space:
#### 1. Publish Papers:
*   Má»Ÿ rá»™ng khung suy luáº­n CoT Ä‘á»ƒ tÃ­ch há»£p pháº£n há»“i Ä‘a lÆ°á»£t hoáº·c tÆ°Æ¡ng tÃ¡c tá»« ngÆ°á»i dÃ¹ng, cho phÃ©p cÃ¡c ká»‹ch báº£n chá»‰nh sá»­a phá»©c táº¡p hÆ¡n vÃ  Ä‘iá»u chá»‰nh dá»±a trÃªn ngá»¯ cáº£nh.
*   NghiÃªn cá»©u á»©ng dá»¥ng phÆ°Æ¡ng phÃ¡p tÃ¡ch rá»i suy luáº­n-táº¡o áº£nh nÃ y cho cÃ¡c tÃ¡c vá»¥ Ä‘a phÆ°Æ¡ng thá»©c khÃ¡c nhÆ° chá»‰nh sá»­a video hoáº·c táº¡o cáº£nh 3D cÃ³ suy luáº­n khÃ´ng gian.
*   KhÃ¡m phÃ¡ cÃ¡c kiáº¿n trÃºc khÃ¡c cho module suy luáº­n, cÃ³ thá»ƒ tÃ­ch há»£p suy luáº­n biá»ƒu tÆ°á»£ng tiÃªn tiáº¿n hÆ¡n hoáº·c Ä‘á»“ thá»‹ tri thá»©c Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng hiá»ƒu ngá»¯ nghÄ©a.

#### 2. Patent:
*   Há»‡ thá»‘ng chá»‰nh sá»­a hÃ¬nh áº£nh trÃªn thiáº¿t bá»‹ di Ä‘á»™ng sá»­ dá»¥ng há»c tÄƒng cÆ°á»ng vÃ  mÃ´ hÃ¬nh tÆ° duy chuá»—i suy luáº­n Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c chá»‰nh sá»­a hÃ¬nh áº£nh phá»©c táº¡p dá»±a trÃªn vÄƒn báº£n trÃªn Ä‘iá»‡n thoáº¡i.
*   PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a chá»‰nh sá»­a hÃ¬nh áº£nh trÃªn thiáº¿t bá»‹ di Ä‘á»™ng thÃ´ng qua danh sÃ¡ch kiá»ƒm tra nhá»‹ phÃ¢n Ä‘Æ°á»£c sinh ra bá»Ÿi VLM, giÃºp cung cáº¥p pháº§n thÆ°á»Ÿng á»•n Ä‘á»‹nh vÃ  chÃ­nh xÃ¡c cho cÃ¡c tÃ¡c vá»¥ suy luáº­n trÃªn Ä‘iá»‡n thoáº¡i.
*   CÃ´ng nghá»‡ tá»‘i Æ°u hÃ³a thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng cho chá»‰nh sá»­a áº£nh di Ä‘á»™ng, tÃ¡ch rá»i quÃ¡ trÃ¬nh suy luáº­n vÃ  táº¡o áº£nh, cho phÃ©p thiáº¿t bá»‹ Ä‘iá»‡n thoáº¡i khÃ¡m phÃ¡ nhiá»u giáº£ thuyáº¿t ngá»¯ nghÄ©a trÆ°á»›c khi thá»±c hiá»‡n chá»‰nh sá»­a hÃ¬nh áº£nh cuá»‘i cÃ¹ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03467](https://huggingface.co/papers/2601.03467) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03467](https://arxiv.org/abs/2601.03467) |
| PDF Download | [https://arxiv.org/pdf/2601.03467.pdf](https://arxiv.org/pdf/2601.03467.pdf) |
| Github Repository | N/A |

--- 

## 15. Enhancing Linguistic Competence of Language Models through Pre-training with Language Learning Tasks

**TÃ¡c giáº£:** Atsuki Yamaguchi, Maggie Mi, Nikolaos Aletras

**Xuáº¥t báº£n lÃºc:** 2026-01-06

**Tag:** Language Models, Pre-training, Linguistic Competence, Language Learning Tasks, L2T, Deep Learning.

### Main Problem:
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ (LMs) hiá»‡n táº¡i Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c báº±ng cÃ¡ch dá»± Ä‘oÃ¡n token tiáº¿p theo trÃªn cÃ¡c táº­p dá»¯ liá»‡u vÄƒn báº£n thÃ´. Máº·c dÃ¹ phÆ°Æ¡ng phÃ¡p nÃ y hiá»‡u quáº£ trong viá»‡c giÃºp cÃ¡c LM há»c Ä‘Æ°á»£c kiáº¿n thá»©c tháº¿ giá»›i vÃ  kháº£ nÄƒng suy luáº­n, nÃ³ khÃ´ng trá»±c tiáº¿p tá»‘i Æ°u hÃ³a nÄƒng lá»±c ngÃ´n ngá»¯, tá»©c lÃ  kháº£ nÄƒng hiá»ƒu vÃ  diá»…n giáº£i cÃ¡c hiá»‡n tÆ°á»£ng ngÃ´n ngá»¯ Ä‘a dáº¡ng. Äiá»u nÃ y khiáº¿n cÃ¡c LM thÆ°á»ng chá»‰ báº¯t chÆ°á»›c cÃ¡c máº«u bá» máº·t mÃ  khÃ´ng thá»±c sá»± náº¯m báº¯t Ä‘Æ°á»£c cáº¥u trÃºc ngÃ´n ngá»¯ cÆ¡ báº£n.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t L2T (Language Learning Tasks), má»™t framework huáº¥n luyá»‡n trÆ°á»›c tÃ­ch há»£p cÃ¡c nhiá»‡m vá»¥ há»c ngÃ´n ngá»¯ song song vá»›i viá»‡c dá»± Ä‘oÃ¡n token tiÃªu chuáº©n. L2T Ä‘Æ°á»£c láº¥y cáº£m há»©ng tá»« quÃ¡ trÃ¬nh tiáº¿p thu ngÃ´n ngá»¯ á»Ÿ con ngÆ°á»i, chuyá»ƒn Ä‘á»•i vÄƒn báº£n thÃ´ thÃ nh cÃ¡c cáº·p input-output cÃ³ cáº¥u trÃºc Ä‘á»ƒ cung cáº¥p sá»± kÃ­ch thÃ­ch ngÃ´n ngá»¯ rÃµ rÃ ng. Framework nÃ y bao gá»“m 14 nhiá»‡m vá»¥ há»c ngÃ´n ngá»¯ Ä‘a dáº¡ng á»Ÿ bá»‘n cáº¥p Ä‘á»™ ngá»¯ phÃ¡p (kÃ½ tá»±, tá»«, cÃ¢u vÃ  diá»…n ngÃ´n), Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ khuyáº¿n khÃ­ch sá»± phÃ¡t triá»ƒn cÃ¡c biá»ƒu diá»…n cÃ³ cáº¥u trÃºc vÆ°á»£t ra ngoÃ i sá»± xuáº¥t hiá»‡n Ä‘á»“ng thá»i bá» máº·t. Báº±ng cÃ¡ch huáº¥n luyá»‡n LMs trÃªn há»—n há»£p dá»¯ liá»‡u L2T vÃ  vÄƒn báº£n thÃ´, má»¥c tiÃªu lÃ  cáº£i thiá»‡n hiá»‡u suáº¥t tá»•ng thá»ƒ cá»§a mÃ´ hÃ¬nh trÃªn cÃ¡c benchmark nÄƒng lá»±c ngÃ´n ngá»¯ vÃ  tÄƒng tá»‘c quÃ¡ trÃ¬nh nÃ y, trong khi váº«n duy trÃ¬ hiá»‡u suáº¥t cáº¡nh tranh trÃªn cÃ¡c nhiá»‡m vá»¥ suy luáº­n chung.

### Main Results:
- Framework L2T cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ nÄƒng lá»±c ngÃ´n ngá»¯, Ä‘áº¡t má»©c tÄƒng trung bÃ¬nh 2.8% vÃ  lÃªn Ä‘áº¿n 11.3% trÃªn má»™t sá»‘ hiá»‡n tÆ°á»£ng ngÃ´n ngá»¯ cá»¥ thá»ƒ khi Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ báº±ng benchmark BLiMP.
- CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng L2T vÆ°á»£t trá»™i hÆ¡n cÃ¡c baseline chá»‰ dÃ¹ng vÄƒn báº£n thÃ´ trong cáº£ hai ká»‹ch báº£n dá»¯ liá»‡u (Disjoint vÃ  Shared) vÃ  á»Ÿ cáº£ hai quy mÃ´ mÃ´ hÃ¬nh (500M vÃ  1B tham sá»‘). Äiá»u nÃ y cho tháº¥y ráº±ng nÄƒng lá»±c ngÃ´n ngá»¯ phá»¥ thuá»™c vÃ o sá»± Ä‘a dáº¡ng cá»§a cÃ¡c tÃ­n hiá»‡u Ä‘Æ°á»£c Ã¡p dá»¥ng trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n chá»© khÃ´ng chá»‰ riÃªng khá»‘i lÆ°á»£ng dá»¯ liá»‡u.
- CÃ¡c nhiá»‡m vá»¥ L2T Ä‘áº·c biá»‡t hiá»‡u quáº£ trong viá»‡c cáº£i thiá»‡n cÃ¡c hiá»‡u á»©ng Äáº£o (Island effects) vá»›i má»©c tÄƒng tá»« 6.9 Ä‘áº¿n 11.3 Ä‘iá»ƒm.
- L2T duy trÃ¬ hiá»‡u suáº¥t cáº¡nh tranh trÃªn cÃ¡c benchmark suy luáº­n chung (bao gá»“m Reading Comprehension, Commonsense Reasoning vÃ  Language Modeling), cho tháº¥y cÃ¡c nhiá»‡m vá»¥ há»c ngÃ´n ngá»¯ bá»• sung khÃ´ng lÃ m suy giáº£m kháº£ nÄƒng tá»•ng quÃ¡t cá»§a mÃ´ hÃ¬nh.

### Conclusion & Future Works:
Káº¿t luáº­n chÃ­nh lÃ  viá»‡c tÃ­ch há»£p cÃ¡c nhiá»‡m vá»¥ há»c ngÃ´n ngá»¯ trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n trÆ°á»›c lÃ  má»™t phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ Ä‘á»ƒ nÃ¢ng cao nÄƒng lá»±c ngÃ´n ngá»¯ cá»§a cÃ¡c mÃ´ hÃ¬nh mÃ  váº«n duy trÃ¬ cÃ¡c kháº£ nÄƒng tá»•ng quÃ¡t cá»§a chÃºng. BÃ i bÃ¡o nháº¥n máº¡nh ráº±ng sá»± Ä‘a dáº¡ng cá»§a cÃ¡c tÃ­n hiá»‡u huáº¥n luyá»‡n lÃ  yáº¿u tá»‘ quan trá»ng Ä‘á»‘i vá»›i nÄƒng lá»±c ngÃ´n ngá»¯. Äá»‘i vá»›i cÃ¡c cÃ´ng viá»‡c trong tÆ°Æ¡ng lai, cÃ¡c tÃ¡c giáº£ gá»£i Ã½ ráº±ng cÃ¡c hiá»‡n tÆ°á»£ng ngÃ´n ngá»¯ phá»©c táº¡p hÆ¡n, nhÆ° Filler-Gap dependencies, cÃ³ thá»ƒ Ä‘Ã²i há»i cÃ¡c má»¥c tiÃªu cáº¥p Ä‘á»™ diá»…n ngÃ´n cÃ³ má»¥c tiÃªu cá»¥ thá»ƒ hÆ¡n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ.

### Brainstorming Space:
#### 1. Publish Papers:
- NghiÃªn cá»©u tÃ¡c Ä‘á»™ng cá»§a viá»‡c Ä‘iá»u chá»‰nh cÆ°á»ng Ä‘á»™ vÃ  táº§n suáº¥t cá»§a cÃ¡c nhiá»‡m vá»¥ há»c ngÃ´n ngá»¯ trong framework L2T Ä‘á»ƒ tÃ¬m ra cáº¥u hÃ¬nh tá»‘i Æ°u cho tá»«ng cáº¥p Ä‘á»™ nÄƒng lá»±c ngÃ´n ngá»¯.
- Má»Ÿ rá»™ng framework L2T Ä‘á»ƒ há»— trá»£ cÃ¡c ngÃ´n ngá»¯ Ã­t tÃ i nguyÃªn hoáº·c ngÃ´n ngá»¯ cÃ³ cáº¥u trÃºc ngá»¯ phÃ¡p phá»©c táº¡p hÆ¡n, Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a nÃ³ trong mÃ´i trÆ°á»ng Ä‘a ngÃ´n ngá»¯.
- KhÃ¡m phÃ¡ sá»± káº¿t há»£p cá»§a L2T vá»›i cÃ¡c ká»¹ thuáº­t huáº¥n luyá»‡n trÆ°á»›c khÃ¡c nhÆ° instruction tuning Ä‘á»ƒ táº¡o ra cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ vá»«a cÃ³ nÄƒng lá»±c ngÃ´n ngá»¯ sÃ¢u sáº¯c vá»«a cÃ³ kháº£ nÄƒng tuÃ¢n thá»§ hÆ°á»›ng dáº«n tá»‘t.

#### 2. Patent:
- Má»™t á»©ng dá»¥ng di Ä‘á»™ng tÃ­ch há»£p L2T Ä‘á»ƒ phÃ¢n tÃ­ch tin nháº¯n hoáº·c vÄƒn báº£n ngÆ°á»i dÃ¹ng nháº­p vÃ o, cung cáº¥p gá»£i Ã½ tá»©c thÃ¬ Ä‘á»ƒ cáº£i thiá»‡n ngá»¯ phÃ¡p vÃ  cáº¥u trÃºc cÃ¢u, giÃºp ngÆ°á»i dÃ¹ng há»c vÃ  cáº£i thiá»‡n ká»¹ nÄƒng viáº¿t tiáº¿ng Anh.
- Má»™t tÃ­nh nÄƒng "Kiá»ƒm tra Ngá»¯ phÃ¡p ThÃ´ng minh" trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, sá»­ dá»¥ng cÃ´ng nghá»‡ L2T Ä‘á»ƒ phÃ¡t hiá»‡n vÃ  sá»­a cÃ¡c lá»—i ngá»¯ phÃ¡p phá»©c táº¡p trong email hoáº·c tÃ i liá»‡u, Ä‘á»“ng thá»i giáº£i thÃ­ch lÃ½ do sá»­a chá»¯a cho ngÆ°á»i dÃ¹ng.
- Má»™t cÃ´ng cá»¥ luyá»‡n nÃ³i vÃ  há»c tá»« vá»±ng trÃªn Ä‘iá»‡n thoáº¡i dá»±a trÃªn L2T, tá»± Ä‘á»™ng táº¡o cÃ¡c bÃ i táº­p Ä‘iá»n vÃ o chá»— trá»‘ng hoáº·c sáº¯p xáº¿p láº¡i tá»« tá»« cÃ¡c Ä‘oáº¡n vÄƒn báº£n tin tá»©c hoáº·c sÃ¡ch ngÆ°á»i dÃ¹ng quan tÃ¢m, táº­p trung vÃ o viá»‡c cá»§ng cá»‘ cáº¥u trÃºc ngÃ´n ngá»¯.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03448](https://huggingface.co/papers/2601.03448) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03448](https://arxiv.org/abs/2601.03448) |
| PDF Download | [https://arxiv.org/pdf/2601.03448.pdf](https://arxiv.org/pdf/2601.03448.pdf) |
| Github Repository | [https://github.com/gucci-j/l2t](https://github.com/gucci-j/l2t) |

--- 

## 16. Pearmut: Human Evaluation of Translation Made Trivial

**TÃ¡c giáº£:** VilÃ©m Zouhar, Tom Kocmi

**Xuáº¥t báº£n lÃºc:** 2026-01-06

**Tag:** Human Evaluation, Machine Translation, Multilingual NLP, Annotation Platform, Pearmut, Evaluation Tools

### Main Problem:
Váº¥n Ä‘á» cá»‘t lÃµi mÃ  bÃ i bÃ¡o Ä‘á» cáº­p lÃ  viá»‡c Ä‘Ã¡nh giÃ¡ con ngÆ°á»i (human evaluation) lÃ  tiÃªu chuáº©n vÃ ng trong Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn Ä‘a ngÃ´n ngá»¯ (multilingual NLP), Ä‘áº·c biá»‡t lÃ  dá»‹ch mÃ¡y, nhÆ°ng thÆ°á»ng bá»‹ bá» qua hoáº·c thay tháº¿ báº±ng cÃ¡c chá»‰ sá»‘ tá»± Ä‘á»™ng. LÃ½ do lÃ  cÃ¡c cÃ´ng cá»¥ hiá»‡n cÃ³ ráº¥t phá»©c táº¡p, tá»‘n thá»i gian thiáº¿t láº­p, Ä‘Ã²i há»i nhiá»u ká»¹ thuáº­t vÃ  chi phÃ­ váº­n hÃ nh, cÅ©ng nhÆ° thiáº¿u tÃ­nh nháº¥t quÃ¡n vÃ  kháº£ nÄƒng tÃ¡i láº­p cÃ¡c giao thá»©c chÃº thÃ­ch. Äiá»u nÃ y dáº«n Ä‘áº¿n cÃ¡c káº¿t luáº­n sai lá»‡ch vÃ  lÃ m cháº­m tiáº¿n trÃ¬nh phÃ¡t triá»ƒn mÃ´ hÃ¬nh.

### Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u Pearmut, má»™t ná»n táº£ng nháº¹ nhÆ°ng Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng, giÃºp viá»‡c thiáº¿t láº­p vÃ  cháº¡y Ä‘Ã¡nh giÃ¡ con ngÆ°á»i tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i trá»Ÿ nÃªn dá»… dÃ ng nhÆ° Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng. Pearmut loáº¡i bá» cÃ¡c rÃ o cáº£n phá»• biáº¿n vÃ  há»— trá»£ Ä‘Ã¡nh giÃ¡ cÃ¡c tÃ¡c vá»¥ Ä‘a ngÃ´n ngá»¯, táº­p trung Ä‘áº·c biá»‡t vÃ o dá»‹ch mÃ¡y. Ná»n táº£ng nÃ y triá»ƒn khai cÃ¡c giao thá»©c Ä‘Ã¡nh giÃ¡ tiÃªu chuáº©n nhÆ° DA, ESA, MQM, Ä‘á»“ng thá»i cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘á»ƒ táº¡o máº«u cÃ¡c giao thá»©c má»›i. NÃ³ bao gá»“m cÃ¡c tÃ­nh nÄƒng nhÆ° ngá»¯ cáº£nh cáº¥p tÃ i liá»‡u, Ä‘Ã¡nh giÃ¡ tuyá»‡t Ä‘á»‘i vÃ  Ä‘á»‘i chiáº¿u, kiá»ƒm tra sá»± chÃº Ã½ (attention checks), chÃº thÃ­ch trÆ°á»›c ESAAI vÃ  cÃ¡c chiáº¿n lÆ°á»£c gÃ¡n nhiá»‡m vá»¥ dá»±a trÃªn há»c tÄ©nh hoáº·c há»c chá»§ Ä‘á»™ng. Pearmut nháº±m má»¥c Ä‘Ã­ch biáº¿n Ä‘Ã¡nh giÃ¡ con ngÆ°á»i trá»Ÿ thÃ nh má»™t thÃ nh pháº§n thá»±c táº¿, thÆ°á»ng xuyÃªn trong quÃ¡ trÃ¬nh phÃ¡t triá»ƒn vÃ  cháº©n Ä‘oÃ¡n mÃ´ hÃ¬nh.

### Main Results:
1.  **Dá»… thiáº¿t láº­p vÃ  sá»­ dá»¥ng:** NghiÃªn cá»©u Ä‘iá»ƒn hÃ¬nh vá»›i cÃ¡c nhÃ  nghiÃªn cá»©u cho tháº¥y Pearmut cÃ³ thá»i gian thiáº¿t láº­p ngáº¯n nháº¥t (trung bÃ¬nh 11 phÃºt) vÃ  nháº­n Ä‘Æ°á»£c Ä‘iá»ƒm cao nháº¥t vá» má»©c Ä‘á»™ dá»… sá»­ dá»¥ng (9.0), sá»± phÃ¹ há»£p cho dá»‹ch thuáº­t (9.0) vÃ  Ã½ Ä‘á»‹nh sá»­ dá»¥ng trong tÆ°Æ¡ng lai (9.0) so vá»›i cÃ¡c cÃ´ng cá»¥ cáº¡nh tranh.
2.  **Hiá»‡u quáº£ vÃ  cháº¥t lÆ°á»£ng Ä‘Ã¡nh giÃ¡:** NghiÃªn cá»©u Ä‘iá»ƒn hÃ¬nh vá»›i ngÆ°á»i chÃº thÃ­ch chá»‰ ra ráº±ng Pearmut cho phÃ©p chÃº thÃ­ch nhanh hÆ¡n (124.38 giÃ¢y/má»¥c) so vá»›i Appraise (144.86 giÃ¢y/má»¥c), Ä‘á»“ng thá»i duy trÃ¬ cháº¥t lÆ°á»£ng Ä‘Ã¡nh giÃ¡ tÆ°Æ¡ng Ä‘Æ°Æ¡ng (thá»ƒ hiá»‡n qua sá»± phÃ¢n tÃ¡ch Ä‘iá»ƒm mÃ´ hÃ¬nh vÃ  sá»‘ lÆ°á»£ng lá»—i Ä‘Æ°á»£c chÃº thÃ­ch). NgÆ°á»i chÃº thÃ­ch cÅ©ng bÃ y tá» sá»± hÃ i lÃ²ng cao hÆ¡n Ä‘Ã¡ng ká»ƒ vá»›i Pearmut vá» tá»‘c Ä‘á»™, Ä‘á»™ rÃµ rÃ ng vÃ  Ã­t ná»— lá»±c hÆ¡n.
3.  **TÆ°Æ¡ng thÃ­ch vá»›i quy trÃ¬nh lÃ m viá»‡c hiá»‡n Ä‘áº¡i:** Má»™t tÃ¡c nhÃ¢n mÃ£ hÃ³a LLM cÃ³ thá»ƒ tá»± Ä‘á»™ng viáº¿t script thiáº¿t láº­p cho Pearmut vÃ  LabelStudio, chá»©ng tá» kháº£ nÄƒng tÃ­ch há»£p tá»‘t cá»§a Pearmut vá»›i cÃ¡c quy trÃ¬nh ká»¹ thuáº­t hiá»‡n Ä‘áº¡i.

### Conclusion & Future Works:
Pearmut chuyá»ƒn Ä‘á»•i Ä‘Ã¡nh giÃ¡ con ngÆ°á»i tá»« má»™t ná»— lá»±c khÃ´ng thÆ°á»ng xuyÃªn thÃ nh má»™t thÃ nh pháº§n thiáº¿t yáº¿u vÃ  thÆ°á»ng xuyÃªn cá»§a quÃ¡ trÃ¬nh phÃ¡t triá»ƒn vÃ  cháº©n Ä‘oÃ¡n mÃ´ hÃ¬nh. NÃ³ loáº¡i bá» cÃ¡c rÃ o cáº£n phá»• biáº¿n, cung cáº¥p má»™t ná»n táº£ng hiá»‡u quáº£, dá»… sá»­ dá»¥ng, chuyÃªn biá»‡t cho Ä‘Ã¡nh giÃ¡ dá»‹ch mÃ¡y vÃ  cÃ¡c tÃ¡c vá»¥ Ä‘a ngÃ´n ngá»¯. CÃ¡c hÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ bao gá»“m viá»‡c má»Ÿ rá»™ng cÃ¡c giao thá»©c Ä‘Ã¡nh giÃ¡ má»›i, cáº£i thiá»‡n cÃ¡c chiáº¿n lÆ°á»£c gÃ¡n nhiá»‡m vá»¥ vÃ  tÃ­ch há»£p sÃ¢u hÆ¡n cÃ¡c cÃ´ng cá»¥ phÃ¢n tÃ­ch thá»‘ng kÃª Ä‘á»ƒ thÃºc Ä‘áº©y cÃ¡c thá»±c hÃ nh khoa há»c tiÃªu chuáº©n hÃ³a.

### Brainstorming Space:
#### 1. Publish Papers:
- NghiÃªn cá»©u so sÃ¡nh chi tiáº¿t cÃ¡c chiáº¿n lÆ°á»£c gÃ¡n nhiá»‡m vá»¥ khÃ¡c nhau (task-based, single-stream, dynamic) trong Pearmut vá» hiá»‡u quáº£ chi phÃ­ vÃ  Ä‘á»™ chÃ­nh xÃ¡c Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c ngÃ´n ngá»¯ Ã­t tÃ i nguyÃªn.
- KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs) Ä‘á»ƒ táº¡o ra cÃ¡c pre-annotation cho cÃ¡c giao thá»©c nhÆ° ESAAI, Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng cá»§a chÃºng Ä‘áº¿n tá»‘c Ä‘á»™ vÃ  cháº¥t lÆ°á»£ng chÃº thÃ­ch cá»§a con ngÆ°á»i.
- PhÃ¡t triá»ƒn vÃ  Ä‘Ã¡nh giÃ¡ má»™t giao thá»©c Ä‘Ã¡nh giÃ¡ má»›i trong Pearmut chuyÃªn biá»‡t cho cÃ¡c tÃ¡c vá»¥ Ä‘a phÆ°Æ¡ng thá»©c (vÃ­ dá»¥: dá»‹ch video hoáº·c Ã¢m thanh) vÃ  phÃ¢n tÃ­ch tÃ­nh kháº£ thi cá»§a nÃ³.
#### 2. Patent:
- Há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ báº£n dá»‹ch di Ä‘á»™ng tá»± Ä‘á»™ng, tÃ­ch há»£p Pearmut Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ thá»±c hiá»‡n Ä‘Ã¡nh giÃ¡ trá»±c tiáº¿p trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, bao gá»“m cáº£ cÃ¡c tÃ­nh nÄƒng nhÆ° chÃº thÃ­ch lá»—i báº±ng cá»­ chá»‰ cháº¡m vÃ  pháº£n há»“i giá»ng nÃ³i.
- CÃ´ng nghá»‡ "Adaptive Annotation Stream" cho phÃ©p ná»n táº£ng Ä‘Ã¡nh giÃ¡ dá»‹ch thuáº­t trÃªn Ä‘iá»‡n thoáº¡i tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh Ä‘á»™ khÃ³ vÃ  loáº¡i nhiá»‡m vá»¥ dá»±a trÃªn hiá»‡u suáº¥t vÃ  Ä‘á»™ tin cáº­y cá»§a ngÆ°á»i chÃº thÃ­ch theo thá»i gian thá»±c Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c phÃ¢n bá»• tÃ i nguyÃªn.
- á»¨ng dá»¥ng di Ä‘á»™ng "Multimodal Translation Quality Auditor" cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘Ã¡nh giÃ¡ cháº¥t lÆ°á»£ng dá»‹ch thuáº­t Ä‘a phÆ°Æ¡ng thá»©c (vÃ­ dá»¥: vÄƒn báº£n, Ã¢m thanh, hÃ¬nh áº£nh) trá»±c tiáº¿p trÃªn Ä‘iá»‡n thoáº¡i, sá»­ dá»¥ng cÃ¡c giao thá»©c tÃ¹y chá»‰nh vÃ  tÃ­nh nÄƒng kiá»ƒm tra sá»± chÃº Ã½ tÃ­ch há»£p Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng dá»¯ liá»‡u.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.02933](https://huggingface.co/papers/2601.02933) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.02933](https://arxiv.org/abs/2601.02933) |
| PDF Download | [https://arxiv.org/pdf/2601.02933.pdf](https://arxiv.org/pdf/2601.02933.pdf) |
| Github Repository | [https://github.com/zouharvi/pearmut](https://github.com/zouharvi/pearmut) |

--- 

## 17. Gen3R: 3D Scene Generation Meets Feed-Forward Reconstruction

**TÃ¡c giáº£:** Jiaxin Huang, Yuanbo Yang, Bangbang Yang, Lin Ma, Yuewen Ma, Yiyi Liao

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** 3D Scene Generation, Feed-Forward Reconstruction, Video Diffusion, Geometric Priors, Latent Space, VGGT.
### Main Problem:
CÃ¡c phÆ°Æ¡ng phÃ¡p táº¡o cáº£nh 3D hiá»‡n táº¡i thÆ°á»ng gáº·p pháº£i cÃ¡c háº¡n cháº¿ nhÆ° cáº¥u trÃºc hÃ¬nh há»c kÃ©m, chi phÃ­ tá»‘i Æ°u hÃ³a cao, hoáº·c khÃ³ khÄƒn trong viá»‡c há»c cÃ¡c biá»ƒu diá»…n hÃ¬nh há»c do sá»± khan hiáº¿m dá»¯ liá»‡u 3D quy mÃ´ lá»›n. Viá»‡c chá»‰ dá»±a vÃ o tÃ­n hiá»‡u 2D thÆ°á»ng dáº«n Ä‘áº¿n hÃ¬nh há»c dÆ°á»›i chuáº©n vÃ  cháº¥t lÆ°á»£ng táº¡o ra bá»‹ háº¡n cháº¿. CÃ¡c mÃ´ hÃ¬nh Diffusion video gáº§n Ä‘Ã¢y gáº·p thÃ¡ch thá»©c trong viá»‡c há»c má»™t khÃ´ng gian latent táº­p trung vÃ o hÃ¬nh há»c.

### Main Idea:
Gen3R lÃ  má»™t phÆ°Æ¡ng phÃ¡p báº¯c cáº§u cÃ¡c priors máº¡nh máº½ cá»§a cÃ¡c mÃ´ hÃ¬nh tÃ¡i táº¡o 3D ná»n táº£ng vÃ  cÃ¡c mÃ´ hÃ¬nh Diffusion video Ä‘á»ƒ táº¡o cáº£nh 3D. Ã tÆ°á»Ÿng chÃ­nh lÃ  tÃ¡i sá»­ dá»¥ng mÃ´ hÃ¬nh tÃ¡i táº¡o VGGT Ä‘á»ƒ táº¡o ra cÃ¡c latent hÃ¬nh há»c báº±ng cÃ¡ch huáº¥n luyá»‡n má»™t bá»™ adapter trÃªn cÃ¡c token cá»§a nÃ³. CÃ¡c latent hÃ¬nh há»c nÃ y Ä‘Æ°á»£c chuáº©n hÃ³a Ä‘á»ƒ cÄƒn chá»‰nh vá»›i cÃ¡c latent hÃ¬nh áº£nh (appearance latents) cá»§a cÃ¡c mÃ´ hÃ¬nh Diffusion video Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. Báº±ng cÃ¡ch táº¡o ra Ä‘á»“ng thá»i cÃ¡c latent Ä‘Æ°á»£c tÃ¡ch rá»i nhÆ°ng cÄƒn chá»‰nh nÃ y, Gen3R sáº£n xuáº¥t cáº£ video RGB vÃ  hÃ¬nh há»c 3D tÆ°Æ¡ng á»©ng, bao gá»“m tÆ° tháº¿ camera, báº£n Ä‘á»“ Ä‘á»™ sÃ¢u vÃ  Ä‘Ã¡m mÃ¢y Ä‘iá»ƒm toÃ n cá»¥c.

### Main Results:
*   Äáº¡t Ä‘Æ°á»£c káº¿t quáº£ tiÃªn tiáº¿n (state-of-the-art) trong táº¡o cáº£nh 3D cÃ³ Ä‘iá»u kiá»‡n tá»« má»™t hoáº·c nhiá»u hÃ¬nh áº£nh.
*   CÃ³ kháº£ nÄƒng táº¡o ra cÃ¡c video RGB nháº¥t quÃ¡n vá» máº·t thá»i gian vÃ  cÃ¡c Ä‘Ã¡m mÃ¢y Ä‘iá»ƒm 3D Ä‘Æ°á»£c cÄƒn chá»‰nh toÃ n cá»¥c.
*   PhÆ°Æ¡ng phÃ¡p nÃ y cÃ³ thá»ƒ nÃ¢ng cao tÃ­nh máº¡nh máº½ cá»§a quÃ¡ trÃ¬nh tÃ¡i táº¡o báº±ng cÃ¡ch táº­n dá»¥ng cÃ¡c priors táº¡o sinh, chá»©ng minh lá»£i Ã­ch tÆ°Æ¡ng há»— cá»§a viá»‡c káº¿t ná»‘i cháº·t cháº½ cÃ¡c mÃ´ hÃ¬nh tÃ¡i táº¡o vÃ  táº¡o sinh.
*   KhuÃ´n khá»• há»— trá»£ Ä‘iá»u kiá»‡n linh hoáº¡t, cho phÃ©p táº¡o ra tá»« má»™t hoáº·c nhiá»u gÃ³c nhÃ¬n Ä‘áº§u vÃ o, cÃ³ hoáº·c khÃ´ng cÃ³ gá»£i Ã½ camera, cÅ©ng nhÆ° tÃ¡i táº¡o cáº£nh feed-forward trong má»™t mÃ´ hÃ¬nh thá»‘ng nháº¥t.

### Conclusion & Future Works:
Gen3R trÃ¬nh bÃ y má»™t khuÃ´n khá»• hiá»‡u quáº£ vÃ  máº¡nh máº½ cho viá»‡c táº¡o cáº£nh 3D cháº¥t lÆ°á»£ng cao vá»›i hÃ¬nh há»c nháº¥t quÃ¡n báº±ng cÃ¡ch káº¿t há»£p cÃ¡c priors hÃ¬nh há»c phong phÃº tá»« mÃ´ hÃ¬nh tÃ¡i táº¡o ná»n táº£ng vá»›i priors RGB máº¡nh máº½ cá»§a mÃ´ hÃ¬nh Diffusion video. PhÆ°Æ¡ng phÃ¡p nÃ y má»Ÿ ra tiá»m nÄƒng cho viá»‡c táº¡o ra mÃ´i trÆ°á»ng áº£o quy mÃ´ lá»›n vÃ  cung cáº¥p cÃ´ng cá»¥ má»›i cho thiáº¿t káº¿ ná»™i dung sÃ¡ng táº¡o.

### Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u viá»‡c tÃ­ch há»£p cÃ¡c mÃ´ hÃ¬nh tÃ¡i táº¡o 3D ná»n táº£ng khÃ¡c hoáº·c biá»ƒu diá»…n 3D chi tiáº¿t hÆ¡n (vÃ­ dá»¥: lÆ°á»›i Ä‘a giÃ¡c) vÃ o khuÃ´n khá»• Gen3R Ä‘á»ƒ má»Ÿ rá»™ng kháº£ nÄƒng táº¡o hÃ¬nh há»c.
*   KhÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p má»›i Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng kiá»ƒm soÃ¡t ngá»¯ nghÄ©a hoáº·c tÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng trong quÃ¡ trÃ¬nh táº¡o cáº£nh 3D, vÃ­ dá»¥ thÃ´ng qua hÆ°á»›ng dáº«n báº±ng vÄƒn báº£n hoáº·c báº£n phÃ¡c tháº£o.
*   PhÃ¢n tÃ­ch tÃ¡c Ä‘á»™ng cá»§a viá»‡c cÄƒn chá»‰nh cÃ¡c latent space khÃ¡c nhau vÃ  cÃ¡c hÃ m máº¥t mÃ¡t khÃ¡c Ä‘á»‘i vá»›i tÃ­nh nháº¥t quÃ¡n Ä‘a gÃ³c nhÃ¬n vÃ  cháº¥t lÆ°á»£ng hÃ¬nh há»c cá»§a cáº£nh Ä‘Æ°á»£c táº¡o ra.

#### 2. Patent:
*   Má»™t á»©ng dá»¥ng di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng chá»¥p má»™t vÃ i áº£nh hoáº·c má»™t Ä‘oáº¡n video ngáº¯n báº±ng Ä‘iá»‡n thoáº¡i vÃ  tá»± Ä‘á»™ng táº¡o ra má»™t mÃ´ hÃ¬nh 3D hoÃ n chá»‰nh cá»§a cáº£nh, sau Ä‘Ã³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng trong cÃ¡c á»©ng dá»¥ng thá»±c táº¿ tÄƒng cÆ°á»ng hoáº·c in 3D.
*   Há»‡ thá»‘ng camera Ä‘iá»‡n thoáº¡i thÃ´ng minh tÃ­ch há»£p cÃ´ng nghá»‡ Gen3R Ä‘á»ƒ cung cáº¥p tÃ­nh nÄƒng "xem trÆ°á»›c 3D" cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¡c váº­t thá»ƒ áº£o vÃ o má»™t mÃ´i trÆ°á»ng thá»±c Ä‘Æ°á»£c tÃ¡i táº¡o 3D ngay láº­p tá»©c, phá»¥c vá»¥ cho má»¥c Ä‘Ã­ch thiáº¿t káº¿ ná»™i tháº¥t hoáº·c mua sáº¯m áº£o.
*   CÃ´ng nghá»‡ tÃ­ch há»£p vÃ o á»©ng dá»¥ng báº£n Ä‘á»“ hoáº·c du lá»‹ch di Ä‘á»™ng, cho phÃ©p ngÆ°á»i dÃ¹ng táº¡o ra cÃ¡c chuyáº¿n tham quan 3D tÆ°Æ¡ng tÃ¡c cá»§a má»™t khu vá»±c tá»« bá»™ sÆ°u táº­p áº£nh cÃ¡ nhÃ¢n, cung cáº¥p thÃ´ng tin Ä‘á»™ sÃ¢u vÃ  vá»‹ trÃ­ camera chÃ­nh xÃ¡c trÃªn Ä‘iá»‡n thoáº¡i.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.04090](https://huggingface.co/papers/2601.04090) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.04090](https://arxiv.org/abs/2601.04090) |
| PDF Download | [https://arxiv.org/pdf/2601.04090.pdf](https://arxiv.org/pdf/2601.04090.pdf) |
| Github Repository | [https://github.com/JaceyHuang/Gen3R](https://github.com/JaceyHuang/Gen3R) |

--- 

## 18. ResTok: Learning Hierarchical Residuals in 1D Visual Tokenizers for Autoregressive Image Generation

**TÃ¡c giáº£:** Xu Zhang, Cheng Da, Huan Yang, Kun Gai, Ming Lu, Zhan Ma

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** Autoregressive Image Generation, Visual Tokenization, Hierarchical Models, Residual Networks, Vision Transformer (ViT)

### Main Problem:
CÃ¡c tokenizer hÃ¬nh áº£nh 1D hiá»‡n cÃ³ cho mÃ´ hÃ¬nh sinh tá»± há»“i quy (AR) chá»§ yáº¿u tuÃ¢n theo cÃ¡c nguyÃªn táº¯c mÃ´ hÃ¬nh ngÃ´n ngá»¯. Äiá»u nÃ y dáº«n Ä‘áº¿n cÃ¡c token tiá»m áº©n cÃ³ cáº¥u trÃºc Ä‘Æ¡n cáº¥p vÃ  xá»­ lÃ½ dá»¯ liá»‡u thá»‹ giÃ¡c nhÆ° cÃ¡c luá»“ng token pháº³ng tuáº§n tá»±, bá» qua cÃ¡c thuá»™c tÃ­nh quan trá»ng cá»§a thá»‹ giÃ¡c nhÆ° thiáº¿t káº¿ máº¡ng phÃ¢n cáº¥p vÃ  pháº§n dÆ°. Háº­u quáº£ lÃ  thiáº¿u kháº£ nÄƒng káº¿t há»£p tÃ­nh nÄƒng Ä‘a cáº¥p vÃ  táº¡o ra cÃ¡c codebook tiá»m áº©n cÃ³ entropy cao, gÃ¢y khÃ³ khÄƒn cho quÃ¡ trÃ¬nh mÃ´ hÃ¬nh hÃ³a AR.

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t ResidualTokenizer (ResTok), má»™t tokenizer hÃ¬nh áº£nh 1D Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tÃ­ch há»£p cÃ¡c pháº§n dÆ° phÃ¢n cáº¥p cho cáº£ token hÃ¬nh áº£nh vÃ  token tiá»m áº©n. CÃ¡c Ã½ tÆ°á»Ÿng chÃ­nh bao gá»“m:
1.  **Biá»ƒu diá»…n phÃ¢n cáº¥p:** Tiáº¿n hÃ nh há»£p nháº¥t dáº§n dáº§n cÃ¡c token hÃ¬nh áº£nh thÃ nh cÃ¡c tÃ­nh nÄƒng thÃ´ hÆ¡n, cho phÃ©p cÃ¡c token tiá»m áº©n káº¿t há»£p cÃ¡c tÃ­nh nÄƒng Ä‘a cáº¥p (cross-level feature fusion) Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng biá»ƒu diá»…n.
2.  **Pháº§n dÆ° ngá»¯ nghÄ©a:** Há»c cÃ¡c pháº§n dÆ° cÃ³ cáº¥u trÃºc ngá»¯ nghÄ©a giá»¯a cÃ¡c cáº¥p báº­c Ä‘á»ƒ ngÄƒn cháº·n sá»± trÃ¹ng láº·p thÃ´ng tin, tá»« Ä‘Ã³ táº¡o ra cÃ¡c phÃ¢n phá»‘i tiá»m áº©n táº­p trung hÆ¡n vá»›i entropy tháº¥p, dá»… dÃ ng hÆ¡n cho mÃ´ hÃ¬nh AR.
3.  **TÄƒng tá»‘c quÃ¡ trÃ¬nh sinh:** Giá»›i thiá»‡u má»™t bá»™ táº¡o AR phÃ¢n cáº¥p (HAR) cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n toÃ n bá»™ má»™t cáº¥p Ä‘á»™ token tiá»m áº©n cÃ¹ng má»™t lÃºc, thay vÃ¬ sinh tá»«ng token má»™t, giÃºp giáº£m Ä‘Ã¡ng ká»ƒ sá»‘ bÆ°á»›c láº¥y máº«u.

### Main Results:
ResTok chá»©ng minh sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ trong quÃ¡ trÃ¬nh sinh áº£nh AR:
-   Äáº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t gFID lÃ  2.34 trÃªn táº­p dá»¯ liá»‡u ImageNet-256x256.
-   Chá»‰ yÃªu cáº§u 9 bÆ°á»›c láº¥y máº«u Ä‘á»ƒ táº¡o áº£nh, nhá» cÆ¡ cháº¿ sinh áº£nh phÃ¢n cáº¥p.
-   CÃ¡c liÃªn káº¿t giá»¯a cÃ¡c cáº¥p Ä‘á»™ (vÃ­ dá»¥: token tiá»m áº©n thÃ´ hÆ¡n khá»›p vá»›i token hÃ¬nh áº£nh cáº¥p cao, token tiá»m áº©n tinh táº¿ hÆ¡n náº¯m báº¯t chi tiáº¿t pháº§n dÆ° cáº¥p tháº¥p) tá»± Ä‘á»™ng xuáº¥t hiá»‡n mÃ  khÃ´ng cáº§n rÃ ng buá»™c rÃµ rÃ ng.

### Conclusion & Future Works:
Viá»‡c khÃ´i phá»¥c cÃ¡c Æ°u tiÃªn pháº§n dÆ° phÃ¢n cáº¥p trong quÃ¡ trÃ¬nh token hÃ³a hÃ¬nh áº£nh cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ quÃ¡ trÃ¬nh táº¡o áº£nh AR cháº¥t lÆ°á»£ng cao vÃ  hiá»‡u quáº£. BÃ i bÃ¡o nháº¥n máº¡nh táº§m quan trá»ng cá»§a cÃ¡c thiáº¿t káº¿ máº¡ng phÃ¢n cáº¥p vÃ  pháº§n dÆ° trong viá»‡c nÃ¢ng cao kháº£ nÄƒng biá»ƒu diá»…n thá»‹ giÃ¡c. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ bao gá»“m viá»‡c khÃ¡m phÃ¡ cÃ¡c cÆ¡ cháº¿ há»£p nháº¥t vÃ  thiáº¿t káº¿ pháº§n dÆ° tiÃªn tiáº¿n hÆ¡n, cÅ©ng nhÆ° Ã¡p dá»¥ng phÆ°Æ¡ng phÃ¡p nÃ y cho cÃ¡c nhiá»‡m vá»¥ Ä‘a phÆ°Æ¡ng thá»©c khÃ¡c ngoÃ i viá»‡c táº¡o áº£nh.

### Brainstorming Space:

#### 1. Publish Papers:
1.  NghiÃªn cá»©u tÃ¡c Ä‘á»™ng cá»§a cÃ¡c chiáº¿n lÆ°á»£c há»£p nháº¥t vÃ  upsampling khÃ¡c nhau trong kiáº¿n trÃºc tokenizer phÃ¢n cáº¥p Ä‘á»‘i vá»›i hiá»‡u suáº¥t vÃ  cháº¥t lÆ°á»£ng áº£nh Ä‘Æ°á»£c táº¡o.
2.  KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p cÃ¡c cÆ¡ cháº¿ pháº§n dÆ° ngá»¯ nghÄ©a tá»± thÃ­ch á»©ng, cho phÃ©p mÃ´ hÃ¬nh Ä‘iá»u chá»‰nh má»©c Ä‘á»™ chi tiáº¿t vÃ  trá»«u tÆ°á»£ng hÃ³a tÃ¹y thuá»™c vÃ o ná»™i dung áº£nh.
3.  Ãp dá»¥ng tokenizer phÃ¢n cáº¥p vÃ  bá»™ táº¡o HAR cho viá»‡c táº¡o ra chuá»—i video hoáº·c mÃ´ hÃ¬nh 3D, nÆ¡i cáº¥u trÃºc phÃ¢n cáº¥p cÃ³ thá»ƒ mang láº¡i lá»£i Ã­ch vá» hiá»‡u quáº£ vÃ  cháº¥t lÆ°á»£ng.

#### 2. Patent:
1.  Há»‡ thá»‘ng camera Ä‘iá»‡n thoáº¡i thÃ´ng minh tÃ­ch há»£p ResTok Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c nÃ©n vÃ  xá»­ lÃ½ hÃ¬nh áº£nh thá»i gian thá»±c, cho phÃ©p chá»¥p áº£nh cháº¥t lÆ°á»£ng cao vá»›i dung lÆ°á»£ng lÆ°u trá»¯ tháº¥p vÃ  tá»‘c Ä‘á»™ xá»­ lÃ½ nhanh.
2.  CÃ´ng nghá»‡ hiá»ƒn thá»‹ vÃ  chá»‰nh sá»­a áº£nh trÃªn thiáº¿t bá»‹ di Ä‘á»™ng sá»­ dá»¥ng tokenizer pháº§n dÆ° phÃ¢n cáº¥p Ä‘á»ƒ tÃ¡i táº¡o áº£nh vá»›i cÃ¡c má»©c Ä‘á»™ chi tiáº¿t khÃ¡c nhau, cho phÃ©p ngÆ°á»i dÃ¹ng chá»‰nh sá»­a áº£nh theo tá»«ng cáº¥p Ä‘á»™ tá»« tá»•ng thá»ƒ Ä‘áº¿n chi tiáº¿t nhá» má»™t cÃ¡ch mÆ°á»£t mÃ .
3.  á»¨ng dá»¥ng trá»£ lÃ½ áº£o di Ä‘á»™ng cÃ³ kháº£ nÄƒng táº¡o hÃ¬nh áº£nh dá»±a trÃªn mÃ´ táº£ vÄƒn báº£n, sá»­ dá»¥ng kiáº¿n trÃºc ResTok vÃ  bá»™ táº¡o HAR Ä‘á»ƒ sinh ra cÃ¡c hÃ¬nh áº£nh phá»©c táº¡p nhanh chÃ³ng vÃ  vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao trÃªn pháº§n cá»©ng Ä‘iá»‡n thoáº¡i.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03955](https://huggingface.co/papers/2601.03955) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03955](https://arxiv.org/abs/2601.03955) |
| PDF Download | [https://arxiv.org/pdf/2601.03955.pdf](https://arxiv.org/pdf/2601.03955.pdf) |
| Github Repository | N/A |

--- 

## 19. MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents

**TÃ¡c giáº£:** Dongming Jiang, Yi Li, Guanpeng Li, Bingzhe Li

**Xuáº¥t báº£n lÃºc:** 2026-01-06

**Tag:** MAG, Multi-Graph, Agentic Memory, LLMs, Long-Horizon Reasoning, Retrieval, Causal Reasoning

### Main Problem:
Large Language Models (LLMs) gáº·p khÃ³ khÄƒn trong viá»‡c duy trÃ¬ vÃ  suy luáº­n trÃªn ngá»¯ cáº£nh dÃ i háº¡n do cá»­a sá»• chÃº Ã½ há»¯u háº¡n vÃ  thiáº¿u cÆ¡ cháº¿ bá»™ nhá»› cÃ³ cáº¥u trÃºc bá»n vá»¯ng. CÃ¡c há»‡ thá»‘ng Memory-Augmented Generation (MAG) hiá»‡n cÃ³ chá»§ yáº¿u dá»±a vÃ o sá»± tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a trÃªn cÃ¡c kho bá»™ nhá»› Ä‘Æ¡n nháº¥t, lÃ m vÆ°á»›ng máº¯c thÃ´ng tin thá»i gian, nhÃ¢n quáº£ vÃ  thá»±c thá»ƒ, dáº«n Ä‘áº¿n kháº£ nÄƒng diá»…n giáº£i kÃ©m, sá»± khÃ´ng khá»›p giá»¯a Ã½ Ä‘á»‹nh truy váº¥n vÃ  báº±ng chá»©ng Ä‘Æ°á»£c truy xuáº¥t, cÃ¹ng Ä‘á»™ chÃ­nh xÃ¡c suy luáº­n dÆ°á»›i má»©c tá»‘i Æ°u, Ä‘áº·c biá»‡t lÃ  trong cÃ¡c tÃ¡c vá»¥ suy luáº­n phá»©c táº¡p yÃªu cáº§u hiá»ƒu biáº¿t vá» má»‘i quan há»‡ "táº¡i sao".

### Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t MAGMA, má»™t kiáº¿n trÃºc bá»™ nhá»› tÃ¡c tá»­ dá»±a trÃªn Ä‘a Ä‘á»“ thá»‹, Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c háº¡n cháº¿ cá»§a MAG hiá»‡n cÃ³. MAGMA biá»ƒu diá»…n má»—i má»¥c bá»™ nhá»› qua bá»‘n Ä‘á»“ thá»‹ quan há»‡ trá»±c giao (ngá»¯ nghÄ©a, thá»i gian, nhÃ¢n quáº£ vÃ  thá»±c thá»ƒ). Viá»‡c truy xuáº¥t Ä‘Æ°á»£c xÃ¢y dá»±ng nhÆ° má»™t quÃ¡ trÃ¬nh duyá»‡t Ä‘á»“ thá»‹ cÃ³ hÆ°á»›ng chÃ­nh sÃ¡ch, cho phÃ©p lá»±a chá»n thÃ­ch á»©ng vá»›i truy váº¥n vÃ  xÃ¢y dá»±ng ngá»¯ cáº£nh cÃ³ cáº¥u trÃºc. Kiáº¿n trÃºc nÃ y tÃ¡ch biá»‡t biá»ƒu diá»…n bá»™ nhá»› khá»i logic truy xuáº¥t, cung cáº¥p cÃ¡c Ä‘Æ°á»ng suy luáº­n minh báº¡ch vÃ  kiá»ƒm soÃ¡t chi tiáº¿t quÃ¡ trÃ¬nh truy xuáº¥t thÃ´ng qua má»™t cÆ¡ cháº¿ truy váº¥n phÃ¢n cáº¥p, nháº­n biáº¿t Ã½ Ä‘á»‹nh. MAGMA cÅ©ng sá»­ dá»¥ng cÆ¡ cháº¿ tiáº¿n hÃ³a bá»™ nhá»› luá»“ng kÃ©p Ä‘á»ƒ Ä‘áº£m báº£o pháº£n há»“i nhanh chÃ³ng trong khi cá»§ng cá»‘ cáº¥u trÃºc quan há»‡.

### Main Results:
MAGMA nháº¥t quÃ¡n vÆ°á»£t trá»™i so vá»›i cÃ¡c há»‡ thá»‘ng bá»™ nhá»› tÃ¡c tá»­ hiá»‡n Ä‘áº¡i trong cÃ¡c tÃ¡c vá»¥ suy luáº­n dÃ i háº¡n trÃªn cÃ¡c bá»™ Ä‘iá»ƒm chuáº©n Lo-CoMo vÃ  LongMemEval. Há»‡ thá»‘ng giáº£m Ä‘á»™ trá»… truy xuáº¥t vÃ  tiÃªu thá»¥ token so vá»›i cÃ¡c há»‡ thá»‘ng trÆ°á»›c Ä‘Ã³. MAGMA cung cáº¥p Ä‘Æ°á»ng suy luáº­n minh báº¡ch vÃ  kiá»ƒm soÃ¡t chi tiáº¿t hÆ¡n trong viá»‡c lá»±a chá»n bá»™ nhá»›, cáº£i thiá»‡n sá»± khá»›p ná»‘i giá»¯a Ã½ Ä‘á»‹nh truy váº¥n vÃ  báº±ng chá»©ng Ä‘Æ°á»£c truy xuáº¥t.

### Conclusion & Future Works:
MAGMA cung cáº¥p má»™t ná»n táº£ng cÃ³ nguyÃªn táº¯c vÃ  cÃ³ thá»ƒ má»Ÿ rá»™ng cho bá»™ nhá»› tÃ¡c tá»­ báº±ng cÃ¡ch mÃ´ hÃ¬nh hÃ³a cáº¥u trÃºc quan há»‡ khÃ´ng Ä‘á»“ng nháº¥t trong tráº£i nghiá»‡m cá»§a tÃ¡c tá»­. Báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c Ä‘á»“ thá»‹ quan há»‡ trá»±c giao vÃ  cÆ¡ cháº¿ truy xuáº¥t thÃ­ch á»©ng, MAGMA cáº£i thiá»‡n cáº£ sá»± nháº¥t quÃ¡n dÃ i háº¡n vÃ  kháº£ nÄƒng diá»…n giáº£i trong suy luáº­n cá»§a AI Agents. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ táº­p trung vÃ o viá»‡c khÃ¡m phÃ¡ sÃ¢u hÆ¡n cÃ¡ch tá»‘i Æ°u hÃ³a cÃ¡c thÃ nh pháº§n nÃ y hoáº·c tÃ­ch há»£p thÃªm cÃ¡c loáº¡i quan há»‡ phá»©c táº¡p khÃ¡c Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng cá»§a há»‡ thá»‘ng.

### Brainstorming Space:
#### 1. Publish Papers:
NghiÃªn cá»©u cÆ¡ cháº¿ tá»± Ä‘á»™ng há»c vÃ  táº¡o ra cÃ¡c loáº¡i quan há»‡ Ä‘á»“ thá»‹ má»›i ngoÃ i bá»‘n loáº¡i Ä‘Ã£ Ä‘á» xuáº¥t Ä‘á»ƒ náº¯m báº¯t cÃ¡c phá»¥ thuá»™c phá»©c táº¡p hÆ¡n.
KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p MAGMA vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p há»c tÄƒng cÆ°á»ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a chÃ­nh sÃ¡ch duyá»‡t Ä‘á»“ thá»‹ trong thá»i gian thá»±c dá»±a trÃªn pháº£n há»“i cá»§a tÃ¡c tá»­.
PhÃ¡t triá»ƒn má»™t framework Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n Ä‘á»ƒ Ä‘á»‹nh lÆ°á»£ng kháº£ nÄƒng diá»…n giáº£i vÃ  kháº£ nÄƒng giáº£i thÃ­ch cá»§a cÃ¡c há»‡ thá»‘ng bá»™ nhá»› tÃ¡c tá»­ dá»±a trÃªn Ä‘á»“ thá»‹.

#### 2. Patent:
Há»‡ thá»‘ng bá»™ nhá»› thÃ´ng minh cho thiáº¿t bá»‹ di Ä‘á»™ng cÃ³ kháº£ nÄƒng tá»± Ä‘á»™ng tá»• chá»©c cÃ¡c tÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng (tin nháº¯n, cuá»™c gá»i, lá»‹ch sá»­ duyá»‡t web) thÃ nh cÃ¡c Ä‘á»“ thá»‹ ngá»¯ nghÄ©a, thá»i gian, nhÃ¢n quáº£ vÃ  thá»±c thá»ƒ Ä‘á»ƒ truy xuáº¥t thÃ´ng tin cÃ¡ nhÃ¢n hÃ³a.
á»¨ng dá»¥ng Ä‘iá»‡n thoáº¡i thÃ´ng minh vá»›i trá»£ lÃ½ áº£o sá»­ dá»¥ng kiáº¿n trÃºc bá»™ nhá»› Ä‘a Ä‘á»“ thá»‹ Ä‘á»ƒ cung cáº¥p cÃ¡c gá»£i Ã½ vÃ  cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c hÆ¡n dá»±a trÃªn ngá»¯ cáº£nh lá»‹ch sá»­ ngÆ°á»i dÃ¹ng vÃ  cÃ¡c má»‘i quan há»‡ áº©n.
PhÆ°Æ¡ng phÃ¡p tá»‘i Æ°u hÃ³a tÃ i nguyÃªn cho thiáº¿t bá»‹ di Ä‘á»™ng báº±ng cÃ¡ch sá»­ dá»¥ng chÃ­nh sÃ¡ch duyá»‡t Ä‘á»“ thá»‹ thÃ­ch á»©ng Ä‘á»ƒ truy xuáº¥t bá»™ nhá»› hiá»‡u quáº£, giáº£m Ä‘á»™ trá»… vÃ  tiÃªu thá»¥ nÄƒng lÆ°á»£ng khi xá»­ lÃ½ cÃ¡c truy váº¥n phá»©c táº¡p cá»§a ngÆ°á»i dÃ¹ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.03236](https://huggingface.co/papers/2601.03236) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.03236](https://arxiv.org/abs/2601.03236) |
| PDF Download | [https://arxiv.org/pdf/2601.03236.pdf](https://arxiv.org/pdf/2601.03236.pdf) |
| Github Repository | N/A |

--- 

## 20. RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization

**TÃ¡c giáº£:** Wei-Tse Cheng, Yen-Jen Chiou, Yuan-Fu Yang

**Xuáº¥t báº£n lÃºc:** 2025-12-28

**Tag:** SLAM, 3D Gaussian Splatting, Real-time Mapping, Dense Initialization, View Synthesis, DINOv3

### Main Problem:
CÃ¡c framework SLAM dá»±a trÃªn 3D Gaussian Splatting hiá»‡n táº¡i thÆ°á»ng dá»±a vÃ o quÃ¡ trÃ¬nh densification láº·p Ä‘i láº·p láº¡i dá»±a trÃªn sai sá»‘ (residual-driven densification). Äiá»u nÃ y dáº«n Ä‘áº¿n cÃ¡c má»¥c tiÃªu khÃ´ng á»•n Ä‘á»‹nh, há»™i tá»¥ khÃ´ng vá»¯ng vÃ  Ä‘á»™ nháº¡y cáº£m vá»›i cÃ¡c khu vá»±c giÃ u texture hoáº·c lá»™n xá»™n do sá»± bao phá»§ cháº­m trá»… vÃ  hÃ¬nh há»c khÃ´ng Ä‘á»“ng Ä‘á»u.

### Main Idea:
RGS-SLAM Ä‘á» xuáº¥t thay tháº¿ giai Ä‘oáº¡n densification truyá»n thá»‘ng báº±ng má»™t phÆ°Æ¡ng phÃ¡p khá»Ÿi táº¡o Gaussian "má»™t láº§n chá»¥p" (one-shot) dá»±a trÃªn cÃ¡c tÆ°Æ¡ng á»©ng máº­t Ä‘á»™ cao, khÃ´ng cáº§n huáº¥n luyá»‡n. Há»‡ thá»‘ng sá»­ dá»¥ng cÃ¡c descriptor DINOv3 Ä‘Æ°á»£c tinh chá»‰nh qua bá»™ phÃ¢n loáº¡i inlier nháº­n biáº¿t Ä‘á»™ tin cáº­y Ä‘á»ƒ táº¡o ra cÃ¡c tÆ°Æ¡ng á»©ng Ä‘a khung nhÃ¬n dÃ y Ä‘áº·c. CÃ¡c tÆ°Æ¡ng á»©ng nÃ y sau Ä‘Ã³ Ä‘Æ°á»£c tam giÃ¡c hÃ³a Ä‘á»ƒ táº¡o ra má»™t táº­p há»£p cÃ¡c háº¡t Gaussian phÃ¢n bá»‘ tá»‘t vÃ  nháº­n biáº¿t cáº¥u trÃºc trÆ°á»›c khi tá»‘i Æ°u hÃ³a. CÃ¡ch tiáº¿p cáº­n nÃ y giÃºp á»•n Ä‘á»‹nh quÃ¡ trÃ¬nh láº­p báº£n Ä‘á»“ sá»›m, tÄƒng tá»‘c Ä‘á»™ há»™i tá»¥ vÃ  cho phÃ©p tá»‘i Æ°u hÃ³a cÃ¡c tham sá»‘ Gaussian (mean, covariance, opacity, color) vá»›i cáº¥u trÃºc báº£n Ä‘á»“ cá»‘ Ä‘á»‹nh.

### Main Results:
- TÄƒng tá»‘c Ä‘á»™ há»™i tá»¥ khoáº£ng 20%.
- Äáº¡t Ä‘á»™ trung thá»±c káº¿t xuáº¥t cao hÆ¡n trong cÃ¡c cáº£nh giÃ u texture vÃ  lá»™n xá»™n.
- Äáº¡t Ä‘Æ°á»£c Ä‘á»™ chÃ­nh xÃ¡c Ä‘á»‹nh vá»‹ vÃ  tÃ¡i táº¡o cáº¡nh tranh hoáº·c vÆ°á»£t trá»™i so vá»›i cÃ¡c há»‡ thá»‘ng SLAM dá»±a trÃªn Gaussian vÃ  Ä‘iá»ƒm tiÃªn tiáº¿n nháº¥t.
- Duy trÃ¬ hiá»‡u suáº¥t láº­p báº£n Ä‘á»“ thá»i gian thá»±c lÃªn tá»›i 925 FPS.
- Giáº£m Ä‘á»™ trÃ´i (drift) hÆ¡n 30% thÃ´ng qua cÃ¡c tÆ°Æ¡ng á»©ng cÃ³ trá»ng sá»‘ Ä‘á»™ tin cáº­y.
- Äáº¡t thÃ´ng lÆ°á»£ng káº¿t xuáº¥t cao hÆ¡n 20%.
- Cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c vÃ  hoÃ n chá»‰nh tÃ¡i táº¡o khoáº£ng 20%.
- ÄÆ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn bá»™ dá»¯ liá»‡u TUM RGB-D vÃ  Replica.

### Conclusion & Future Works:
RGS-SLAM cung cáº¥p má»™t phÆ°Æ¡ng phÃ¡p máº¡nh máº½ vÃ  hiá»‡u quáº£ cho SLAM dá»±a trÃªn Gaussian Splatting báº±ng cÃ¡ch sá»­ dá»¥ng khá»Ÿi táº¡o máº­t Ä‘á»™ cao má»™t láº§n chá»¥p, cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ Ä‘á»™ á»•n Ä‘á»‹nh, tá»‘c Ä‘á»™ vÃ  cháº¥t lÆ°á»£ng tÃ¡i táº¡o so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p dá»±a trÃªn densification. Pháº§n trÃ­ch dáº«n khÃ´ng tháº£o luáº­n vá» cÃ¡c cÃ´ng viá»‡c tÆ°Æ¡ng lai cá»¥ thá»ƒ.

### Brainstorming Space:
#### 1. Publish Papers:
- NghiÃªn cá»©u tÃ­ch há»£p khá»Ÿi táº¡o máº­t Ä‘á»™ cao cá»§a RGS-SLAM vá»›i cÃ¡c mÃ´ hÃ¬nh NeRF thá»i gian thá»±c Ä‘á»ƒ cáº£i thiá»‡n sá»± á»•n Ä‘á»‹nh vÃ  tá»‘c Ä‘á»™ há»™i tá»¥ trong quÃ¡ trÃ¬nh há»c táº­p.
- PhÃ¡t triá»ƒn má»™t thuáº­t toÃ¡n lá»±a chá»n keyframe thÃ­ch á»©ng cho RGS-SLAM, sá»­ dá»¥ng thÃ´ng tin tá»« entropy hÃ¬nh há»c hoáº·c Ä‘á»™ bao phá»§ Gaussian Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u quáº£ láº­p báº£n Ä‘á»“.
- KhÃ¡m phÃ¡ viá»‡c má»Ÿ rá»™ng RGS-SLAM cho mÃ´i trÆ°á»ng Ä‘a cáº£m biáº¿n (vÃ­ dá»¥: káº¿t há»£p vá»›i LiDAR hoáº·c IMU) Ä‘á»ƒ nÃ¢ng cao Ä‘á»™ chÃ­nh xÃ¡c vÃ  máº¡nh máº½ trong cÃ¡c Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng hoáº·c texture kÃ©m.
#### 2. Patent:
- Há»‡ thá»‘ng Ä‘á»‹nh vá»‹ vÃ  láº­p báº£n Ä‘á»“ 3D cho thiáº¿t bá»‹ di Ä‘á»™ng, sá»­ dá»¥ng khá»Ÿi táº¡o Gaussian máº­t Ä‘á»™ cao má»™t láº§n chá»¥p Ä‘á»ƒ táº¡o báº£n Ä‘á»“ mÃ´i trÆ°á»ng nhanh chÃ³ng vÃ  chÃ­nh xÃ¡c cho cÃ¡c á»©ng dá»¥ng thá»±c táº¿ tÄƒng cÆ°á»ng trÃªn Ä‘iá»‡n thoáº¡i.
- CÃ´ng nghá»‡ camera Ä‘iá»‡n thoáº¡i thÃ´ng minh cho phÃ©p quÃ©t vÃ  tÃ¡i táº¡o mÃ´ hÃ¬nh 3D cá»§a váº­t thá»ƒ hoáº·c khÃ´ng gian ngay láº­p tá»©c, sá»­ dá»¥ng thuáº­t toÃ¡n tam giÃ¡c hÃ³a tÆ°Æ¡ng á»©ng dÃ y Ä‘áº·c Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ khá»Ÿi táº¡o.
- PhÆ°Æ¡ng phÃ¡p Ä‘iá»u hÆ°á»›ng trong nhÃ  dá»±a trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng, tá»± Ä‘á»™ng xÃ¢y dá»±ng báº£n Ä‘á»“ 3D cháº¥t lÆ°á»£ng cao tá»« dá»¯ liá»‡u camera báº±ng cÃ¡ch khá»Ÿi táº¡o Gaussian tá»« cÃ¡c tÆ°Æ¡ng á»©ng multi-view, giáº£m thiá»ƒu thá»i gian chá» vÃ  cáº£i thiá»‡n tráº£i nghiá»‡m ngÆ°á»i dÃ¹ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.00705](https://huggingface.co/papers/2601.00705) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.00705](https://arxiv.org/abs/2601.00705) |
| PDF Download | [https://arxiv.org/pdf/2601.00705.pdf](https://arxiv.org/pdf/2601.00705.pdf) |
| Github Repository | N/A |

