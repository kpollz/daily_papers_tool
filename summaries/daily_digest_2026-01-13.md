# ğŸ¤— Daily Hugging Face Paper Digest - 2026-01-13

BÃ¡o cÃ¡o Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng vÃ o lÃºc 2026-01-14 10:03:44 báº±ng mÃ´ hÃ¬nh `gemini-2.5-flash`.

## ğŸ“° Summary of Papers

--- 

## 1. Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning *(175 votes)*

**TÃ¡c giáº£:** Chengwen Liu, Xiaomin Yu, Zhuoyue Chang, Zhe Huang, Shuo Zhang, Heng Lian, Kunyi Wang, Rui Xu, Sen Hu, Jianheng Hou, Hao Peng, Chengwei Qin, Xiaobin Hu, Hong Peng, Ronghao Chen, Huacan Wang

**Xuáº¥t báº£n lÃºc:** 2026-01-11

**Tag:** Video Deep Research, Open-domain QA, Multimodal Large Language Models (MLLMs), Agentic AI, Video Reasoning, Web Search, Benchmark

### I. Main Problem:
Váº¥n Ä‘á» cá»‘t lÃµi mÃ  bÃ i bÃ¡o Ä‘á» cáº­p lÃ  sá»± thiáº¿u há»¥t cÃ¡c benchmark Ä‘Ã¡ng tin cáº­y Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng suy luáº­n video trong cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿, nÆ¡i cÃ¡c manh má»‘i thá»‹ giÃ¡c trong video thÆ°á»ng chá»‰ mang tÃ­nh cá»¥c bá»™ vÃ  cÃ¡c cÃ¢u tráº£ lá»i cáº§n xÃ¡c minh láº¡i phÃ¢n tÃ¡n trÃªn web má»Ÿ. CÃ¡c benchmark hiá»‡n cÃ³ thÆ°á»ng giá»›i háº¡n trong bá»‘i cáº£nh dá»¯ liá»‡u Ä‘Ã³ng hoáº·c chá»§ yáº¿u dá»±a trÃªn vÄƒn báº£n, khÃ´ng thá»ƒ Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c kháº£ nÄƒng káº¿t há»£p khai thÃ¡c manh má»‘i video Ä‘a khung, tÃ¬m kiáº¿m thÃ´ng tin tÆ°Æ¡ng tÃ¡c trÃªn web vÃ  suy luáº­n Ä‘a bÆ°á»›c Ä‘á»ƒ xÃ¡c thá»±c thÃ´ng tin.

### II. Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t VideoDR, má»™t benchmark nghiÃªn cá»©u chuyÃªn sÃ¢u vá» video Ä‘áº§u tiÃªn, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng suy luáº­n video cÃ³ tÃ¡c nhÃ¢n trong mÃ´i trÆ°á»ng web má»Ÿ. VideoDR yÃªu cáº§u cÃ¡c mÃ´ hÃ¬nh thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:
1.  **TrÃ­ch xuáº¥t neo thá»‹ giÃ¡c Ä‘a khung:** Nháº­n diá»‡n vÃ  tá»•ng há»£p cÃ¡c manh má»‘i hÃ¬nh áº£nh tá»« nhiá»u khung hÃ¬nh trong video.
2.  **Truy xuáº¥t thÃ´ng tin tÆ°Æ¡ng tÃ¡c trÃªn web:** Sá»­ dá»¥ng cÃ´ng cá»¥ tÃ¬m kiáº¿m trÃªn trÃ¬nh duyá»‡t Ä‘á»ƒ Ä‘á»‹nh vá»‹ báº±ng chá»©ng tiá»m nÄƒng trÃªn web má»Ÿ.
3.  **Suy luáº­n Ä‘a bÆ°á»›c:** Thá»±c hiá»‡n suy luáº­n Ä‘a bÆ°á»›c trÃªn khÃ´ng gian báº±ng chá»©ng káº¿t há»£p tá»« video vÃ  cÃ¡c trang web Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i duy nháº¥t vÃ  cÃ³ thá»ƒ kiá»ƒm chá»©ng Ä‘Æ°á»£c.
Benchmark Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ´ng qua quy trÃ¬nh chÃº thÃ­ch thá»§ cÃ´ng vÃ  kiá»ƒm soÃ¡t cháº¥t lÆ°á»£ng nghiÃªm ngáº·t, Ä‘áº£m báº£o má»—i cÃ¢u há»i Ä‘á»u phá»¥ thuá»™c Ä‘á»“ng thá»i vÃ o cáº£ video vÃ  káº¿t quáº£ tÃ¬m kiáº¿m trÃªn web.

### III. Main Results:
-   VideoDR lÃ  benchmark Ä‘áº§u tiÃªn cÃ³ há»‡ thá»‘ng Ä‘á»ƒ nghiÃªn cá»©u cÃ¡c tÃ¡c nhÃ¢n video trong mÃ´i trÆ°á»ng web má»Ÿ, cung cáº¥p cÃ¡c máº«u cháº¥t lÆ°á»£ng cao tráº£i rá»™ng trÃªn sÃ¡u miá»n ngá»¯ nghÄ©a khÃ¡c nhau.
-   ÄÃ¡nh giÃ¡ cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘a phÆ°Æ¡ng thá»©c (MLLMs) cáº£ mÃ£ nguá»“n Ä‘Ã³ng vÃ  mÃ£ nguá»“n má»Ÿ dÆ°á»›i hai mÃ´ hÃ¬nh Workflow vÃ  Agentic cho tháº¥y phÆ°Æ¡ng phÃ¡p Agentic khÃ´ng pháº£i lÃºc nÃ o cÅ©ng vÆ°á»£t trá»™i hÆ¡n Workflow. Hiá»‡u quáº£ cá»§a Agentic phá»¥ thuá»™c vÃ o kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh trong viá»‡c duy trÃ¬ cÃ¡c neo video ban Ä‘áº§u qua cÃ¡c chuá»—i truy xuáº¥t dÃ i.
-   PhÃ¢n tÃ­ch sÃ¢u hÆ¡n chá»‰ ra ráº±ng "Goal Drift" (láº¡c máº¥t má»¥c tiÃªu) vÃ  "Long-horizon Consistency" (tÃ­nh nháº¥t quÃ¡n dÃ i háº¡n) lÃ  nhá»¯ng nÃºt tháº¯t cá»• chai cá»‘t lÃµi háº¡n cháº¿ sá»± phÃ¡t triá»ƒn cá»§a cÃ¡c tÃ¡c nhÃ¢n nghiÃªn cá»©u video chuyÃªn sÃ¢u tháº¿ há»‡ tiáº¿p theo.

### IV. Conclusion & Future Works:
BÃ i bÃ¡o káº¿t luáº­n ráº±ng VideoDR cung cáº¥p má»™t benchmark cÃ³ há»‡ thá»‘ng Ä‘á»ƒ nghiÃªn cá»©u cÃ¡c tÃ¡c nhÃ¢n video trong mÃ´i trÆ°á»ng web má»Ÿ vÃ  Ä‘Ã£ lÃ m sÃ¡ng tá» nhá»¯ng thÃ¡ch thá»©c chÃ­nh Ä‘á»‘i vá»›i cÃ¡c tÃ¡c nhÃ¢n nghiÃªn cá»©u video chuyÃªn sÃ¢u tháº¿ há»‡ tiáº¿p theo. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cáº§n táº­p trung vÃ o viá»‡c giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» "Goal Drift" vÃ  "Long-horizon Consistency" Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh trong viá»‡c duy trÃ¬ sá»± gáº¯n káº¿t vá»›i cÃ¡c neo video ban Ä‘áº§u qua cÃ¡c chuá»—i suy luáº­n vÃ  tÃ¬m kiáº¿m dÃ i.

### V. Brainstorming Space:
#### 1. Publish Papers:
1.  NghiÃªn cá»©u cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh má»›i giÃºp duy trÃ¬ "video anchors" hiá»‡u quáº£ hÆ¡n trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m thÃ´ng tin Ä‘a bÆ°á»›c trÃªn web má»Ÿ.
2.  PhÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ Ä‘á»‹nh lÆ°á»£ng cho "Goal Drift" vÃ  "Long-horizon Consistency" trong cÃ¡c tÃ¡c vá»¥ suy luáº­n Ä‘a phÆ°Æ¡ng thá»©c.
3.  KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p cÃ¡c ká»¹ thuáº­t suy luáº­n nhÃ¢n quáº£ Ä‘á»ƒ cáº£i thiá»‡n kháº£ nÄƒng tá»•ng há»£p báº±ng chá»©ng tá»« video vÃ  web trong cÃ¡c tÃ¡c vá»¥ QA.

#### 2. Patent:
1.  Há»‡ thá»‘ng trá»£ lÃ½ AI di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng quay video vÃ  Ä‘áº·t cÃ¢u há»i má»Ÿ, sau Ä‘Ã³ AI sáº½ tÃ¬m kiáº¿m thÃ´ng tin trÃªn web Ä‘á»ƒ tráº£ lá»i dá»±a trÃªn cÃ¡c manh má»‘i trong video, hiá»ƒn thá»‹ káº¿t quáº£ trá»±c tiáº¿p trÃªn Ä‘iá»‡n thoáº¡i.
2.  á»¨ng dá»¥ng di Ä‘á»™ng cÃ³ kháº£ nÄƒng ghi láº¡i cáº£nh quan hoáº·c váº­t thá»ƒ tá»« video, sau Ä‘Ã³ tá»± Ä‘á»™ng tÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trÃªn máº¡ng vÃ  cung cáº¥p cÃ¡c gá»£i Ã½ hÃ nh Ä‘á»™ng hoáº·c sáº£n pháº©m dá»±a trÃªn ná»™i dung video.
3.  CÃ´ng nghá»‡ tÃ­ch há»£p vÃ o camera Ä‘iá»‡n thoáº¡i Ä‘á»ƒ nháº­n diá»‡n cÃ¡c Ä‘á»‘i tÆ°á»£ng hoáº·c sá»± kiá»‡n trong video theo thá»i gian thá»±c, Ä‘á»“ng thá»i tá»± Ä‘á»™ng truy xuáº¥t cÃ¡c thÃ´ng tin bá»• sung tá»« web Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh hoáº·c xÃ¡c thá»±c thÃ´ng tin cho ngÆ°á»i dÃ¹ng khi há» Ä‘ang xem hoáº·c quay video.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.06943](https://huggingface.co/papers/2601.06943) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.06943](https://arxiv.org/abs/2601.06943) |
| PDF Download | [https://arxiv.org/pdf/2601.06943.pdf](https://arxiv.org/pdf/2601.06943.pdf) |
| Github Repository | [https://github.com/QuantaAlpha/VideoDR-Benchmark](https://github.com/QuantaAlpha/VideoDR-Benchmark) |

--- 

## 2. BabyVision: Visual Reasoning Beyond Language *(156 votes)*

**TÃ¡c giáº£:** Liang Chen, Weichu Xie, Yiyan Liang, Hongfeng He, Hans Zhao, Zhibo Yang, Zhiqi Huang, Haoning Wu, Haoyu Lu, Y. charles, Yiping Bao, Yuantao Fan, Guopeng Li, Haiyang Shen, Xuanzhong Chen, Wendong Xu, Shuzheng Si, Zefan Cai, Wenhao Chai, Ziqi Huang, Fangfu Liu, Tianyu Liu, Baobao Chang, Xiaobo Hu, Kaiyuan Chen, Yixin Ren, Yang Liu, Yuan Gong, Kuan Li

**Xuáº¥t báº£n lÃºc:** 2026-01-10

**Tag:** MLLMs, Visual Reasoning, Benchmark, Early Vision, Generative Models, Visual Perception

### I. Main Problem:
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘a phÆ°Æ¡ng thá»©c (MLLM) hiá»‡n Ä‘áº¡i váº«n phá»¥ thuá»™c nhiá»u vÃ o cÃ¡c tiÃªn nghiá»‡m ngÃ´n ngá»¯ Ä‘á»ƒ bÃ¹ Ä‘áº¯p cho kháº£ nÄƒng hiá»ƒu thá»‹ giÃ¡c cÃ²n yáº¿u. ChÃºng liÃªn tá»¥c tháº¥t báº¡i trong cÃ¡c tÃ¡c vá»¥ thá»‹ giÃ¡c cÆ¡ báº£n mÃ  con ngÆ°á»i, ká»ƒ cáº£ tráº» 3 tuá»•i, cÃ³ thá»ƒ giáº£i quyáº¿t dá»… dÃ ng, cho tháº¥y MLLM thiáº¿u cÃ¡c nguyÃªn lÃ½ thá»‹ giÃ¡c ná»n táº£ng. CÃ¡c Ä‘Ã¡nh giÃ¡ hiá»‡n cÃ³ thÆ°á»ng nháº¯m má»¥c tiÃªu vÃ o cÃ¡c nhiá»‡m vá»¥ cáº¥p cao, dá»±a trÃªn kiáº¿n thá»©c vÃ  Ã­t táº­p trung vÃ o cÃ¡c kháº£ nÄƒng suy luáº­n thá»‹ giÃ¡c Ä‘á»™c láº­p vá»›i ngÃ´n ngá»¯.

### II. Main Idea:
NghiÃªn cá»©u giá»›i thiá»‡u BABYVISION, má»™t bá»™ tiÃªu chuáº©n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c kháº£ nÄƒng thá»‹ giÃ¡c cá»‘t lÃµi cá»§a MLLM Ä‘á»™c láº­p vá»›i kiáº¿n thá»©c ngÃ´n ngá»¯. BABYVISION bao gá»“m 388 cÃ¢u há»i, chia thÃ nh 22 loáº¡i phá»¥ trong 4 danh má»¥c chÃ­nh: PhÃ¢n biá»‡t chi tiáº¿t, Theo dÃµi thá»‹ giÃ¡c, Nháº­n thá»©c khÃ´ng gian vÃ  Nháº­n dáº¡ng máº«u thá»‹ giÃ¡c. Bá»™ tiÃªu chuáº©n nÃ y táº­p trung vÃ o cÃ¡c ká»¹ nÄƒng thá»‹ giÃ¡c sá»›m mÃ  con ngÆ°á»i phÃ¡t triá»ƒn trÆ°á»›c khi cÃ³ ngÃ´n ngá»¯. NgoÃ i ra, nghiÃªn cá»©u cÃ²n Ä‘á» xuáº¥t BABYVISION-GEN, má»™t phiÃªn báº£n táº¡o sinh Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ suy luáº­n thá»‹ giÃ¡c thÃ´ng qua viá»‡c táº¡o áº£nh thay vÃ¬ chá»‰ Ä‘áº§u ra ngÃ´n ngá»¯, kÃ¨m theo má»™t bá»™ cÃ´ng cá»¥ Ä‘Ã¡nh giÃ¡ tá»± Ä‘á»™ng Ä‘áº¡t Ä‘á»™ Ä‘á»“ng thuáº­n 96% vá»›i Ä‘Ã¡nh giÃ¡ cá»§a con ngÆ°á»i.

### III. Main Results:
- CÃ¡c MLLM hÃ ng Ä‘áº§u cÃ³ hiá»‡u suáº¥t tháº¥p hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i con ngÆ°á»i trÃªn BABYVISION. Cá»¥ thá»ƒ, Gemini3-Pro-Preview Ä‘áº¡t 49.7%, kÃ©m xa tráº» 6 tuá»•i vÃ  má»©c trung bÃ¬nh 94.1% cá»§a ngÆ°á»i lá»›n.
- Khoáº£ng cÃ¡ch hiá»‡u suáº¥t tuyá»‡t Ä‘á»‘i giá»¯a mÃ´ hÃ¬nh tá»‘t nháº¥t vÃ  ngÆ°á»i lá»›n lÃ  44.4%.
- CÃ¡c tháº¥t báº¡i lá»›n nháº¥t cá»§a MLLM xuáº¥t hiá»‡n trong cÃ¡c tÃ¡c vá»¥ Theo dÃµi thá»‹ giÃ¡c vÃ  Nháº­n thá»©c khÃ´ng gian, cho tháº¥y chÃºng máº¥t kháº£ nÄƒng theo dÃµi Ä‘á»‘i tÆ°á»£ng vÃ  thiáº¿u trÃ­ tÆ°á»Ÿng tÆ°á»£ng khÃ´ng gian.
- CÃ¡c mÃ´ hÃ¬nh táº¡o sinh cho tháº¥y nhá»¯ng cáº£i thiá»‡n Ä‘áº§y há»©a háº¹n trÃªn BABYVISION-GEN Ä‘á»‘i vá»›i cÃ¡c tÃ¡c vá»¥ khÃ³ cho MLLM, Ä‘áº·c biá»‡t lÃ  theo dÃµi thá»‹ giÃ¡c vÃ  phÃ¢n biá»‡t chi tiáº¿t, máº·c dÃ¹ Ä‘á»™ tin cáº­y tá»•ng thá»ƒ váº«n cÃ²n háº¡n cháº¿.

### IV. Conclusion & Future Works:
BABYVISION Ä‘Ã£ bÃ³c tráº§n má»™t lá»— há»•ng Ä‘Ã¡ng ká»ƒ trong kháº£ nÄƒng suy luáº­n thá»‹ giÃ¡c cÆ¡ báº£n cá»§a MLLM, khÃ´ng Ä‘Æ°á»£c phÃ¡t hiá»‡n bá»Ÿi cÃ¡c bá»™ tiÃªu chuáº©n hiá»‡n cÃ³. Tiáº¿n bá»™ trong viá»‡c giáº£i quyáº¿t cÃ¡c thÃ¡ch thá»©c cá»§a BABYVISION Ä‘áº¡i diá»‡n cho má»™t bÆ°á»›c tiáº¿n quan trá»ng hÆ°á»›ng tá»›i kháº£ nÄƒng nháº­n thá»©c vÃ  suy luáº­n thá»‹ giÃ¡c á»Ÿ cáº¥p Ä‘á»™ con ngÆ°á»i. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo sáº½ khÃ¡m phÃ¡ cÃ¡ch Ä‘Ã o táº¡o dá»±a trÃªn há»c tÄƒng cÆ°á»ng (RLVR) vÃ  cÃ¡c mÃ´ hÃ¬nh táº¡o sinh cÃ³ thá»ƒ cáº£i thiá»‡n hÆ¡n ná»¯a hiá»‡u suáº¥t suy luáº­n thá»‹ giÃ¡c.

### V. Brainstorming Space:
#### 1. Publish Papers:
- NghiÃªn cá»©u so sÃ¡nh chi tiáº¿t hiá»‡u suáº¥t cá»§a MLLM trÃªn BABYVISION vá»›i cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh thá»‹ giÃ¡c truyá»n thá»‘ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh lá»£i tháº¿ vÃ  háº¡n cháº¿ cá»§a tá»«ng phÆ°Æ¡ng phÃ¡p.
- PhÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã o táº¡o MLLM má»›i tÃ­ch há»£p cÃ¡c module há»c táº­p "trÆ°á»›c ngÃ´n ngá»¯" Ä‘á»ƒ cáº£i thiá»‡n trá»±c tiáº¿p kháº£ nÄƒng thá»‹ giÃ¡c cÆ¡ báº£n cá»§a chÃºng.
- PhÃ¢n tÃ­ch sÃ¢u hÆ¡n cÃ¡c loáº¡i lá»—i cá»¥ thá»ƒ mÃ  MLLM máº¯c pháº£i trÃªn BABYVISION Ä‘á»ƒ táº¡o ra cÃ¡c chiáº¿n lÆ°á»£c kháº¯c phá»¥c má»¥c tiÃªu cho tá»«ng danh má»¥c tÃ¡c vá»¥.
#### 2. Patent:
- Má»™t á»©ng dá»¥ng di Ä‘á»™ng sá»­ dá»¥ng AI cÃ³ kháº£ nÄƒng hÆ°á»›ng dáº«n ngÆ°á»i dÃ¹ng nháº­n diá»‡n vÃ  theo dÃµi cÃ¡c váº­t thá»ƒ trong mÃ´i trÆ°á»ng thá»±c táº¿, vÃ­ dá»¥ nhÆ° tÃ¬m Ä‘Æ°á»ng Ä‘i qua má»™t mÃª cung váº­t lÃ½.
- CÃ´ng nghá»‡ camera Ä‘iá»‡n thoáº¡i thÃ´ng minh cÃ³ thá»ƒ nháº­n diá»‡n cÃ¡c máº«u hÃ¬nh thá»‹ giÃ¡c phá»©c táº¡p vÃ  Ä‘á» xuáº¥t cÃ¡ch sáº¯p xáº¿p váº­t thá»ƒ hoáº·c trang trÃ­ Ä‘á»ƒ táº¡o ra bá»‘ cá»¥c hÃ i hÃ²a.
- Má»™t há»‡ thá»‘ng há»— trá»£ trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng giÃºp tráº» em phÃ¡t triá»ƒn ká»¹ nÄƒng phÃ¢n biá»‡t thá»‹ giÃ¡c chi tiáº¿t thÃ´ng qua cÃ¡c trÃ² chÆ¡i tÆ°Æ¡ng tÃ¡c, phÃ¡t hiá»‡n sá»± khÃ¡c biá»‡t nhá» giá»¯a cÃ¡c hÃ¬nh áº£nh.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.06521](https://huggingface.co/papers/2601.06521) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.06521](https://arxiv.org/abs/2601.06521) |
| PDF Download | [https://arxiv.org/pdf/2601.06521.pdf](https://arxiv.org/pdf/2601.06521.pdf) |
| Github Repository | [https://github.com/UniPat-AI/BabyVision](https://github.com/UniPat-AI/BabyVision) |

--- 

## 3. PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning *(65 votes)*

**TÃ¡c giáº£:** Jingcheng Hu, Yinmin Zhang, Shijie Shang, Xiaobo Yang, Yue Peng, Zhewei Huang, Hebin Zhou, Xin Wu, Jie Cheng, Fanqi Wan, Xiangwen Kong, Chengyuan Yao, Kaiwen Yan, Ailin Huang, Hongyu Zhou, Qi Han, Zheng Ge, Daxin Jiang, Xiangyu Zhang, Heung-Yeung Shum

**Xuáº¥t báº£n lÃºc:** 2026-01-09

**Tag:** PaCoRe, Language Models, Test-Time Compute, Parallel Reasoning, Reinforcement Learning, Context Window.

### I. Main Problem:
Váº¥n Ä‘á» cá»‘t lÃµi mÃ  bÃ i bÃ¡o Ä‘á» cáº­p lÃ  giá»›i háº¡n cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ hiá»‡n Ä‘áº¡i trong viá»‡c má»Ÿ rá»™ng kháº£ nÄƒng tÃ­nh toÃ¡n trong thá»i gian kiá»ƒm thá»­ (Test-Time Compute - TTC) vÆ°á»£t xa suy luáº­n tuáº§n tá»± trong má»™t cá»­a sá»• ngá»¯ cáº£nh cá»‘ Ä‘á»‹nh, khiáº¿n chÃºng khÃ´ng thá»ƒ giáº£i quyáº¿t hiá»‡u quáº£ cÃ¡c tÃ¡c vá»¥ suy luáº­n phá»©c táº¡p vÃ  dÃ i háº¡n.

### II. Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u PaCoRe (Parallel Coordinated Reasoning), má»™t khung Ä‘Ã o táº¡o vÃ  suy luáº­n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ vÆ°á»£t qua giá»›i háº¡n vá» TTC. PaCoRe chuyá»ƒn Ä‘á»•i tá»« mÃ´ hÃ¬nh tuáº§n tá»± truyá»n thá»‘ng sang thÃºc Ä‘áº©y TTC thÃ´ng qua khÃ¡m phÃ¡ song song quy mÃ´ lá»›n, Ä‘Æ°á»£c Ä‘iá»u phá»‘i qua kiáº¿n trÃºc truyá»n thÃ´ng Ä‘iá»‡p qua nhiá»u vÃ²ng. Má»—i vÃ²ng thá»±c hiá»‡n nhiá»u quá»¹ Ä‘áº¡o suy luáº­n song song, nÃ©n cÃ¡c phÃ¡t hiá»‡n cá»§a chÃºng thÃ nh cÃ¡c thÃ´ng Ä‘iá»‡p cÃ³ giá»›i háº¡n ngá»¯ cáº£nh, vÃ  tá»•ng há»£p cÃ¡c thÃ´ng Ä‘iá»‡p nÃ y Ä‘á»ƒ hÆ°á»›ng dáº«n vÃ²ng tiáº¿p theo vÃ  cuá»‘i cÃ¹ng Ä‘Æ°a ra cÃ¢u tráº£ lá»i cuá»‘i cÃ¹ng. QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c Ä‘Ã o táº¡o end-to-end báº±ng há»c tÄƒng cÆ°á»ng dá»±a trÃªn káº¿t quáº£ quy mÃ´ lá»›n, giÃºp mÃ´ hÃ¬nh náº¯m vá»¯ng kháº£ nÄƒng tá»•ng há»£p cáº§n thiáº¿t.

### III. Main Results:
PaCoRe cho phÃ©p má»Ÿ rá»™ng TTC hiá»‡u quáº£ lÃªn Ä‘áº¿n hÃ ng triá»‡u token mÃ  khÃ´ng vÆ°á»£t quÃ¡ giá»›i háº¡n ngá»¯ cáº£nh. PhÆ°Æ¡ng phÃ¡p nÃ y mang láº¡i nhá»¯ng cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ trÃªn nhiá»u lÄ©nh vá»±c khÃ¡c nhau, Ä‘áº·c biá»‡t lÃ  trong toÃ¡n há»c: má»™t mÃ´ hÃ¬nh PaCoRe-8B Ä‘áº¡t 94.5% trÃªn HMMT 2025, vÆ°á»£t qua GPT-5 (93.2%) báº±ng cÃ¡ch má»Ÿ rá»™ng TTC hiá»‡u quáº£ lÃªn khoáº£ng hai triá»‡u token. CÃ¡c tÃ¡c giáº£ Ä‘Ã£ mÃ£ nguá»“n má»Ÿ cÃ¡c checkpoint mÃ´ hÃ¬nh, dá»¯ liá»‡u Ä‘Ã o táº¡o vÃ  toÃ n bá»™ pipeline suy luáº­n.

### IV. Conclusion & Future Works:
PaCoRe giáº£i quyáº¿t hiá»‡u quáº£ háº¡n cháº¿ cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ vá» kháº£ nÄƒng má»Ÿ rá»™ng TTC do giá»›i háº¡n cá»­a sá»• ngá»¯ cáº£nh, Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t vÆ°á»£t trá»™i thÃ´ng qua suy luáº­n song song vÃ  kháº£ nÄƒng tá»•ng há»£p Ä‘Æ°á»£c Ä‘Ã o táº¡o báº±ng há»c tÄƒng cÆ°á»ng. Viá»‡c cÃ´ng bá»‘ mÃ£ nguá»“n vÃ  dá»¯ liá»‡u sáº½ thÃºc Ä‘áº©y cÃ¡c nghiÃªn cá»©u vÃ  phÃ¡t triá»ƒn tiáº¿p theo trong cá»™ng Ä‘á»“ng.

### V. Brainstorming Space:
#### 1. Publish Papers:
1. NghiÃªn cá»©u cÃ¡c phÆ°Æ¡ng phÃ¡p nÃ©n thÃ´ng Ä‘iá»‡p (message compaction) tiÃªn tiáº¿n hÆ¡n, cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh tÃ³m táº¯t Ä‘á»ƒ giá»¯ láº¡i nhiá»u ngá»¯ cáº£nh quan trá»ng hÆ¡n thay vÃ¬ chá»‰ káº¿t luáº­n cuá»‘i cÃ¹ng.
2. Ãp dá»¥ng PaCoRe vÃ o cÃ¡c lÄ©nh vá»±c khÃ¡c Ä‘Ã²i há»i suy luáº­n dÃ i háº¡n nhÆ° phÃ¢n tÃ­ch tÃ i liá»‡u phÃ¡p lÃ½, phÃ¡t hiá»‡n khoa há»c hoáº·c thiáº¿t káº¿ ká»¹ thuáº­t, Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ trÃªn cÃ¡c táº­p dá»¯ liá»‡u chuyÃªn biá»‡t.
3. KhÃ¡m phÃ¡ cÃ¡c chiáº¿n lÆ°á»£c tá»‘i Æ°u Ä‘á»ƒ Ä‘iá»u chá»‰nh sá»‘ lÆ°á»£ng quá»¹ Ä‘áº¡o song song vÃ  sá»‘ vÃ²ng phá»‘i há»£p cho cÃ¡c loáº¡i váº¥n Ä‘á» khÃ¡c nhau, cÃ³ thá»ƒ tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh dá»±a trÃªn Ä‘á»™ phá»©c táº¡p cá»§a tÃ¡c vá»¥.
#### 2. Patent:
1. Há»‡ thá»‘ng trá»£ lÃ½ áº£o trÃªn Ä‘iá»‡n thoáº¡i sá»­ dá»¥ng kiáº¿n trÃºc PaCoRe Ä‘á»ƒ xá»­ lÃ½ cÃ¡c yÃªu cáº§u Ä‘a bÆ°á»›c, phá»©c táº¡p tá»« ngÆ°á»i dÃ¹ng báº±ng cÃ¡ch phÃ¢n tÃ¡ch vÃ  tá»•ng há»£p thÃ´ng tin song song mÃ  khÃ´ng lÃ m trÃ n bá»™ nhá»› ngá»¯ cáº£nh cá»§a thiáº¿t bá»‹.
2. á»¨ng dá»¥ng giáº£i toÃ¡n hoáº·c láº­p trÃ¬nh trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh tÃ­ch há»£p PaCoRe, cho phÃ©p ngÆ°á»i dÃ¹ng nháº­p cÃ¡c bÃ i toÃ¡n phá»©c táº¡p vÃ  nháº­n Ä‘Æ°á»£c lá»i giáº£i chi tiáº¿t thÃ´ng qua viá»‡c khÃ¡m phÃ¡ nhiá»u phÆ°Æ¡ng Ã¡n giáº£i song song vÃ  nÃ©n káº¿t quáº£ thÃ nh cÃ¡c thÃ´ng Ä‘iá»‡p nhá» gá»n hiá»ƒn thá»‹ trÃªn mÃ n hÃ¬nh di Ä‘á»™ng.
3. CÃ´ng nghá»‡ tá»‘i Æ°u hÃ³a tÃ i nguyÃªn thiáº¿t bá»‹ di Ä‘á»™ng báº±ng cÃ¡ch sá»­ dá»¥ng PaCoRe Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ suy luáº­n náº·ng kÃ½ trong ná»n, phÃ¢n chia cÃ´ng viá»‡c thÃ nh cÃ¡c vÃ²ng xá»­ lÃ½ nhá» gá»n, Ä‘áº£m báº£o hiá»‡u suáº¥t cao vÃ  tiáº¿t kiá»‡m pin trÃªn Ä‘iá»‡n thoáº¡i.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.05593](https://huggingface.co/papers/2601.05593) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.05593](https://arxiv.org/abs/2601.05593) |
| PDF Download | [https://arxiv.org/pdf/2601.05593.pdf](https://arxiv.org/pdf/2601.05593.pdf) |
| Github Repository | [https://github.com/stepfun-ai/PaCoRe](https://github.com/stepfun-ai/PaCoRe) |

--- 

## 4. MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head *(31 votes)*

**TÃ¡c giáº£:** Kewei Zhang, Ye Huang, Yufan Deng, Jincheng Yu, Junsong Chen, Huan Ling, Enze Xie, Daquan Zhou

**Xuáº¥t báº£n lÃºc:** 2026-01-12

**Tag:** Linear Attention, Multi-Head Attention, Expressivity Restoration, Global Context Collapse, Scalability, Transformer

### I. Main Problem:
Kiáº¿n trÃºc Transformer vá»›i cÆ¡ cháº¿ self-attention cÃ³ Ä‘á»™ phá»©c táº¡p vá» thá»i gian vÃ  bá»™ nhá»› lÃ  báº­c hai (quadratic), háº¡n cháº¿ kháº£ nÄƒng má»Ÿ rá»™ng cho cÃ¡c á»©ng dá»¥ng quy mÃ´ lá»›n vÃ  tÃ¡c vá»¥ chuá»—i dÃ i nhÆ° táº¡o áº£nh Ä‘á»™ phÃ¢n giáº£i cao vÃ  táº¡o video. Linear attention cung cáº¥p má»™t giáº£i phÃ¡p thay tháº¿ hiá»‡u quáº£ hÆ¡n vá»›i Ä‘á»™ phá»©c táº¡p tuyáº¿n tÃ­nh, nhÆ°ng láº¡i thÆ°á»ng lÃ m giáº£m hiá»‡u suáº¥t Ä‘Ã¡ng ká»ƒ do máº¥t Ä‘i kháº£ nÄƒng thÃ­ch á»©ng vá»›i tá»«ng truy váº¥n riÃªng láº». Váº¥n Ä‘á» cá»‘t lÃµi nÃ y Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  "global context collapse", nÆ¡i mÃ´ hÃ¬nh máº¥t Ä‘i sá»± Ä‘a dáº¡ng trong biá»ƒu diá»…n thÃ´ng tin. CÃ¡c giáº£i phÃ¡p hiá»‡n cÃ³ thÆ°á»ng tÃ¡i táº¡o chi phÃ­ tÃ­nh toÃ¡n thÃ´ng qua cÃ¡c module bá»• sung, lÃ m máº¥t Ä‘i má»¥c Ä‘Ã­ch ban Ä‘áº§u vá» hiá»‡u quáº£.

### II. Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t Multi-Head Linear Attention (MHLA) nháº±m khÃ´i phá»¥c kháº£ nÄƒng biá»ƒu cáº£m cá»§a linear attention mÃ  váº«n duy trÃ¬ Ä‘á»™ phá»©c táº¡p tuyáº¿n tÃ­nh vÃ  khÃ´ng cáº§n cÃ¡c module bá»• sung. MHLA giáº£i quyáº¿t váº¥n Ä‘á» "global context collapse" báº±ng cÃ¡ch chia cÃ¡c token thÃ nh cÃ¡c "heads" (khá»‘i) khÃ´ng trÃ¹ng láº·p theo chiá»u token. Vá»›i má»—i khá»‘i, MHLA tÃ­nh toÃ¡n cÃ¡c tÃ³m táº¯t key-value cá»¥c bá»™. Sau Ä‘Ã³, má»—i khá»‘i truy váº¥n sáº½ tÃ­nh toÃ¡n má»™t há»—n há»£p cÃ¡c tÃ³m táº¯t key-value cá»¥c bá»™ Ä‘Æ°á»£c Ä‘iá»u kiá»‡n bá»Ÿi truy váº¥n, cho phÃ©p khÃ´i phá»¥c sá»± Ä‘a dáº¡ng biá»ƒu diá»…n vÃ  tÃ­nh chá»n lá»c phá»¥ thuá»™c vÃ o truy váº¥n. QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a vá»›i Ä‘á»™ phá»©c táº¡p O(N) vÃ  chá»‰ dá»±a vÃ o cÃ¡c phÃ©p toÃ¡n nhÃ¢n ma tráº­n tá»•ng quÃ¡t (GEMM) tiÃªu chuáº©n.

### III. Main Results:
MHLA Ä‘Ã£ chá»©ng minh hiá»‡u quáº£ vÆ°á»£t trá»™i so vá»›i cÃ¡c baseline linear attention hiá»‡n cÃ³ vá»›i chi phÃ­ tÃ­nh toÃ¡n khÃ´ng Ä‘Ã¡ng ká»ƒ. NÃ³ khÃ´i phá»¥c pháº§n lá»›n sá»©c máº¡nh biá»ƒu cáº£m cá»§a softmax attention trong khi duy trÃ¬ Ä‘á»™ phá»©c táº¡p tuyáº¿n tÃ­nh. CÃ¡c káº¿t quáº£ chÃ­nh bao gá»“m:
*   Cáº£i thiá»‡n 3.6% trÃªn tÃ¡c vá»¥ phÃ¢n loáº¡i ImageNet.
*   TÄƒng 6.3% trÃªn tÃ¡c vá»¥ Xá»­ lÃ½ NgÃ´n ngá»¯ Tá»± nhiÃªn (NLP).
*   Cáº£i thiá»‡n 12.6% trÃªn tÃ¡c vá»¥ táº¡o áº£nh.
*   TÄƒng cÆ°á»ng 41% trÃªn tÃ¡c vá»¥ táº¡o video so vá»›i linear attention thÃ´ng thÆ°á»ng, táº¥t cáº£ Ä‘á»u trong cÃ¹ng Ä‘á»™ phá»©c táº¡p thá»i gian.
MHLA cÅ©ng Ä‘Æ°á»£c chá»©ng minh lÃ  lÃ m tÄƒng Ä‘Ã¡ng ká»ƒ "rank" cá»§a ma tráº­n trá»ng sá»‘ attention vÃ  giáº£m "entropy", cho tháº¥y kháº£ nÄƒng chÃº Ã½ phong phÃº vÃ  táº­p trung hÆ¡n.

### IV. Conclusion & Future Works:
MHLA lÃ  má»™t giáº£i phÃ¡p hiá»‡u quáº£ cho váº¥n Ä‘á» "global context collapse" trong linear attention, khÃ´i phá»¥c kháº£ nÄƒng biá»ƒu cáº£m vÃ  sá»± Ä‘a dáº¡ng token-level mÃ  váº«n duy trÃ¬ Ä‘á»™ phá»©c táº¡p tuyáº¿n tÃ­nh. PhÆ°Æ¡ng phÃ¡p nÃ y trÃ¡nh Ä‘Æ°á»£c viá»‡c thÃªm cÃ¡c module phá»¥ trá»£, khiáº¿n nÃ³ trá»Ÿ thÃ nh má»™t lá»±a chá»n máº¡nh máº½ Ä‘á»ƒ má»Ÿ rá»™ng cÃ¡c mÃ´ hÃ¬nh Transformer cho cÃ¡c tÃ¡c vá»¥ chuá»—i dÃ i vÃ  dá»¯ liá»‡u lá»›n.

### V. Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u sá»± káº¿t há»£p cá»§a MHLA vá»›i cÃ¡c ká»¹ thuáº­t nÃ©n mÃ´ hÃ¬nh (pruning, quantization) Ä‘á»ƒ triá»ƒn khai hiá»‡u quáº£ trÃªn cÃ¡c thiáº¿t bá»‹ tÃ i nguyÃªn háº¡n cháº¿.
*   KhÃ¡m phÃ¡ á»©ng dá»¥ng cá»§a MHLA trong cÃ¡c lÄ©nh vá»±c má»›i nhÆ° phÃ¢n tÃ­ch dá»¯ liá»‡u chuá»—i thá»i gian hoáº·c mÃ´ hÃ¬nh hÃ³a Ä‘á»“ thá»‹.
*   PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng sÃ¢u hÆ¡n vá» má»‘i quan há»‡ giá»¯a sá»‘ lÆ°á»£ng "heads" trong MHLA vÃ  hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn cÃ¡c loáº¡i dá»¯ liá»‡u khÃ¡c nhau.

#### 2. Patent:
*   Há»‡ thá»‘ng camera an ninh trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh sá»­ dá»¥ng MHLA Ä‘á»ƒ phÃ¢n tÃ­ch vÃ  nháº­n diá»‡n hÃ nh vi báº¥t thÆ°á»ng trong chuá»—i video dÃ i theo thá»i gian thá»±c mÃ  váº«n tiáº¿t kiá»‡m pin.
*   CÃ´ng nghá»‡ hiá»ƒn thá»‹ thÃ´ng tin Ä‘á»™ng trÃªn mÃ n hÃ¬nh Ä‘iá»‡n thoáº¡i, tá»± Ä‘á»™ng tá»•ng há»£p vÃ  hiá»ƒn thá»‹ cÃ¡c ná»™i dung quan trá»ng tá»« nhiá»u nguá»“n dá»¯ liá»‡u chuá»—i dÃ i báº±ng MHLA.
*   á»¨ng dá»¥ng chá»‰nh sá»­a Ã¢m thanh chuyÃªn nghiá»‡p trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng, sá»­ dá»¥ng MHLA Ä‘á»ƒ xá»­ lÃ½ vÃ  táº¡o hiá»‡u á»©ng cho cÃ¡c báº£n ghi Ã¢m dÃ i vá»›i Ä‘á»™ chÃ­nh xÃ¡c cao vÃ  tá»‘c Ä‘á»™ nhanh.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.07832](https://huggingface.co/papers/2601.07832) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.07832](https://arxiv.org/abs/2601.07832) |
| PDF Download | [https://arxiv.org/pdf/2601.07832.pdf](https://arxiv.org/pdf/2601.07832.pdf) |
| Github Repository | [https://github.com/DAGroup-PKU/MHLA](https://github.com/DAGroup-PKU/MHLA) |

--- 

## 5. X-Coder: Advancing Competitive Programming with Fully Synthetic Tasks, Solutions, and Tests *(30 votes)*

**TÃ¡c giáº£:** Jie Wu, Haoling Li, Xin Zhang, Jiani Guo, Jane Luo, Steven Liu, Yangyu Huang, Ruihang Chu, Scarlett Li, Yujiu Yang

**Xuáº¥t báº£n lÃºc:** 2026-01-11

**Tag:** Competitive Programming, Code LLMs, Synthetic Data Generation, Supervised Fine-tuning (SFT), Reinforcement Learning (RL), Code Reasoning
### I. Main Problem:
CÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ mÃ£ (Code LLMs) hiá»‡n táº¡i gáº·p thÃ¡ch thá»©c lá»›n vá»›i láº­p trÃ¬nh cáº¡nh tranh do nhu cáº§u suy luáº­n chuyÃªn sÃ¢u vÃ  Ä‘á»™ phá»©c táº¡p logic cao. Sá»± phá»¥ thuá»™c náº·ng ná» vÃ o dá»¯ liá»‡u thá»±c táº¿ Ä‘Ã£ háº¡n cháº¿ kháº£ nÄƒng má»Ÿ rá»™ng cá»§a chÃºng. CÃ¡c bá»™ dá»¯ liá»‡u láº­p trÃ¬nh cáº¡nh tranh hiá»‡n cÃ³ ráº¥t khan hiáº¿m, thÆ°á»ng Ä‘Æ°á»£c tÃ¡i sá»­ dá»¥ng vÃ  khÃ´ng Ä‘á»§ quy mÃ´, Ä‘á»™ khÃ³ cÅ©ng nhÆ° sá»± Ä‘a dáº¡ng Ä‘á»ƒ há»— trá»£ viá»‡c cáº£i thiá»‡n liÃªn tá»¥c cÃ¡c Code LLM. Viá»‡c thu tháº­p dá»¯ liá»‡u thá»±c táº¿ má»›i cÅ©ng ráº¥t khÃ³ khÄƒn, vÃ  cÃ¡c biáº¿n thá»ƒ dá»¯ liá»‡u Ä‘Æ°á»£c tá»•ng há»£p tá»« cÃ¡c tÃ i nguyÃªn hiá»‡n cÃ³ bá»‹ giá»›i háº¡n bá»Ÿi cÃ¡c nhiá»‡m vá»¥ gá»‘c.

### II. Main Idea:
BÃ i nghiÃªn cá»©u khÃ¡m phÃ¡ má»™t cÃ¡ch tiáº¿p cáº­n hoÃ n toÃ n tá»•ng há»£p: huáº¥n luyá»‡n Code LLM báº±ng cÃ¡c tÃ¡c vá»¥, giáº£i phÃ¡p vÃ  bá»™ kiá»ƒm thá»­ Ä‘Æ°á»£c táº¡o hoÃ n toÃ n, mÃ  khÃ´ng cáº§n dá»±a vÃ o dá»¯ liá»‡u thá»±c táº¿. Äá»ƒ Ä‘áº¡t Ä‘Æ°á»£c Ä‘iá»u nÃ y, bÃ i bÃ¡o Ä‘á» xuáº¥t má»™t quy trÃ¬nh tá»•ng há»£p dá»¯ liá»‡u má»›i cÃ³ tÃªn SynthSmith, sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p tá»•ng há»£p dá»±a trÃªn tÃ­nh nÄƒng. SynthSmith Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ táº¡o ra cÃ¡c tÃ¡c vá»¥ Ä‘a dáº¡ng vÃ  thÃ¡ch thá»©c trong láº­p trÃ¬nh cáº¡nh tranh, cÃ¹ng vá»›i cÃ¡c giáº£i phÃ¡p vÃ  kiá»ƒm thá»­ Ä‘Ã£ Ä‘Æ°á»£c xÃ¡c minh, há»— trá»£ cáº£ huáº¥n luyá»‡n tinh chá»‰nh cÃ³ giÃ¡m sÃ¡t (SFT) vÃ  há»c tÄƒng cÆ°á»ng (RL).

Quy trÃ¬nh SynthSmith bao gá»“m bá»‘n bÆ°á»›c chÃ­nh:
1.  **Táº¡o tÃ¡c vá»¥:** TrÃ­ch xuáº¥t vÃ  phÃ¡t triá»ƒn cÃ¡c tÃ­nh nÄƒng liÃªn quan Ä‘áº¿n láº­p trÃ¬nh cáº¡nh tranh tá»« cÃ¡c Ä‘oáº¡n mÃ£ nhá», sau Ä‘Ã³ káº¿t há»£p chÃºng vÃ o cáº¥u trÃºc cÃ¢y Ä‘á»ƒ táº¡o ra cÃ¡c ká»‹ch báº£n váº¥n Ä‘á» má»›i máº» vÃ  Ä‘áº§y thÃ¡ch thá»©c theo nhiá»u phong cÃ¡ch khÃ¡c nhau (nhÆ° Codeforces, LeetCode, AtCoder).
2.  **Táº¡o Ä‘áº§u vÃ o kiá»ƒm thá»­:** Sá»­ dá»¥ng cáº£ phÆ°Æ¡ng phÃ¡p dá»±a trÃªn gá»£i Ã½ (prompting) vÃ  dá»±a trÃªn cÃ´ng cá»¥ (tool-based, vÃ­ dá»¥ nhÆ° CYaRon) Ä‘á»ƒ táº¡o ra cÃ¡c bá»™ Ä‘áº§u vÃ o kiá»ƒm thá»­ Ä‘a dáº¡ng vÃ  toÃ n diá»‡n, bao gá»“m cáº£ cÃ¡c trÆ°á»ng há»£p tiÃªu chuáº©n vÃ  trÆ°á»ng há»£p biÃªn.
3.  **Táº¡o giáº£i phÃ¡p á»©ng viÃªn:** Táº¡o ra nhiá»u giáº£i phÃ¡p á»©ng viÃªn cho má»—i tÃ¡c vá»¥ báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) suy luáº­n tiÃªn tiáº¿n, Ä‘áº£m báº£o má»—i giáº£i phÃ¡p bao gá»“m quy trÃ¬nh suy luáº­n Ä‘áº§y Ä‘á»§ vÃ  triá»ƒn khai mÃ£ Python khÃ´ng cÃ³ lá»—i cÃº phÃ¡p.
4.  **XÃ¡c minh kÃ©p giáº£i phÃ¡p vÃ  kiá»ƒm thá»­:**
    *   **BÆ°á»›c 1:** XÃ¡c minh cÃ¡c trÆ°á»ng há»£p kiá»ƒm thá»­ thÃ´ng qua bá» phiáº¿u Ä‘á»“ng thuáº­n tá»« nhiá»u giáº£i phÃ¡p á»©ng viÃªn Ä‘á»ƒ xÃ¡c Ä‘á»‹nh káº¿t quáº£ Ä‘áº§u ra Ä‘Ãºng táº¡m thá»i, Ä‘á»“ng thá»i gÃ¡n trá»ng sá»‘ cho cÃ¡c trÆ°á»ng há»£p kiá»ƒm thá»­ dá»±a trÃªn Ä‘á»™ khÃ³.
    *   **BÆ°á»›c 2:** XÃ¡c minh cÃ¡c giáº£i phÃ¡p báº±ng cÃ¡ch Ä‘Ã¡nh giÃ¡ cÃ³ trá»ng sá»‘ trÃªn bá»™ kiá»ƒm thá»­ chÃ­nh vÃ  xÃ¡c thá»±c trÃªn má»™t táº­p kiá»ƒm tra Ä‘á»™c láº­p (hold-out validation set) Ä‘á»ƒ chá»n ra giáº£i phÃ¡p "vÃ ng" (golden solution) Ä‘Ã¡ng tin cáº­y vÃ  cÃ³ kháº£ nÄƒng khÃ¡i quÃ¡t hÃ³a.

Dá»±a trÃªn dá»¯ liá»‡u tá»•ng há»£p cháº¥t lÆ°á»£ng cao nÃ y, bÃ i bÃ¡o giá»›i thiá»‡u dÃ²ng mÃ´ hÃ¬nh X-Coder, Ä‘Æ°á»£c huáº¥n luyá»‡n theo mÃ´ hÃ¬nh SFT-sau-Ä‘Ã³-RL (SFT-then-RL), nháº±m Ä‘áº¡t Ä‘Æ°á»£c nhá»¯ng cáº£i tiáº¿n Ä‘Ã¡ng ká»ƒ vá» hiá»‡u suáº¥t trong láº­p trÃ¬nh cáº¡nh tranh.

### III. Main Results:
*   **Hiá»‡u suáº¥t vÆ°á»£t trá»™i:** DÃ²ng mÃ´ hÃ¬nh X-Coder, Ä‘áº·c biá»‡t lÃ  X-Coder-7B, Ä‘áº¡t tá»· lá»‡ vÆ°á»£t qua áº¥n tÆ°á»£ng 62.9 avg@8 trÃªn LiveCodeBench v5 vÃ  55.8 avg@8 trÃªn v6.
*   **VÆ°á»£t qua cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n:** X-Coder-7B, vá»›i chá»‰ 7B tham sá»‘, vÆ°á»£t trá»™i hÆ¡n cÃ¡c mÃ´ hÃ¬nh lá»›n hÆ¡n nhÆ° DeepCoder-14B-Preview vÃ  AReal-boba-14B, cÅ©ng nhÆ° cÃ¡c mÃ´ hÃ¬nh cÃ¹ng kÃ­ch thÆ°á»›c khÃ¡c trÃªn cáº£ hai phiÃªn báº£n LiveCodeBench.
*   **Quy luáº­t má»Ÿ rá»™ng:** CÃ¡c quy luáº­t má»Ÿ rá»™ng Ä‘Æ°á»£c duy trÃ¬ trÃªn bá»™ dá»¯ liá»‡u tá»•ng há»£p, vÃ  nghiÃªn cá»©u Ä‘Ã£ khÃ¡m phÃ¡ nhá»¯ng chiá»u má»Ÿ rá»™ng hiá»‡u quáº£ hÆ¡n.
*   **Hiá»ƒu biáº¿t sÃ¢u sáº¯c vá» RL:** Cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t vá» há»c tÄƒng cÆ°á»ng táº­p trung vÃ o mÃ£, bao gá»“m nguyÃªn táº¯c "tá»‘t hÆ¡n sáº½ tá»‘t hÆ¡n" vÃ  kháº£ nÄƒng phá»¥c há»“i cá»§a RL trÆ°á»›c sá»± giÃ¡m sÃ¡t nhiá»…u.
*   **PhÃ¢n tÃ­ch yáº¿u tá»‘ hiá»‡u suáº¥t:** NghiÃªn cá»©u phÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ chÃ­nh Ä‘á»‹nh hÃ¬nh hiá»‡u suáº¥t, bao gá»“m Ä‘á»™ dÃ i cá»§a Chain-of-Thought (CoT), áº£nh hÆ°á»Ÿng cá»§a viá»‡c xÃ¡c minh giáº£i phÃ¡p, phong cÃ¡ch tÃ¡c vá»¥ vÃ  chiáº¿n lÆ°á»£c chá»n dá»¯ liá»‡u.
*   **Äiá»ƒm ngháº½n vÃ  má»‘i quan há»‡:** KhÃ¡m phÃ¡ cÃ¡c Ä‘iá»ƒm ngháº½n giá»›i háº¡n kháº£ nÄƒng suy luáº­n mÃ£ vÃ  má»‘i quan há»‡ dÃ¢y chuyá»n giá»¯a Ä‘á»™ khÃ³ tÃ¡c vá»¥, Ä‘á»™ dÃ i suy luáº­n vÃ  tá»· lá»‡ vÆ°á»£t qua.
*   **HÃ nh vi nháº­n thá»©c:** CÃ¡c nghiÃªn cá»©u Ä‘iá»ƒn hÃ¬nh Ä‘Ã£ phÃ¡t hiá»‡n cÃ¡c hÃ nh vi nháº­n thá»©c má»›i ná»•i sau SFT vÃ  RL, cháº³ng háº¡n nhÆ° "pháº§n thÆ°á»Ÿng gian láº­n" (reward hacking) vÃ  cÃ¡c mÃ´ hÃ¬nh khÃ´ng mong muá»‘n.

### IV. Conclusion & Future Works:
**Káº¿t luáº­n:** Viá»‡c má»Ÿ rá»™ng quy mÃ´ dá»¯ liá»‡u tá»•ng há»£p cháº¥t lÆ°á»£ng cao vÃ  Ã¡p dá»¥ng huáº¥n luyá»‡n theo giai Ä‘oáº¡n (SFT-then-RL) cÃ³ thá»ƒ thÃºc Ä‘áº©y Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng suy luáº­n mÃ£, Ä‘á»“ng thá»i giáº£m bá»›t sá»± phá»¥ thuá»™c vÃ o dá»¯ liá»‡u mÃ£ thá»±c táº¿. CÃ¡ch tiáº¿p cáº­n tá»•ng há»£p hoÃ n toÃ n vÃ  quy trÃ¬nh SynthSmith chá»©ng minh tiá»m nÄƒng máº¡nh máº½ trong viá»‡c táº¡o ra dá»¯ liá»‡u láº­p trÃ¬nh cáº¡nh tranh Ä‘a dáº¡ng vÃ  thÃ¡ch thá»©c.

**HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo (ngá»¥ Ã½):** Cáº§n nghiÃªn cá»©u sÃ¢u hÆ¡n vá» cÃ¡c chiáº¿n lÆ°á»£c RL Ä‘á»ƒ giáº£m thiá»ƒu cÃ¡c hÃ nh vi tiÃªu cá»±c nhÆ° "pháº§n thÆ°á»Ÿng gian láº­n" Ä‘Ã£ Ä‘Æ°á»£c quan sÃ¡t. NgoÃ i ra, viá»‡c tiáº¿p tá»¥c khÃ¡m phÃ¡ cÃ¡c chiá»u má»Ÿ rá»™ng hiá»‡u quáº£ cá»§a dá»¯ liá»‡u tá»•ng há»£p vÃ  cáº£i thiá»‡n sá»± hiá»ƒu biáº¿t vá» má»‘i quan há»‡ giá»¯a Ä‘á»™ khÃ³ tÃ¡c vá»¥, Ä‘á»™ dÃ i suy luáº­n vÃ  tá»· lá»‡ vÆ°á»£t qua bÃ i kiá»ƒm thá»­ lÃ  nhá»¯ng lÄ©nh vá»±c tiá»m nÄƒng cho nghiÃªn cá»©u trong tÆ°Æ¡ng lai.

### V. Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a viá»‡c phÃ¡t hiá»‡n vÃ  giáº£m thiá»ƒu cÃ¡c hÃ nh vi khÃ´ng mong muá»‘n nhÆ° reward hacking trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ mÃ£ Ä‘Æ°á»£c huáº¥n luyá»‡n báº±ng dá»¯ liá»‡u tá»•ng há»£p.
*   KhÃ¡m phÃ¡ hiá»‡u quáº£ cá»§a viá»‡c tá»•ng há»£p dá»¯ liá»‡u láº­p trÃ¬nh cáº¡nh tranh Ä‘a ngÃ´n ngá»¯ Ä‘á»ƒ nÃ¢ng cao kháº£ nÄƒng suy luáº­n cá»§a Code LLM trÃªn cÃ¡c ngÃ´n ngá»¯ láº­p trÃ¬nh khÃ¡c nhau.
*   PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng vÃ  Ä‘á»‹nh tÃ­nh vá» má»‘i quan há»‡ giá»¯a Ä‘á»™ khÃ³ cá»§a nhiá»‡m vá»¥ tá»•ng há»£p, Ä‘á»™ dÃ i chuá»—i suy luáº­n vÃ  tá»· lá»‡ vÆ°á»£t qua bÃ i kiá»ƒm tra Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c táº¡o dá»¯ liá»‡u.

#### 2. Patent:
*   Há»‡ thá»‘ng vÃ  phÆ°Æ¡ng phÃ¡p táº¡o tá»± Ä‘á»™ng cÃ¡c bÃ i toÃ¡n láº­p trÃ¬nh cáº¡nh tranh Ä‘a dáº¡ng, giáº£i phÃ¡p vÃ  bá»™ kiá»ƒm thá»­ hoÃ n toÃ n tá»•ng há»£p cho viá»‡c huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh AI trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng.
*   PhÆ°Æ¡ng phÃ¡p xÃ¡c minh kÃ©p cÃ¡c giáº£i phÃ¡p vÃ  bá»™ kiá»ƒm thá»­ cho cÃ¡c bÃ i toÃ¡n láº­p trÃ¬nh báº±ng cÃ¡ch sá»­ dá»¥ng bá» phiáº¿u Ä‘á»“ng thuáº­n vÃ  Ä‘Ã¡nh giÃ¡ cÃ³ trá»ng sá»‘ Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ tin cáº­y khi triá»ƒn khai trÃªn thiáº¿t bá»‹ di Ä‘á»™ng.
*   Giao thá»©c huáº¥n luyá»‡n xáº¿p táº§ng (SFT-then-RL) Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a cho cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ mÃ£ trÃªn ná»n táº£ng di Ä‘á»™ng, cho phÃ©p nÃ¢ng cao kháº£ nÄƒng suy luáº­n mÃ£ vá»›i dá»¯ liá»‡u tá»•ng há»£p vÃ  tÃ i nguyÃªn tÃ­nh toÃ¡n háº¡n cháº¿.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.06953](https://huggingface.co/papers/2601.06953) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.06953](https://arxiv.org/abs/2601.06953) |
| PDF Download | [https://arxiv.org/pdf/2601.06953.pdf](https://arxiv.org/pdf/2601.06953.pdf) |
| Github Repository | [https://github.com/JieWu02/X-Coder](https://github.com/JieWu02/X-Coder) |

--- 

## 6. GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts *(26 votes)*

**TÃ¡c giáº£:** Wenhao Zeng, Xuteng Zhang, Yuling Shi, Chao Hu, Yuting Chen, Beijun Shen, Xiaodong Gu

**Xuáº¥t báº£n lÃºc:** 2026-01-08

**Tag:** Large Language Models, Collaborative Inference, Reasoning, Latency Reduction, Entropy-based Routing

### I. Main Problem:
CÃ¡c mÃ´ hÃ¬nh suy luáº­n lá»›n (LRMs) Ä‘áº¡t hiá»‡u suáº¥t vÆ°á»£t trá»™i thÃ´ng qua viá»‡c táº¡o ra chuá»—i suy luáº­n nhiá»u bÆ°á»›c, nhÆ°ng kháº£ nÄƒng nÃ y láº¡i Ä‘i kÃ¨m vá»›i Ä‘á»™ trá»… suy luáº­n vÃ  chi phÃ­ tÃ­nh toÃ¡n Ä‘Ã¡ng ká»ƒ. Máº·c dÃ¹ suy luáº­n cá»™ng tÃ¡c há»©a háº¹n má»™t giáº£i phÃ¡p báº±ng cÃ¡ch phÃ¢n bá»• cÃ´ng viá»‡c giá»¯a cÃ¡c mÃ´ hÃ¬nh nháº¹ vÃ  mÃ´ hÃ¬nh lá»›n, thÃ¡ch thá»©c cÆ¡ báº£n váº«n lÃ  xÃ¡c Ä‘á»‹nh khi nÃ o má»™t bÆ°á»›c suy luáº­n cáº§n kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh lá»›n hay hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh nhá». CÃ¡c chiáº¿n lÆ°á»£c Ä‘á»‹nh tuyáº¿n hiá»‡n cÃ³ thÆ°á»ng dá»±a vÃ o xÃ¡c suáº¥t token cá»¥c bá»™ hoáº·c xÃ¡c minh sau quÃ¡ trÃ¬nh, Ä‘iá»u nÃ y gÃ¢y ra chi phÃ­ suy luáº­n Ä‘Ã¡ng ká»ƒ.

### II. Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t GlimpRouter, má»™t khung suy luáº­n cá»™ng tÃ¡c tá»«ng bÆ°á»›c khÃ´ng cáº§n huáº¥n luyá»‡n, dá»±a trÃªn quan Ä‘iá»ƒm má»›i ráº±ng Ä‘á»™ khÃ³ cá»§a má»™t bÆ°á»›c suy luáº­n cÃ³ thá»ƒ Ä‘Æ°á»£c suy ra tá»« token Ä‘áº§u tiÃªn cá»§a nÃ³. Láº¥y cáº£m há»©ng tá»« hiá»‡n tÆ°á»£ng "Aha Moment" trong LRMs, cÃ¡c tÃ¡c giáº£ chá»©ng minh ráº±ng entropy cá»§a token khá»Ÿi táº¡o (Hinit) lÃ  má»™t chá»‰ sá»‘ dá»± Ä‘oÃ¡n máº¡nh máº½ vá» Ä‘á»™ khÃ³ cá»§a bÆ°á»›c. GlimpRouter sá»­ dá»¥ng má»™t mÃ´ hÃ¬nh trá»ng lÆ°á»£ng nháº¹ Ä‘á»ƒ chá»‰ táº¡o ra token Ä‘áº§u tiÃªn cá»§a má»—i bÆ°á»›c suy luáº­n. Náº¿u entropy cá»§a token khá»Ÿi táº¡o nÃ y vÆ°á»£t quÃ¡ má»™t ngÆ°á»¡ng nháº¥t Ä‘á»‹nh, bÆ°á»›c suy luáº­n sáº½ Ä‘Æ°á»£c chuyá»ƒn cho má»™t mÃ´ hÃ¬nh lá»›n hÆ¡n; ngÆ°á»£c láº¡i, mÃ´ hÃ¬nh nháº¹ sáº½ tiáº¿p tá»¥c táº¡o ra toÃ n bá»™ bÆ°á»›c. CÆ¡ cháº¿ nÃ y giÃºp phÃ¢n bá»• tÃ­nh toÃ¡n hiá»‡u quáº£ dá»±a trÃªn "má»™t cÃ¡i nhÃ¬n thoÃ¡ng qua vá» suy nghÄ©" thay vÃ¬ Ä‘Ã¡nh giÃ¡ toÃ n bá»™ bÆ°á»›c.

### III. Main Results:
- GlimpRouter giáº£m Ä‘Ã¡ng ká»ƒ Ä‘á»™ trá»… suy luáº­n trong khi váº«n duy trÃ¬ Ä‘á»™ chÃ­nh xÃ¡c hoáº·c tháº­m chÃ­ cáº£i thiá»‡n nÃ³.
- TrÃªn benchmark AIME25, GlimpRouter Ä‘áº¡t cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ 10.7% vá» Ä‘á»™ chÃ­nh xÃ¡c vÃ  giáº£m 25.9% Ä‘á»™ trá»… suy luáº­n so vá»›i mÃ´ hÃ¬nh lá»›n Ä‘á»™c láº­p.
- PhÃ¢n tÃ­ch cho tháº¥y entropy cá»§a token khá»Ÿi táº¡o (Hinit) cÃ³ phÃ¢n bá»‘ hai Ä‘á»‰nh vÃ  Ä‘uÃ´i náº·ng, cho tháº¥y nÃ³ lÃ  má»™t tÃ­n hiá»‡u phÃ¢n biá»‡t Ä‘á»™ khÃ³ máº¡nh máº½, khÃ´ng giá»‘ng nhÆ° cÃ¡c chá»‰ sá»‘ khÃ¡c cÃ³ phÃ¢n bá»‘ Ä‘Æ¡n Ä‘á»‰nh háº¹p.
- Quan sÃ¡t tháº¥y má»‘i tÆ°Æ¡ng quan Ã¢m má»™t cÃ¡ch Ä‘Æ¡n Ä‘iá»‡u vÃ  cháº·t cháº½ giá»¯a Hinit vÃ  má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh nhá» vÃ  mÃ´ hÃ¬nh lá»›n (Ä‘Æ°á»£c Ä‘o báº±ng BLEU-4 vÃ  SBERT), kháº³ng Ä‘á»‹nh ráº±ng cÃ¡c bÆ°á»›c cÃ³ Hinit tháº¥p cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ hÃ¬nh nháº¹ xá»­ lÃ½ hiá»‡u quáº£ mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n káº¿t quáº£.

### IV. Conclusion & Future Works:
BÃ i bÃ¡o káº¿t luáº­n ráº±ng GlimpRouter cung cáº¥p má»™t cÆ¡ cháº¿ Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£ Ä‘á»ƒ phÃ¢n bá»• tÃ i nguyÃªn tÃ­nh toÃ¡n dá»±a trÃªn má»™t tÃ­n hiá»‡u tá»‘i thiá»ƒu tá»« sá»± khá»Ÿi Ä‘áº§u cá»§a má»™t bÆ°á»›c suy luáº­n. Äiá»u nÃ y giÃºp giáº£m Ä‘Ã¡ng ká»ƒ Ä‘á»™ trá»… suy luáº­n trong khi duy trÃ¬ hoáº·c nÃ¢ng cao hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh suy luáº­n lá»›n (LRMs), mang láº¡i má»™t giáº£i phÃ¡p thiáº¿t thá»±c cho viá»‡c triá»ƒn khai chÃºng. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ bao gá»“m viá»‡c khÃ¡m phÃ¡ cÃ¡ch tÃ­ch há»£p chiáº¿n lÆ°á»£c Ä‘á»‹nh tuyáº¿n cáº¥p Ä‘á»™ bÆ°á»›c nÃ y vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p giáº£i mÃ£ suy Ä‘oÃ¡n cáº¥p Ä‘á»™ token Ä‘á»ƒ táº¡o ra tá»‘c Ä‘á»™ tÄƒng tá»‘c bá»• sung vÃ  tá»•ng há»£p.

### V. Brainstorming Space:
#### 1. Publish Papers:
- NghiÃªn cá»©u sÃ¢u hÆ¡n vá» má»‘i quan há»‡ giá»¯a cÃ¡c tÃ­n hiá»‡u "Aha Moment" vÃ  cáº¥u trÃºc ná»™i táº¡i cá»§a cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘á»ƒ phÃ¡t triá»ƒn cÃ¡c chá»‰ sá»‘ Ä‘á»™ khÃ³ tinh vi hÆ¡n.
- PhÃ¡t triá»ƒn má»™t phÆ°Æ¡ng phÃ¡p thÃ­ch á»©ng Ä‘á»ƒ tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh ngÆ°á»¡ng entropy trong GlimpRouter dá»±a trÃªn cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a tÃ¡c vá»¥ hoáº·c pháº£n há»“i thá»i gian thá»±c.
- Má»Ÿ rá»™ng GlimpRouter sang cÃ¡c nhiá»‡m vá»¥ suy luáº­n Ä‘a phÆ°Æ¡ng thá»©c báº±ng cÃ¡ch tÃ­ch há»£p thÃ´ng tin Ä‘á»™ khÃ³ tá»« cÃ¡c dáº¡ng dá»¯ liá»‡u khÃ¡c nhau vÃ o quyáº¿t Ä‘á»‹nh Ä‘á»‹nh tuyáº¿n.

#### 2. Patent:
- Há»‡ thá»‘ng quáº£n lÃ½ nÄƒng lÆ°á»£ng thÃ´ng minh cho Ä‘iá»‡n thoáº¡i di Ä‘á»™ng, sá»­ dá»¥ng GlimpRouter Ä‘á»ƒ phÃ¢n luá»“ng cÃ¡c yÃªu cáº§u tá»« trá»£ lÃ½ áº£o hoáº·c á»©ng dá»¥ng AI sang mÃ´ hÃ¬nh trÃªn thiáº¿t bá»‹ (tiÃªu thá»¥ Ã­t nÄƒng lÆ°á»£ng) hoáº·c mÃ´ hÃ¬nh Ä‘Ã¡m mÃ¢y (tiÃªu thá»¥ nhiá»u nÄƒng lÆ°á»£ng) dá»±a trÃªn Ä‘á»™ phá»©c táº¡p cá»§a yÃªu cáº§u.
- CÃ´ng nghá»‡ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t á»©ng dá»¥ng AI trÃªn thiáº¿t bá»‹ di Ä‘á»™ng, tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c phiÃªn báº£n mÃ´ hÃ¬nh ngÃ´n ngá»¯ khÃ¡c nhau (nháº¹ vÃ  náº·ng) dá»±a trÃªn entropy cá»§a token Ä‘áº§u tiÃªn Ä‘Æ°á»£c dá»± Ä‘oÃ¡n, nháº±m cung cáº¥p pháº£n há»“i nhanh chÃ³ng vÃ  duy trÃ¬ tuá»•i thá» pin.
- PhÆ°Æ¡ng phÃ¡p Ä‘iá»u khiá»ƒn chip xá»­ lÃ½ AI trÃªn Ä‘iá»‡n thoáº¡i, tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh táº§n sá»‘ hoáº·c kÃ­ch hoáº¡t cÃ¡c nhÃ¢n xá»­ lÃ½ chuyÃªn dá»¥ng dá»±a trÃªn ngÆ°á»¡ng Hinit Ä‘Æ°á»£c tÃ­nh toÃ¡n, Ä‘áº£m báº£o tÃ i nguyÃªn Ä‘Æ°á»£c phÃ¢n bá»• hiá»‡u quáº£ chá»‰ khi cáº§n thiáº¿t cho cÃ¡c tÃ¡c vá»¥ suy luáº­n phá»©c táº¡p.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.05110](https://huggingface.co/papers/2601.05110) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.05110](https://arxiv.org/abs/2601.05110) |
| PDF Download | [https://arxiv.org/pdf/2601.05110.pdf](https://arxiv.org/pdf/2601.05110.pdf) |
| Github Repository | [https://github.com/Zengwh02/GlimpRouter](https://github.com/Zengwh02/GlimpRouter) |

--- 

## 7. Lost in the Noise: How Reasoning Models Fail with Contextual Distractors *(24 votes)*

**TÃ¡c giáº£:** Seongyun Lee, Yongrae Jo, Minju Seo, Moontae Lee, Minjoon Seo

**Xuáº¥t báº£n lÃºc:** 2026-01-12

**Tag:** Reasoning, RAG, AI Agents, Robustness, Noise, Benchmarking, LLM Evaluation, Reinforcement Learning

### I. Main Problem:
CÃ¡c mÃ´ hÃ¬nh suy luáº­n vÃ  há»‡ thá»‘ng AI tÃ¡c tá»­ hiá»‡n nay, dÃ¹ ngÃ y cÃ ng phá»¥ thuá»™c vÃ o thÃ´ng tin bÃªn ngoÃ i, nhÆ°ng láº¡i thiáº¿u kháº£ nÄƒng xá»­ lÃ½ hiá»‡u quáº£ cÃ¡c ngá»¯ cáº£nh Ä‘áº§u vÃ o cÃ³ nhiá»…u trong tháº¿ giá»›i thá»±c. CÃ¡c benchmark hiá»‡n táº¡i chá»‰ Ä‘Ã¡nh giÃ¡ trong mÃ´i trÆ°á»ng "sáº¡ch", dáº«n Ä‘áº¿n cÃ¡i nhÃ¬n sai lá»‡ch vá» nÄƒng lá»±c cá»§a mÃ´ hÃ¬nh. CÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n nháº¥t tráº£i qua sá»± sá»¥t giáº£m hiá»‡u suáº¥t nghiÃªm trá»ng (lÃªn Ä‘áº¿n 80%) khi Ä‘á»‘i máº·t vá»›i nhiá»…u ngá»¯ cáº£nh. HÆ¡n ná»¯a, cÃ¡c quy trÃ¬nh tÃ¡c tá»­ thÆ°á»ng khuáº¿ch Ä‘áº¡i lá»—i do quÃ¡ tin tÆ°á»Ÿng vÃ o Ä‘áº§u ra cÃ´ng cá»¥ nhiá»…u, vÃ  nhá»¯ng yáº¿u tá»‘ gÃ¢y nhiá»…u cÃ³ thá»ƒ dáº«n Ä‘áº¿n sá»± sai lá»‡ch ngoÃ i Ã½ muá»‘n. CÃ¡c phÆ°Æ¡ng phÃ¡p phá»• biáº¿n nhÆ° nháº¯c lá»‡nh, ká»¹ thuáº­t ngá»¯ cáº£nh, SFT vÃ  há»c tÄƒng cÆ°á»ng chá»‰ dá»±a trÃªn pháº§n thÆ°á»Ÿng káº¿t quáº£ Ä‘á»u khÃ´ng Ä‘áº£m báº£o Ä‘á»™ bá»n vá»¯ng.

### II. Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u **NoisyBench**, má»™t bá»™ benchmark toÃ n diá»‡n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ³ há»‡ thá»‘ng Ä‘á»™ bá»n vá»¯ng cá»§a mÃ´ hÃ¬nh trÃªn 11 bá»™ dá»¯ liá»‡u trong cÃ¡c tÃ¡c vá»¥ RAG, suy luáº­n, cÄƒn chá»‰nh vÃ  sá»­ dá»¥ng cÃ´ng cá»¥ Ä‘á»‘i vá»›i nhiá»u loáº¡i nhiá»…u khÃ¡c nhau, bao gá»“m tÃ i liá»‡u ngáº«u nhiÃªn, lá»‹ch sá»­ trÃ² chuyá»‡n khÃ´ng liÃªn quan vÃ  nhá»¯ng yáº¿u tá»‘ gÃ¢y nhiá»…u tiÃªu cá»±c khÃ³. Äá»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng phá»¥c há»“i cá»§a mÃ´ hÃ¬nh, bÃ i bÃ¡o Ä‘á» xuáº¥t **Rationale-Aware Reward (RARE)**, má»™t hÃ m pháº§n thÆ°á»Ÿng Ä‘Æ¡n giáº£n nhÆ°ng hiá»‡u quáº£, cá»§ng cá»‘ quÃ¡ trÃ¬nh suy luáº­n báº±ng cÃ¡ch khuyáº¿n khÃ­ch viá»‡c xÃ¡c Ä‘á»‹nh thÃ´ng tin há»¯u Ã­ch trong ngá»¯ cáº£nh nhiá»…u. NgoÃ i ra, **NoisyInstruct** lÃ  má»™t táº­p dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ dáº¡y mÃ´ hÃ¬nh loáº¡i bá» cÃ¡c yáº¿u tá»‘ gÃ¢y nhiá»…u.

### III. Main Results:
*   CÃ¡c mÃ´ hÃ¬nh hiá»‡n Ä‘áº¡i cho tháº¥y sá»± sá»¥t giáº£m hiá»‡u suáº¥t tháº£m khá»‘c lÃªn Ä‘áº¿n 80% khi gáº·p pháº£i cÃ¡c yáº¿u tá»‘ gÃ¢y nhiá»…u ngá»¯ cáº£nh.
*   CÃ¡c quy trÃ¬nh tÃ¡c tá»­ cÃ³ thá»ƒ khuáº¿ch Ä‘áº¡i lá»—i do quÃ¡ tin tÆ°á»Ÿng vÃ o Ä‘áº§u ra cÃ´ng cá»¥ nhiá»…u, vÃ  nhiá»…u cÃ³ thá»ƒ kÃ­ch hoáº¡t sá»± sai lá»‡ch ngoÃ i Ã½ muá»‘n ngay cáº£ khi khÃ´ng cÃ³ Ã½ Ä‘á»‹nh Ä‘á»‘i khÃ¡ng.
*   CÃ¡c ká»¹ thuáº­t nhÆ° nháº¯c lá»‡nh, ká»¹ thuáº­t ngá»¯ cáº£nh, SFT vÃ  há»c tÄƒng cÆ°á»ng chá»‰ dá»±a trÃªn pháº§n thÆ°á»Ÿng káº¿t quáº£ khÃ´ng Ä‘á»§ Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ bá»n vá»¯ng.
*   RARE tÄƒng cÆ°á»ng Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng phá»¥c há»“i báº±ng cÃ¡ch khuyáº¿n khÃ­ch nháº­n diá»‡n thÃ´ng tin há»¯u Ã­ch trong nhiá»…u, cáº£i thiá»‡n tá»· lá»‡ lá»c yáº¿u tá»‘ gÃ¢y nhiá»…u trong chuá»—i suy luáº­n vÃ  mang láº¡i Ä‘á»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng cao hÆ¡n so vá»›i pháº§n thÆ°á»Ÿng dá»±a trÃªn káº¿t quáº£ Ä‘Æ¡n thuáº§n.
*   NghiÃªn cá»©u phÃ¡t hiá»‡n xu hÆ°á»›ng nghá»‹ch Ä‘áº£o: TÄƒng cÆ°á»ng tÃ­nh toÃ¡n trong thá»i gian kiá»ƒm tra (sá»­ dá»¥ng nhiá»u token suy luáº­n hÆ¡n) láº¡i dáº«n Ä‘áº¿n hiá»‡u suáº¥t kÃ©m hÆ¡n trong cÃ¡c thiáº¿t láº­p cÃ³ nhiá»…u.
*   PhÃ¢n tÃ­ch sá»± chÃº Ã½ cho tháº¥y cÃ¡c mÃ´ hÃ¬nh táº­p trung khÃ´ng cÃ¢n Ä‘á»‘i vÃ o cÃ¡c token gÃ¢y nhiá»…u, Ä‘áº·c biá»‡t lÃ  trong cÃ¡c dá»± Ä‘oÃ¡n khÃ´ng chÃ­nh xÃ¡c.

### IV. Conclusion & Future Works:
CÃ´ng trÃ¬nh nÃ y phÆ¡i bÃ y khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ giá»¯a cÃ¡c benchmark "sáº¡ch" vÃ  mÃ´i trÆ°á»ng nhiá»…u thá»±c táº¿ mÃ  cÃ¡c há»‡ thá»‘ng AI tÃ¡c tá»­ váº­n hÃ nh. Báº±ng cÃ¡ch giá»›i thiá»‡u NoisyBench, NoisyInstruct vÃ  RARE, nghiÃªn cá»©u cung cáº¥p ná»n táº£ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ vÃ  cáº£i thiá»‡n Ä‘á»™ bá»n vá»¯ng vá»›i nhiá»…u, Ä‘á»“ng thá»i Ä‘Æ°a ra nhá»¯ng hiá»ƒu biáº¿t quan trá»ng cho viá»‡c phÃ¡t triá»ƒn tháº¿ há»‡ tÃ¡c tá»­ cÃ³ kháº£ nÄƒng suy luáº­n máº¡nh máº½ vÃ  Ä‘Ã¡ng tin cáº­y hÆ¡n.

### V. Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u vá» viá»‡c tÃ­ch há»£p RARE vá»›i cÃ¡c kiáº¿n trÃºc mÃ´ hÃ¬nh má»›i Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ xá»­ lÃ½ ngá»¯ cáº£nh dÃ i, Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a viá»‡c káº¿t há»£p nÃ y trong viá»‡c duy trÃ¬ Ä‘á»™ chÃ­nh xÃ¡c vÃ  kháº£ nÄƒng lá»c nhiá»…u.
*   KhÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p tá»± Ä‘á»™ng táº¡o ra cÃ¡c loáº¡i nhiá»…u "hard negative" hiá»‡u quáº£ hÆ¡n Ä‘á»ƒ liÃªn tá»¥c thÃ¡ch thá»©c vÃ  cáº£i thiá»‡n kháº£ nÄƒng lá»c nhiá»…u cá»§a mÃ´ hÃ¬nh trong NoisyBench.
*   PhÃ¢n tÃ­ch sÃ¢u hÆ¡n vá» cÆ¡ cháº¿ "inverse scaling trend" vÃ  Ä‘á» xuáº¥t cÃ¡c giáº£i phÃ¡p kiáº¿n trÃºc hoáº·c huáº¥n luyá»‡n Ä‘á»ƒ ngÄƒn cháº·n sá»± suy giáº£m hiá»‡u suáº¥t khi mÃ´ hÃ¬nh sá»­ dá»¥ng nhiá»u token suy luáº­n hÆ¡n trong mÃ´i trÆ°á»ng nhiá»…u.

#### 2. Patent:
*   Há»‡ thá»‘ng trá»£ lÃ½ áº£o trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh sá»­ dá»¥ng Rationale-Aware Reward Ä‘á»ƒ lá»c bá» thÃ´ng tin khÃ´ng liÃªn quan tá»« lá»‹ch sá»­ trÃ² chuyá»‡n hoáº·c cÃ¡c tÃ i liá»‡u Ä‘Æ°á»£c truy xuáº¥t, Ä‘áº£m báº£o pháº£n há»“i chÃ­nh xÃ¡c vÃ  Ä‘Ã¡ng tin cáº­y cho cÃ¡c yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng.
*   á»¨ng dá»¥ng báº£o máº­t vÃ  kiá»ƒm duyá»‡t ná»™i dung trÃªn thiáº¿t bá»‹ di Ä‘á»™ng tÃ­ch há»£p cÆ¡ cháº¿ phÃ¡t hiá»‡n vÃ  bá» qua cÃ¡c "hard negative distractors" trong cÃ¡c cuá»™c há»™i thoáº¡i hoáº·c bÃ i viáº¿t, giÃºp ngÆ°á»i dÃ¹ng trÃ¡nh bá»‹ hiá»ƒu láº§m hoáº·c tiáº¿p nháº­n thÃ´ng tin sai lá»‡ch.
*   CÃ´ng nghá»‡ tÃ­ch há»£p vÃ o cÃ¡c á»©ng dá»¥ng ghi chÃº hoáº·c cÃ´ng cá»¥ nÄƒng suáº¥t trÃªn Ä‘iá»‡n thoáº¡i, sá»­ dá»¥ng NoisyBench Ä‘á»ƒ liÃªn tá»¥c Ä‘Ã¡nh giÃ¡ vÃ  cáº£i thiá»‡n kháº£ nÄƒng cá»§a AI trong viá»‡c tá»•ng há»£p thÃ´ng tin quan trá»ng tá»« cÃ¡c nguá»“n nhiá»…u, Ä‘á»“ng thá»i giáº£m thiá»ƒu sá»± phá»¥ thuá»™c vÃ o cÃ¡c thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.07226](https://huggingface.co/papers/2601.07226) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.07226](https://arxiv.org/abs/2601.07226) |
| PDF Download | [https://arxiv.org/pdf/2601.07226.pdf](https://arxiv.org/pdf/2601.07226.pdf) |
| Github Repository | N/A |

--- 

## 8. OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent *(22 votes)*

**TÃ¡c giáº£:** Bowen Yang, Kaiming Jin, Zhenyu Wu, Zhaoyang Liu, Qiushi Sun, Zehao Li, JingJing Xie, Zhoumianze Liu, Fangzhi Xu, Kanzhi Cheng, Qingyun Li, Yian Wang, Yu Qiao, Zun Wang, Zichen Ding

**Xuáº¥t báº£n lÃºc:** 2026-01-12

**Tag:** Computer-Using Agents, Multimodal RAG, Reflection, Orchestration
### I. Main Problem:
CÃ¡c tÃ¡c nhÃ¢n sá»­ dá»¥ng mÃ¡y tÃ­nh (Computer-Using Agents - CUAs) hiá»‡n táº¡i, máº·c dÃ¹ Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ nhá» Vision-Language Models (VLMs), váº«n gáº·p khÃ³ khÄƒn vá» tÃ­nh bá»n vá»¯ng (robustness) trong cÃ¡c quy trÃ¬nh lÃ m viá»‡c dÃ i háº¡n vÃ  kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a (generalization) trong cÃ¡c lÄ©nh vá»±c má»›i. Nhá»¯ng háº¡n cháº¿ nÃ y xuáº¥t phÃ¡t tá»« viá»‡c thiáº¿u kiá»ƒm soÃ¡t chi tiáº¿t Ä‘á»‘i vá»›i viá»‡c quáº£n lÃ½ ngá»¯ cáº£nh hÃ¬nh áº£nh lá»‹ch sá»­ vÃ  sá»± thiáº¿u há»¥t kháº£ nÄƒng truy xuáº¥t hÆ°á»›ng dáº«n cÃ³ nháº­n biáº¿t hÃ¬nh áº£nh.

### II. Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u OS-SYMPHONY, má»™t khuÃ´n khá»• toÃ n diá»‡n bao gá»“m má»™t Orchestrator Ä‘iá»u phá»‘i hai Ä‘á»•i má»›i chÃ­nh Ä‘á»ƒ tá»± Ä‘á»™ng hÃ³a máº¡nh máº½:
1.  **Reflection-Memory Agent (RMA):** Sá»­ dá»¥ng bá»™ nhá»› dÃ i háº¡n dá»±a trÃªn cÃ¡c "cá»™t má»‘c" (milestone) Ä‘á»ƒ lÆ°u giá»¯ áº£nh chá»¥p mÃ n hÃ¬nh quan trá»ng vÃ  cÃ¡c quá»¹ Ä‘áº¡o trá»«u tÆ°á»£ng. Äiá»u nÃ y cho phÃ©p tá»± sá»­a lá»—i á»Ÿ cáº¥p Ä‘á»™ quá»¹ Ä‘áº¡o, giáº£m thiá»ƒu viá»‡c máº¥t ngá»¯ cáº£nh hÃ¬nh áº£nh trong cÃ¡c tÃ¡c vá»¥ dÃ i háº¡n vÃ  táº¡o ra cÃ¡c pháº£n há»“i Ã½ nghÄ©a Ä‘á»ƒ tinh chá»‰nh káº¿ hoáº¡ch.
2.  **Versatile Tool Agents (vá»›i Multimodal Searcher):** Ãp dá»¥ng mÃ´ hÃ¬nh "See-Act" Ä‘á»ƒ Ä‘iá»u hÆ°á»›ng má»™t mÃ´i trÆ°á»ng sandbox dá»±a trÃªn trÃ¬nh duyá»‡t nháº±m tá»•ng há»£p cÃ¡c hÆ°á»›ng dáº«n trá»±c tiáº¿p, Ä‘Æ°á»£c cÄƒn chá»‰nh trá»±c quan. Äiá»u nÃ y giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» vá» Ä‘á»™ trung thá»±c trong cÃ¡c ká»‹ch báº£n chÆ°a tá»«ng tháº¥y, giÃºp tÃ¡c nhÃ¢n cÃ³ Ä‘Æ°á»£c kiáº¿n thá»©c Ä‘a phÆ°Æ¡ng thá»©c bÃªn ngoÃ i.

### III. Main Results:
OS-SYMPHONY mang láº¡i hiá»‡u suáº¥t vÆ°á»£t trá»™i trÃªn ba tiÃªu chuáº©n trá»±c tuyáº¿n, thiáº¿t láº­p cÃ¡c káº¿t quáº£ hiá»‡n Ä‘áº¡i má»›i (state-of-the-art):
*   OSWorld: Äáº¡t 65.84% (tÄƒng 2.4% so vá»›i SOTA trÆ°á»›c Ä‘Ã³).
*   WindowsAgentArena: Äáº¡t 63.5% (tÄƒng 6.9% so vá»›i SOTA trÆ°á»›c Ä‘Ã³).
*   MacOSArena: Äáº¡t 46.0% (tÄƒng 38.0% so vá»›i SOTA trÆ°á»›c Ä‘Ã³).
KhuÃ´n khá»• nÃ y cÅ©ng cho phÃ©p cÃ¡c VLM mÃ£ nguá»“n má»Ÿ thá»±c hiá»‡n thÃ nh cÃ´ng cÃ¡c tÃ¡c vá»¥ dÃ i háº¡n hoáº·c chÆ°a tá»«ng tháº¥y mÃ  trÆ°á»›c Ä‘Ã¢y vÆ°á»£t quÃ¡ kháº£ nÄƒng cá»§a chÃºng.

### IV. Conclusion & Future Works:
OS-SYMPHONY lÃ  má»™t khuÃ´n khá»• toÃ n diá»‡n, mang láº¡i sá»± cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» hiá»‡u suáº¥t cho cÃ¡c tÃ¡c nhÃ¢n sá»­ dá»¥ng mÃ¡y tÃ­nh, Ä‘áº·c biá»‡t trong cÃ¡c tÃ¡c vá»¥ dÃ i háº¡n vÃ  chÆ°a tá»«ng tháº¥y. Khung nÃ y giáº£i quyáº¿t cÃ¡c thÃ¡ch thá»©c chÃ­nh vá» quáº£n lÃ½ bá»™ nhá»› (ngá»¯ cáº£nh hÃ¬nh áº£nh) vÃ  tá»•ng quÃ¡t hÃ³a (truy xuáº¥t kiáº¿n thá»©c Ä‘a phÆ°Æ¡ng thá»©c). HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo bao gá»“m viá»‡c tá»‘i Æ°u hÃ³a hÆ¡n ná»¯a cÆ¡ cháº¿ pháº£n há»“i vÃ  bá»™ nhá»› Ä‘a phÆ°Æ¡ng thá»©c, cÅ©ng nhÆ° má»Ÿ rá»™ng á»©ng dá»¥ng sang cÃ¡c mÃ´i trÆ°á»ng Ä‘iá»u hÃ nh vÃ  loáº¡i tÃ¡c vá»¥ phá»©c táº¡p hÆ¡n.

### V. Brainstorming Space:
#### 1. Publish Papers:
1.  NghiÃªn cá»©u cÃ¡c phÆ°Æ¡ng phÃ¡p tiÃªn tiáº¿n Ä‘á»ƒ tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh vÃ  trÃ­ch xuáº¥t cÃ¡c "milestone" hÃ¬nh áº£nh quan trá»ng tá»« cÃ¡c quá»¹ Ä‘áº¡o tÆ°Æ¡ng tÃ¡c ngÆ°á»i dÃ¹ng dÃ i Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u quáº£ bá»™ nhá»› cá»§a Reflection-Memory Agent.
2.  PhÃ¡t triá»ƒn má»™t há»‡ thá»‘ng Multimodal Searcher cÃ³ kháº£ nÄƒng khÃ´ng chá»‰ truy xuáº¥t mÃ  cÃ²n táº¡o ra cÃ¡c hÆ°á»›ng dáº«n trá»±c quan tÆ°Æ¡ng tÃ¡c, Ä‘iá»u chá»‰nh theo ngá»¯ cáº£nh ngÆ°á»i dÃ¹ng cá»¥ thá»ƒ trong thá»i gian thá»±c.
3.  KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p cÃ¡c mÃ´ hÃ¬nh há»c tÄƒng cÆ°á»ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a chiáº¿n lÆ°á»£c Ä‘iá»u phá»‘i cá»§a Orchestrator, cho phÃ©p nÃ³ tá»± Ä‘á»™ng há»c cÃ¡ch Æ°u tiÃªn vÃ  káº¿t há»£p cÃ¡c Tool Agents khÃ¡c nhau dá»±a trÃªn loáº¡i nhiá»‡m vá»¥ vÃ  tÃ¬nh huá»‘ng lá»—i.

#### 2. Patent:
1.  Má»™t há»‡ thá»‘ng trá»£ lÃ½ áº£o trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh cÃ³ kháº£ nÄƒng tá»± Ä‘á»™ng thá»±c hiá»‡n cÃ¡c tÃ¡c vá»¥ phá»©c táº¡p báº±ng cÃ¡ch tÃ¬m kiáº¿m vÃ  lÃ m theo cÃ¡c hÆ°á»›ng dáº«n trá»±c quan Ä‘Æ°á»£c tá»•ng há»£p tá»± Ä‘á»™ng tá»« web, vÃ­ dá»¥ nhÆ° táº¡o shortcut á»©ng dá»¥ng hoáº·c thay Ä‘á»•i cÃ i Ä‘áº·t sÃ¢u.
2.  Má»™t á»©ng dá»¥ng trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng giÃºp ngÆ°á»i dÃ¹ng ghi láº¡i má»™t chuá»—i hÃ nh Ä‘á»™ng trÃªn Ä‘iá»‡n thoáº¡i, sau Ä‘Ã³ AI tá»± Ä‘á»™ng phÃ¢n tÃ­ch vÃ  táº¡o ra má»™t "hÆ°á»›ng dáº«n hÃ¬nh áº£nh" cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tá»± Ä‘á»™ng láº·p láº¡i hoáº·c hÆ°á»›ng dáº«n ngÆ°á»i khÃ¡c thá»±c hiá»‡n tÃ¡c vá»¥ Ä‘Ã³ má»™t cÃ¡ch chÃ­nh xÃ¡c.
3.  CÃ´ng nghá»‡ tÃ­ch há»£p vÃ o há»‡ Ä‘iá»u hÃ nh Ä‘iá»‡n thoáº¡i, cho phÃ©p má»™t tÃ¡c nhÃ¢n AI nháº­n diá»‡n khi ngÆ°á»i dÃ¹ng gáº·p khÃ³ khÄƒn hoáº·c láº·p láº¡i má»™t hÃ nh Ä‘á»™ng khÃ´ng hiá»‡u quáº£, sau Ä‘Ã³ tá»± Ä‘á»™ng tÃ¬m kiáº¿m cÃ¡c hÆ°á»›ng dáº«n trá»±c quan vÃ  Ä‘á» xuáº¥t hoáº·c thá»±c hiá»‡n cÃ¡c bÆ°á»›c kháº¯c phá»¥c phÃ¹ há»£p.
4.  Má»™t phÆ°Æ¡ng phÃ¡p tá»± Ä‘á»™ng hÃ³a trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng mÃ  qua Ä‘Ã³, AI cÃ³ thá»ƒ tá»± Ä‘á»™ng duyá»‡t cÃ¡c trang web há»— trá»£, xem cÃ¡c video hÆ°á»›ng dáº«n vÃ  trÃ­ch xuáº¥t cÃ¡c bÆ°á»›c hÃ nh Ä‘á»™ng cá»¥ thá»ƒ Ä‘á»ƒ giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» pháº§n má»m hoáº·c cáº¥u hÃ¬nh trÃªn chÃ­nh thiáº¿t bá»‹ Ä‘Ã³.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.07779](https://huggingface.co/papers/2601.07779) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.07779](https://arxiv.org/abs/2601.07779) |
| PDF Download | [https://arxiv.org/pdf/2601.07779.pdf](https://arxiv.org/pdf/2601.07779.pdf) |
| Github Repository | [https://github.com/OS-Copilot/OS-Symphony](https://github.com/OS-Copilot/OS-Symphony) |

--- 

## 9. Beyond Hard Masks: Progressive Token Evolution for Diffusion Language Models *(20 votes)*

**TÃ¡c giáº£:** Linhao Zhong, Linyu Wu, Bozhen Fang, Tianjian Feng, Chenchen Jing, Wen Wang, Jiaheng Zhang, Hao Chen, Chunhua Shen

**Xuáº¥t báº£n lÃºc:** 2026-01-12

**Tag:** Diffusion, Language Models, Parallel Decoding, Iterative Refinement, Soft Token Evolution, Continuous Trajectory Supervision

### I. Main Problem:
CÃ¡c Diffusion Language Models (DLMs) hiá»‡n táº¡i, Ä‘áº·c biá»‡t lÃ  Masked Diffusion Language Models (MDLMs), gáº·p pháº£i váº¥n Ä‘á» khi sá»­ dá»¥ng cÆ¡ cháº¿ hard binary masking vÃ  gÃ¡n token rá»i ráº¡c. Äiá»u nÃ y khiáº¿n mÃ´ hÃ¬nh khÃ´ng thá»ƒ sá»­a Ä‘á»•i cÃ¡c quyáº¿t Ä‘á»‹nh sá»›m vÃ  bá» qua viá»‡c táº­n dá»¥ng cÃ¡c biá»ƒu diá»…n xÃ¡c suáº¥t trung gian trong quÃ¡ trÃ¬nh tinh chá»‰nh láº·p láº¡i. NgoÃ i ra, MDLMs lÃ£ng phÃ­ tÃ i nguyÃªn tÃ­nh toÃ¡n khi dá»± Ä‘oÃ¡n phÃ¢n phá»‘i token cho táº¥t cáº£ cÃ¡c vá»‹ trÃ­ nhÆ°ng chá»‰ cáº­p nháº­t má»™t pháº§n nhá».

### II. Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t EvoToken-DLM, má»™t phÆ°Æ¡ng phÃ¡p mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn Diffusion má»›i thay tháº¿ cÃ¡c hard binary masks báº±ng phÃ¢n phá»‘i soft token cÃ³ kháº£ nÄƒng phÃ¡t triá»ƒn (evolving soft token distributions). EvoToken-DLM cho phÃ©p quÃ¡ trÃ¬nh chuyá»ƒn Ä‘á»•i dáº§n dáº§n tá»« tráº¡ng thÃ¡i masked sang Ä‘áº§u ra rá»i ráº¡c thÃ´ng qua tinh chá»‰nh láº·p Ä‘i láº·p láº¡i. CÃ¡c token Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng phÃ¢n phá»‘i xÃ¡c suáº¥t trÃªn toÃ n bá»™ tá»« vá»±ng vÃ  tráº£i qua bá»‘n tráº¡ng thÃ¡i tiáº¿n hÃ³a: [MASK] -> Soft([MASK] U V) -> Soft(V) -> [Decode]. Äá»ƒ há»— trá»£ quÃ¡ trÃ¬nh tiáº¿n hÃ³a liÃªn tá»¥c nÃ y, mÃ´ hÃ¬nh giá»›i thiá»‡u cÆ¡ cháº¿ giÃ¡m sÃ¡t quá»¹ Ä‘áº¡o liÃªn tá»¥c (continuous trajectory supervision), nháº±m Ä‘iá»u chá»‰nh má»¥c tiÃªu huáº¥n luyá»‡n vá»›i cÃ¡c cáº­p nháº­t xÃ¡c suáº¥t láº·p láº¡i.

### III. Main Results:
EvoToken-DLM liÃªn tá»¥c Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t vÆ°á»£t trá»™i trÃªn nhiá»u Ä‘iá»ƒm chuáº©n, vÆ°á»£t qua cÃ¡c mÃ´ hÃ¬nh DLM dá»±a trÃªn Diffusion vÃ  MDLMs máº¡nh máº½. PhÆ°Æ¡ng phÃ¡p nÃ y tÃ­ch há»£p liá»n máº¡ch vá»›i cÃ¡c cÆ¡ cháº¿ KV-caching vÃ  má»Ÿ rá»™ng má»™t cÃ¡ch tá»± nhiÃªn sang cÃ i Ä‘áº·t blockwise diffusion, chá»©ng tá» tÃ­nh á»©ng dá»¥ng rá»™ng rÃ£i vÃ  kháº£ nÄƒng nÃ¢ng cao hiá»‡u quáº£ tá»•ng thá»ƒ cá»§a DLM.

### IV. Conclusion & Future Works:
EvoToken-DLM cung cáº¥p má»™t cÃ¡ch tiáº¿p cáº­n hiá»‡u quáº£ vÃ  tá»•ng quÃ¡t Ä‘á»ƒ cáº£i thiá»‡n Diffusion Language Models báº±ng cÃ¡ch thay tháº¿ hard masks báº±ng cÃ¡c soft token distributions tiáº¿n hÃ³a, cho phÃ©p giáº£i mÃ£ cÃ³ thá»ƒ sá»­a Ä‘á»•i vÃ  tinh chá»‰nh liÃªn tá»¥c. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ táº­p trung vÃ o viá»‡c khÃ¡m phÃ¡ cÃ¡c chiáº¿n lÆ°á»£c tinh chá»‰nh quá»¹ Ä‘áº¡o (trajectory refinement strategies) tiÃªn tiáº¿n hÆ¡n vÃ  á»©ng dá»¥ng EvoToken-DLM vÃ o cÃ¡c nhiá»‡m vá»¥ sinh ngÃ´n ngá»¯ phá»©c táº¡p hÆ¡n.

### V. Brainstorming Space:
#### 1. Publish Papers:
1. NghiÃªn cá»©u cÃ¡ch EvoToken-DLM cÃ³ thá»ƒ Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ tÄƒng cÆ°á»ng kháº£ nÄƒng chá»‰nh sá»­a vÃ  tÆ°Æ¡ng tÃ¡c cá»§a cÃ¡c chatbot trong thá»i gian thá»±c.
2. KhÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p má»›i Ä‘á»ƒ tá»‘i Æ°u hÃ³a continuous trajectory supervision nháº±m giáº£m chi phÃ­ tÃ­nh toÃ¡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ  váº«n duy trÃ¬ hiá»‡u suáº¥t cao.
3. PhÃ¢n tÃ­ch áº£nh hÆ°á»Ÿng cá»§a cÃ¡c kÃ­ch thÆ°á»›c block khÃ¡c nhau vÃ  chiáº¿n lÆ°á»£c lá»±a chá»n token trong blockwise decoding cá»§a EvoToken-DLM Ä‘áº¿n cháº¥t lÆ°á»£ng vÃ  tá»‘c Ä‘á»™ sinh vÄƒn báº£n.

#### 2. Patent:
1. Má»™t há»‡ thá»‘ng nháº­p liá»‡u vÄƒn báº£n thÃ´ng minh trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng sá»­ dá»¥ng EvoToken-DLM Ä‘á»ƒ gá»£i Ã½ vÃ  tá»± Ä‘á»™ng sá»­a cÃ¡c tá»« bá»‹ lá»—i hoáº·c chÆ°a hoÃ n chá»‰nh má»™t cÃ¡ch linh hoáº¡t, cho phÃ©p ngÆ°á»i dÃ¹ng dá»… dÃ ng chá»‰nh sá»­a cÃ¡c gá»£i Ã½.
2. á»¨ng dá»¥ng chá»‰nh sá»­a vÄƒn báº£n trÃªn Ä‘iá»‡n thoáº¡i tÃ­ch há»£p EvoToken-DLM, cho phÃ©p ngÆ°á»i dÃ¹ng thay Ä‘á»•i cÃ¡c pháº§n cá»§a cÃ¢u hoáº·c Ä‘oáº¡n vÄƒn má»™t cÃ¡ch liá»n máº¡ch, vá»›i kháº£ nÄƒng hoÃ n tÃ¡c vÃ  Ä‘á» xuáº¥t cÃ¡c lá»±a chá»n thay tháº¿ dá»±a trÃªn phÃ¢n phá»‘i xÃ¡c suáº¥t cá»§a token.
3. PhÆ°Æ¡ng phÃ¡p táº¡o ná»™i dung Ä‘á»™ng cho á»©ng dá»¥ng tin tá»©c hoáº·c máº¡ng xÃ£ há»™i trÃªn Ä‘iá»‡n thoáº¡i, sá»­ dá»¥ng EvoToken-DLM Ä‘á»ƒ sinh ra cÃ¡c tiÃªu Ä‘á» hoáº·c tÃ³m táº¯t bÃ i viáº¿t cÃ³ thá»ƒ Ä‘Æ°á»£c tinh chá»‰nh liÃªn tá»¥c bá»Ÿi thuáº­t toÃ¡n Ä‘á»ƒ phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch cá»§a ngÆ°á»i dÃ¹ng vÃ  ngá»¯ cáº£nh hiá»ƒn thá»‹.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.07351](https://huggingface.co/papers/2601.07351) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.07351](https://arxiv.org/abs/2601.07351) |
| PDF Download | [https://arxiv.org/pdf/2601.07351.pdf](https://arxiv.org/pdf/2601.07351.pdf) |
| Github Repository | [https://github.com/aim-uofa/EvoTokenDLM](https://github.com/aim-uofa/EvoTokenDLM) |

--- 

## 10. Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction *(19 votes)*

**TÃ¡c giáº£:** Muzhao Tian, Zisu Huang, Xiaohua Wang, Jingwen Xu, Zhengkang Guo, Qi Qian, Yuanzhe Shen, Kaitao Song, Jiakang Yuan, Changze Lv, Xiaoqing Zheng

**Xuáº¥t báº£n lÃºc:** 2026-01-08

**Tag:** Long-Term Human-Agent Interaction, LLM Memory, Memory Anchoring, Controllable Memory, SteeM, Personalization, Innovation

### I. Main Problem:
CÃ¡c tÃ¡c nhÃ¢n dá»±a trÃªn LLM trong tÆ°Æ¡ng tÃ¡c dÃ i háº¡n gáº·p pháº£i váº¥n Ä‘á» "Memory Anchoring" (neo giá»¯ bá»Ÿi kÃ½ á»©c), nÆ¡i tÃ¡c nhÃ¢n bá»‹ máº¯c káº¹t bá»Ÿi cÃ¡c tÆ°Æ¡ng tÃ¡c trong quÃ¡ khá»© khi sá»­ dá»¥ng toÃ n bá»™ thÃ´ng tin liÃªn quan, hoáº·c ngÆ°á»£c láº¡i lÃ  thiáº¿u táº­n dá»¥ng kÃ½ á»©c khi loáº¡i trá»« hoÃ n toÃ n. CÃ¡c há»‡ thá»‘ng hiá»‡n cÃ³ thÆ°á»ng Ã¡p dá»¥ng cÃ¡ch tiáº¿p cáº­n "táº¥t cáº£ hoáº·c khÃ´ng gÃ¬ cáº£" Ä‘á»‘i vá»›i viá»‡c sá»­ dá»¥ng bá»™ nhá»›, thiáº¿u má»™t cÆ¡ cháº¿ cho phÃ©p ngÆ°á»i dÃ¹ng kiá»ƒm soÃ¡t linh hoáº¡t má»©c Ä‘á»™ phá»¥ thuá»™c vÃ o kÃ½ á»©c theo thá»i gian thá»±c Ä‘á»ƒ cÃ¢n báº±ng giá»¯a tÃ­nh nháº¥t quÃ¡n vÃ  kháº£ nÄƒng Ä‘á»•i má»›i. Ngay cáº£ khi Ä‘Æ°á»£c nháº¯c nhá»Ÿ Ä‘á»ƒ "sÃ¡ng táº¡o", LLM váº«n thÆ°á»ng thá»ƒ hiá»‡n "rÃ² rá»‰ kÃ½ á»©c" tá»« lá»‹ch sá»­.

### II. Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t SteerableMemory Agent (SteeM), má»™t framework cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘iá»u chá»‰nh Ä‘á»™ng má»©c Ä‘á»™ phá»¥ thuá»™c cá»§a mÃ´ hÃ¬nh vÃ o kÃ½ á»©c. SteeM xem xÃ©t má»©c Ä‘á»™ phá»¥ thuá»™c vÃ o kÃ½ á»©c nhÆ° má»™t chiá»u hÃ nh vi cÃ³ thá»ƒ kiá»ƒm soÃ¡t rÃµ rÃ ng bá»Ÿi ngÆ°á»i dÃ¹ng, cho phÃ©p chuyá»ƒn Ä‘á»•i tá»« cháº¿ Ä‘á»™ "fresh-start" (thÃºc Ä‘áº©y sá»± Ä‘á»•i má»›i) Ä‘áº¿n cháº¿ Ä‘á»™ "high-fidelity" (tuÃ¢n thá»§ cháº·t cháº½ lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c). Framework nÃ y Ä‘Æ°á»£c phÃ¡t triá»ƒn báº±ng cÃ¡ch táº¡o dá»¯ liá»‡u cÄƒn chá»‰nh sá»Ÿ thÃ­ch (preference-aligned data generation), sau Ä‘Ã³ Ã¡p dá»¥ng Fine-Tuning cÃ³ giÃ¡m sÃ¡t (SFT) vÃ  GRPO (Generalized Reinforcement Learning from Preferences).

### III. Main Results:
SteeM vÆ°á»£t trá»™i hÆ¡n Ä‘Ã¡ng ká»ƒ so vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p nháº¯c nhá»Ÿ thÃ´ng thÆ°á»ng vÃ  cÃ¡c chiáº¿n lÆ°á»£c che giáº¥u kÃ½ á»©c cá»©ng nháº¯c. NÃ³ cung cáº¥p kháº£ nÄƒng kiá»ƒm soÃ¡t sáº¯c thÃ¡i vÃ  hiá»‡u quáº£ hÆ¡n cho sá»± cá»™ng tÃ¡c cÃ¡ nhÃ¢n hÃ³a giá»¯a ngÆ°á»i vÃ  tÃ¡c nhÃ¢n, cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘áº¡t Ä‘Æ°á»£c sá»± cÃ¢n báº±ng chÃ­nh xÃ¡c hÆ¡n giá»¯a nháº­n thá»©c vá» kÃ½ á»©c vÃ  sá»± Ä‘á»™c láº­p trong suy luáº­n trÃªn nhiá»u nhiá»‡m vá»¥ dÃ i háº¡n khÃ¡c nhau. NghiÃªn cá»©u cÅ©ng giá»›i thiá»‡u má»™t chá»‰ sá»‘ hÃ nh vi vá» sá»± phá»¥ thuá»™c vÃ o kÃ½ á»©c Ä‘á»ƒ Ä‘á»‹nh lÆ°á»£ng áº£nh hÆ°á»Ÿng cá»§a cÃ¡c tÆ°Æ¡ng tÃ¡c trong quÃ¡ khá»© Ä‘á»‘i vá»›i cÃ¡c Ä‘áº§u ra hiá»‡n táº¡i vÃ  tiáº¿t lá»™ hiá»‡n tÆ°á»£ng "Memory Anchoring" á»Ÿ cÃ¡c LLM hiá»‡n Ä‘áº¡i.

### IV. Conclusion & Future Works:
BÃ i bÃ¡o káº¿t luáº­n ráº±ng viá»‡c biáº¿n má»©c Ä‘á»™ phá»¥ thuá»™c vÃ o kÃ½ á»©c cá»§a tÃ¡c nhÃ¢n thÃ nh má»™t chiá»u hÃ nh vi cÃ³ thá»ƒ kiá»ƒm soÃ¡t bá»Ÿi ngÆ°á»i dÃ¹ng lÃ  má»™t sá»± thay Ä‘á»•i mÃ´ hÃ¬nh quan trá»ng. SteeM thÃ nh cÃ´ng trong viá»‡c cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘iá»u hÆ°á»›ng sá»± Ä‘Ã¡nh Ä‘á»•i giá»¯a tÃ­nh nháº¥t quÃ¡n vÃ  sá»± Ä‘á»•i má»›i dá»±a trÃªn nhu cáº§u tá»©c thá»i, thay Ä‘á»•i cá»§a há». HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ má»Ÿ rá»™ng kháº£ nÄƒng Ä‘iá»u khiá»ƒn nÃ y sang cÃ¡c khÃ­a cáº¡nh khÃ¡c cá»§a tÆ°Æ¡ng tÃ¡c LLM vÃ  khÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p hiá»‡u quáº£ hÆ¡n Ä‘á»ƒ táº¡o dá»¯ liá»‡u cÄƒn chá»‰nh sá»Ÿ thÃ­ch.

### V. Brainstorming Space:
#### 1. Publish Papers:
1. NghiÃªn cá»©u cÃ¡ch tÃ­ch há»£p kháº£ nÄƒng Ä‘iá»u khiá»ƒn bá»™ nhá»› Ä‘á»™ng nÃ y vÃ o cÃ¡c kiáº¿n trÃºc RAG Ä‘á»ƒ tinh chá»‰nh viá»‡c truy xuáº¥t vÃ  sá»­ dá»¥ng thÃ´ng tin tá»« cÆ¡ sá»Ÿ tri thá»©c bÃªn ngoÃ i.
2. PhÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ Ä‘á»‹nh lÆ°á»£ng cho sá»± cÃ¢n báº±ng giá»¯a tÃ­nh nháº¥t quÃ¡n vÃ  Ä‘á»•i má»›i trong cÃ¡c tÃ¡c nhÃ¢n LLM, vÆ°á»£t ra ngoÃ i sá»± phá»¥ thuá»™c vÃ o kÃ½ á»©c.
3. KhÃ¡m phÃ¡ cÃ¡ch Ã¡p dá»¥ng cÃ¡c nguyÃªn táº¯c kiá»ƒm soÃ¡t bá»™ nhá»› cá»§a SteeM Ä‘á»ƒ giáº£m thiá»ƒu thiÃªn vá»‹ hoáº·c thÃºc Ä‘áº©y sá»± sÃ¡ng táº¡o trong cÃ¡c tÃ¡c vá»¥ táº¡o ná»™i dung cá»¥ thá»ƒ.
#### 2. Patent:
1. Há»‡ thá»‘ng Ä‘iá»u khiá»ƒn má»©c Ä‘á»™ phá»¥ thuá»™c vÃ o bá»™ nhá»› cá»§a trá»£ lÃ½ áº£o trÃªn Ä‘iá»‡n thoáº¡i, cho phÃ©p ngÆ°á»i dÃ¹ng tÃ¹y chá»‰nh liá»‡u trá»£ lÃ½ cÃ³ nÃªn dá»±a nhiá»u vÃ o lá»‹ch sá»­ trÃ² chuyá»‡n Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i nháº¥t quÃ¡n hay Æ°u tiÃªn cÃ¡c pháº£n há»“i má»›i máº», Ä‘á»™c láº­p.
2. PhÆ°Æ¡ng phÃ¡p tÃ­ch há»£p thanh trÆ°á»£t hoáº·c nÃºt Ä‘iá»u chá»‰nh trÃªn giao diá»‡n á»©ng dá»¥ng chatbot di Ä‘á»™ng, cho phÃ©p ngÆ°á»i dÃ¹ng thiáº¿t láº­p má»©c Ä‘á»™ "sÃ¡ng táº¡o" hoáº·c "ghi nhá»›" cá»§a chatbot cho tá»«ng tÆ°Æ¡ng tÃ¡c cá»¥ thá»ƒ.
3. CÃ´ng nghá»‡ "cháº¿ Ä‘á»™ quÃªn táº¡m thá»i" cho cÃ¡c á»©ng dá»¥ng tin nháº¯n vÃ  trá»£ lÃ½ áº£o trÃªn Ä‘iá»‡n thoáº¡i, nÆ¡i ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ kÃ­ch hoáº¡t Ä‘á»ƒ tÃ¡c nhÃ¢n táº¡m thá»i bá» qua má»™t pháº§n lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c Ä‘á»ƒ Ä‘Æ°a ra gÃ³c nhÃ¬n má»›i máº» hÆ¡n cho cÃ¡c yÃªu cáº§u hiá»‡n táº¡i.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.05107](https://huggingface.co/papers/2601.05107) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.05107](https://arxiv.org/abs/2601.05107) |
| PDF Download | [https://arxiv.org/pdf/2601.05107.pdf](https://arxiv.org/pdf/2601.05107.pdf) |
| Github Repository | N/A |

--- 

## 11. DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving *(17 votes)*

**TÃ¡c giáº£:** Yang Zhou, Hao Shao, Letian Wang, Zhuofan Zong, Hongsheng Li, Steven L. Waslander

**Xuáº¥t báº£n lÃºc:** 2026-01-04

**Tag:** Generative Video Models, World Models, Autonomous Driving, Benchmark, Evaluation Metrics, Dataset

### I. Main Problem:
LÄ©nh vá»±c cÃ¡c mÃ´ hÃ¬nh tháº¿ giá»›i táº¡o video trong lÃ¡i xe tá»± hÃ nh hiá»‡n Ä‘ang thiáº¿u má»™t chuáº©n má»±c Ä‘Ã¡nh giÃ¡ toÃ n diá»‡n vÃ  nghiÃªm ngáº·t Ä‘á»ƒ Ä‘o lÆ°á»ng tiáº¿n Ä‘á»™ vÃ  Ä‘á»‹nh hÆ°á»›ng Æ°u tiÃªn nghiÃªn cá»©u. CÃ¡c Ä‘Ã¡nh giÃ¡ hiá»‡n cÃ³ cÃ²n háº¡n cháº¿: cÃ¡c chá»‰ sá»‘ video chung bá» qua cÃ¡c yáº¿u tá»‘ hÃ¬nh áº£nh quan trá»ng vá» an toÃ n; tÃ­nh há»£p lÃ½ cá»§a quá»¹ Ä‘áº¡o hiáº¿m khi Ä‘Æ°á»£c Ä‘á»‹nh lÆ°á»£ng; sá»± nháº¥t quÃ¡n vá» máº·t thá»i gian vÃ  cáº¥p Ä‘á»™ tÃ¡c nhÃ¢n bá»‹ bá» qua; vÃ  kháº£ nÄƒng kiá»ƒm soÃ¡t vá»›i Ä‘iá»u kiá»‡n ego bá»‹ phá»›t lá». HÆ¡n ná»¯a, cÃ¡c bá»™ dá»¯ liá»‡u hiá»‡n táº¡i khÃ´ng bao phá»§ Ä‘á»§ sá»± Ä‘a dáº¡ng vá» Ä‘iá»u kiá»‡n cáº§n thiáº¿t cho viá»‡c triá»ƒn khai thá»±c táº¿, bao gá»“m thá»i tiáº¿t, thá»i gian trong ngÃ y, khu vá»±c Ä‘á»‹a lÃ½ vÃ  cÃ¡c thao tÃ¡c phá»©c táº¡p.

### II. Main Idea:
Äá»ƒ giáº£i quyáº¿t nhá»¯ng háº¡n cháº¿ trÃªn, bÃ i bÃ¡o giá»›i thiá»‡u DrivingGen, chuáº©n má»±c toÃ n diá»‡n Ä‘áº§u tiÃªn cho cÃ¡c mÃ´ hÃ¬nh tháº¿ giá»›i táº¡o video trong lÃ¡i xe tá»± hÃ nh. DrivingGen káº¿t há»£p má»™t bá»™ dá»¯ liá»‡u Ä‘Ã¡nh giÃ¡ Ä‘a dáº¡ng Ä‘Æ°á»£c tuyá»ƒn chá»n tá»« cáº£ cÃ¡c bá»™ dá»¯ liá»‡u lÃ¡i xe vÃ  nguá»“n video quy mÃ´ internet, bao gá»“m nhiá»u Ä‘iá»u kiá»‡n thá»i tiáº¿t, thá»i gian trong ngÃ y, khu vá»±c Ä‘á»‹a lÃ½ vÃ  cÃ¡c thao tÃ¡c phá»©c táº¡p. Chuáº©n má»±c nÃ y cÃ²n Ä‘i kÃ¨m vá»›i má»™t bá»™ cÃ¡c chá»‰ sá»‘ má»›i Ä‘Ã¡nh giÃ¡ Ä‘á»“ng thá»i tÃ­nh chÃ¢n thá»±c trá»±c quan, tÃ­nh há»£p lÃ½ cá»§a quá»¹ Ä‘áº¡o, sá»± máº¡ch láº¡c vá» thá»i gian vÃ  kháº£ nÄƒng kiá»ƒm soÃ¡t.

### III. Main Results:
Viá»‡c thá»­ nghiá»‡m 14 mÃ´ hÃ¬nh tiÃªn tiáº¿n trÃªn DrivingGen cho tháº¥y nhá»¯ng Ä‘Ã¡nh Ä‘á»•i rÃµ rÃ ng: cÃ¡c mÃ´ hÃ¬nh chung táº¡o ra hÃ¬nh áº£nh Ä‘áº¹p máº¯t hÆ¡n nhÆ°ng vi pháº¡m cÃ¡c quy táº¯c váº­t lÃ½, trong khi cÃ¡c mÃ´ hÃ¬nh chuyÃªn biá»‡t cho lÃ¡i xe náº¯m báº¯t chuyá»ƒn Ä‘á»™ng má»™t cÃ¡ch thá»±c táº¿ nhÆ°ng láº¡i kÃ©m vá» cháº¥t lÆ°á»£ng hÃ¬nh áº£nh. DrivingGen cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t quan trá»ng vá» Ä‘iá»ƒm máº¡nh vÃ  Ä‘iá»ƒm yáº¿u cá»§a tá»«ng phÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n.

### IV. Conclusion & Future Works:
DrivingGen cung cáº¥p má»™t khung Ä‘Ã¡nh giÃ¡ thá»‘ng nháº¥t Ä‘á»ƒ thÃºc Ä‘áº©y phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh tháº¿ giá»›i lÃ¡i xe Ä‘Ã¡ng tin cáº­y, cÃ³ thá»ƒ kiá»ƒm soÃ¡t vÃ  triá»ƒn khai Ä‘Æ°á»£c, tá»« Ä‘Ã³ há»— trá»£ mÃ´ phá»ng má»Ÿ rá»™ng, láº­p káº¿ hoáº¡ch vÃ  ra quyáº¿t Ä‘á»‹nh dá»±a trÃªn dá»¯ liá»‡u. Táº¥t cáº£ cÃ¡c thÃ nh pháº§n cá»§a DrivingGen â€“ bá»™ dá»¯ liá»‡u vÃ  mÃ£ Ä‘Ã¡nh giÃ¡ â€“ Ä‘á»u Ä‘Æ°á»£c phÃ¡t hÃ nh cÃ´ng khai Ä‘á»ƒ há»— trá»£ nghiÃªn cá»©u cÃ³ thá»ƒ tÃ¡i táº¡o vÃ  thÃºc Ä‘áº©y mÃ´ phá»ng lÃ¡i xe thá»±c táº¿.

### V. Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u vá» phÆ°Æ¡ng phÃ¡p táº¡o video tháº¿ giá»›i má»›i cÃ³ kháº£ nÄƒng cÃ¢n báº±ng giá»¯a cháº¥t lÆ°á»£ng hÃ¬nh áº£nh trá»±c quan vÃ  Ä‘á»™ chÃ­nh xÃ¡c váº­t lÃ½ cá»§a quá»¹ Ä‘áº¡o chuyá»ƒn Ä‘á»™ng.
*   PhÃ¡t triá»ƒn cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡ chuyÃªn sÃ¢u hÆ¡n vá» tÃ­nh nháº¥t quÃ¡n cá»§a tÃ¡c nhÃ¢n vÃ  an toÃ n, Ä‘áº·c biá»‡t trong cÃ¡c tÃ¬nh huá»‘ng hiá»ƒm nghÃ¨o khÃ´ng Ä‘Æ°á»£c Ä‘áº¡i diá»‡n trong dá»¯ liá»‡u Ä‘Ã o táº¡o.
*   KhÃ¡m phÃ¡ viá»‡c sá»­ dá»¥ng há»c tÄƒng cÆ°á»ng Ä‘á»ƒ tá»‘i Æ°u hÃ³a cÃ¡c mÃ´ hÃ¬nh tháº¿ giá»›i táº¡o video, táº­p trung vÃ o viá»‡c tuÃ¢n thá»§ cÃ¡c quy táº¯c váº­t lÃ½ vÃ  kháº£ nÄƒng kiá»ƒm soÃ¡t.
#### 2. Patent:
*   Má»™t há»‡ thá»‘ng Ä‘Ã¡nh giÃ¡ video tháº¿ giá»›i lÃ¡i xe tá»± Ä‘á»™ng tÃ­ch há»£p cÃ¡c chá»‰ sá»‘ Ä‘a chiá»u vá» cháº¥t lÆ°á»£ng hÃ¬nh áº£nh, tÃ­nh váº­t lÃ½ cá»§a quá»¹ Ä‘áº¡o vÃ  tÃ­nh nháº¥t quÃ¡n thá»i gian, cháº¡y trÃªn ná»n táº£ng Ä‘Ã¡m mÃ¢y Ä‘á»ƒ cung cáº¥p dá»‹ch vá»¥ Ä‘Ã¡nh giÃ¡ cho cÃ¡c nhÃ  phÃ¡t triá»ƒn.
*   Má»™t phÆ°Æ¡ng phÃ¡p táº¡o dá»¯ liá»‡u tá»•ng há»£p cho lÃ¡i xe tá»± hÃ nh, táº­p trung vÃ o viá»‡c táº¡o ra cÃ¡c ká»‹ch báº£n hiáº¿m gáº·p (thá»i tiáº¿t kháº¯c nghiá»‡t, tÆ°Æ¡ng tÃ¡c phá»©c táº¡p) vá»›i Ä‘á»™ chÃ¢n thá»±c cao, Ä‘Æ°á»£c kiá»ƒm chá»©ng bá»Ÿi DrivingGen.
*   Má»™t thiáº¿t bá»‹ kiá»ƒm tra an toÃ n cho xe tá»± hÃ nh sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh tháº¿ giá»›i táº¡o video Ä‘á»ƒ mÃ´ phá»ng cÃ¡c tÃ¬nh huá»‘ng nguy hiá»ƒm vÃ  Ä‘Ã¡nh giÃ¡ pháº£n á»©ng cá»§a há»‡ thá»‘ng lÃ¡i xe tá»± hÃ nh, tÃ­ch há»£p kháº£ nÄƒng kiá»ƒm soÃ¡t Ä‘iá»u kiá»‡n Ä‘áº§u vÃ o cá»§a xe.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.01528](https://huggingface.co/papers/2601.01528) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.01528](https://arxiv.org/abs/2601.01528) |
| PDF Download | [https://arxiv.org/pdf/2601.01528.pdf](https://arxiv.org/pdf/2601.01528.pdf) |
| Github Repository | [https://github.com/youngzhou1999/DrivingGen](https://github.com/youngzhou1999/DrivingGen) |

--- 

## 12. MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era *(15 votes)*

**TÃ¡c giáº£:** Lei Zhang, Mouxiang Chen, Ruisheng Cao, Jiawei Chen, Fan Zhou, Yiheng Xu, Jiaxi Yang, Liang Chen, Changwei Luo, Kai Zhang, Fan Yan, KaShun Shum, Jiajun Zhang, Zeyu Cui, Hu Feng, Junyang Lin, Binyuan Hui, Min Yang

**Xuáº¥t báº£n lÃºc:** 2026-01-12

**Tag:** Agentic AI, Distributed System, Orchestration, Large-Scale Training, Cloud Computing

### I. Main Problem:
Sá»± phÃ¡t triá»ƒn nhanh chÃ³ng cá»§a cÃ¡c há»‡ thá»‘ng AI tÆ°Æ¡ng tÃ¡c vÃ  tá»± chá»§ (thá»i Ä‘áº¡i tÃ¡c nhÃ¢n) Ä‘Ã²i há»i háº¡ táº§ng phá»©c táº¡p Ä‘á»ƒ Ä‘iá»u phá»‘i cÃ¡c tÆ°Æ¡ng tÃ¡c giá»¯a tÃ¡c nhÃ¢n vÃ  mÃ´i trÆ°á»ng trÃªn quy mÃ´ lá»›n cho cÃ¡c tÃ¡c vá»¥ phá»©c táº¡p nhÆ° ká»¹ thuáº­t pháº§n má»m vÃ  sá»­ dá»¥ng mÃ¡y tÃ­nh. Háº¡ táº§ng mÃ£ nguá»“n má»Ÿ hiá»‡n cÃ³ khÃ´ng thá»ƒ há»— trá»£ hiá»‡u quáº£ viá»‡c huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c tÃ¡c vá»¥ tÃ¡c nhÃ¢n phá»©c táº¡p nÃ y, dáº«n Ä‘áº¿n ba nÃºt tháº¯t chÃ­nh: háº¡n cháº¿ vá» báº£o máº­t vÃ  cÃ´ láº­p (Security and Isolation Constraints), giá»›i háº¡n kháº£ nÄƒng má»Ÿ rá»™ng lÆ°u trá»¯ (Storage Scalability Limitations), vÃ  nÃºt tháº¯t vá» thÃ´ng lÆ°á»£ng tÃ­nh toÃ¡n (Computational Throughput Bottlenecks).

### II. Main Idea:
BÃ i bÃ¡o giá»›i thiá»‡u MegaFlow, má»™t há»‡ thá»‘ng Ä‘iá»u phá»‘i phÃ¢n tÃ¡n quy mÃ´ lá»›n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ giáº£i quyáº¿t nhá»¯ng thÃ¡ch thá»©c vá» háº¡ táº§ng trong viá»‡c huáº¥n luyá»‡n tÃ¡c nhÃ¢n AI. MegaFlow cho phÃ©p láº­p lá»‹ch trÃ¬nh hiá»‡u quáº£, phÃ¢n bá»• tÃ i nguyÃªn vÃ  quáº£n lÃ½ tÃ¡c vá»¥ chi tiáº¿t cho cÃ¡c tÃ¡c vá»¥ tÃ¡c nhÃ¢n-mÃ´i trÆ°á»ng. NÃ³ trá»«u tÆ°á»£ng hÃ³a háº¡ táº§ng huáº¥n luyá»‡n tÃ¡c nhÃ¢n thÃ nh ba dá»‹ch vá»¥ Ä‘á»™c láº­p: Model Service (xá»­ lÃ½ tÃ­nh toÃ¡n mÃ´ hÃ¬nh vÃ  cáº­p nháº­t tham sá»‘), Agent Service (Ä‘iá»u phá»‘i chiáº¿n lÆ°á»£c thá»±c thi tÃ¡c nhÃ¢n, thu tháº­p kinh nghiá»‡m), vÃ  Environment Service (cung cáº¥p mÃ´i trÆ°á»ng thá»±c thi tÆ°Æ¡ng tÃ¡c vÃ  áº£o hÃ³a, quáº£n lÃ½ láº­p lá»‹ch tÃ¡c vá»¥ phÃ¢n tÃ¡n). CÃ¡c dá»‹ch vá»¥ nÃ y tÆ°Æ¡ng tÃ¡c thÃ´ng qua giao diá»‡n thá»‘ng nháº¥t, cho phÃ©p má»Ÿ rá»™ng Ä‘á»™c láº­p vÃ  phÃ¢n bá»• tÃ i nguyÃªn linh hoáº¡t. MegaFlow Ã¡p dá»¥ng chiáº¿n lÆ°á»£c tÃ i nguyÃªn Ä‘Ã n há»“i ("many-small-instances"), mÃ´ hÃ¬nh thá»±c thi lai (táº¡m thá»i vÃ  bá»n bá»‰), Ä‘iá»u phá»‘i hÆ°á»›ng sá»± kiá»‡n, vÃ  á»§y quyá»n thÃ nh pháº§n chuyÃªn biá»‡t.

### III. Main Results:
MegaFlow Ä‘Ã£ thÃ nh cÃ´ng trong viá»‡c Ä‘iá»u phá»‘i hÃ ng chá»¥c nghÃ¬n tÃ¡c vá»¥ tÃ¡c nhÃ¢n Ä‘á»“ng thá»i, duy trÃ¬ Ä‘á»™ á»•n Ä‘á»‹nh há»‡ thá»‘ng cao vÃ  sá»­ dá»¥ng tÃ i nguyÃªn hiá»‡u quáº£. Há»‡ thá»‘ng Ä‘áº¡t Ä‘Æ°á»£c má»©c giáº£m chi phÃ­ 32% vÃ  kháº£ nÄƒng má»Ÿ rá»™ng nháº¥t quÃ¡n lÃªn hÃ ng chá»¥c nghÃ¬n tÃ¡c vá»¥ Ä‘á»“ng thá»i, vá»›i viá»‡c xÃ¡c thá»±c trong sáº£n xuáº¥t qua hÆ¡n 2 triá»‡u lÆ°á»£t thá»±c thi huáº¥n luyá»‡n tÃ¡c nhÃ¢n. MegaFlow kháº¯c phá»¥c cÃ¡c háº¡n cháº¿ vá» báº£o máº­t/cÃ´ láº­p báº±ng cÃ¡ch di chuyá»ƒn khá»‘i lÆ°á»£ng cÃ´ng viá»‡c container hÃ³a sang dá»‹ch vá»¥ Ä‘iá»‡n toÃ¡n Ä‘Ã¡m mÃ¢y Ä‘Ã n há»“i, giáº£i quyáº¿t cÃ¡c giá»›i háº¡n vá» kháº£ nÄƒng má»Ÿ rá»™ng lÆ°u trá»¯ báº±ng cÃ¡ch cung cáº¥p áº£nh container theo yÃªu cáº§u, vÃ  phÃ¡ vá»¡ cÃ¡c nÃºt tháº¯t thÃ´ng lÆ°á»£ng tÃ­nh toÃ¡n báº±ng cÃ¡ch Ä‘iá»u phá»‘i hÃ ng nghÃ¬n phiÃªn báº£n nháº¹.

### IV. Conclusion & Future Works:
MegaFlow giáº£i quyáº¿t má»™t khoáº£ng trá»‘ng háº¡ táº§ng quan trá»ng trong bá»‘i cáº£nh AI tÃ¡c nhÃ¢n má»›i ná»•i báº±ng cÃ¡ch cho phÃ©p huáº¥n luyá»‡n tÃ¡c nhÃ¢n quy mÃ´ lá»›n. ThÃ´ng Ä‘iá»‡p cuá»‘i cÃ¹ng lÃ  MegaFlow cung cáº¥p má»™t giáº£i phÃ¡p máº¡nh máº½ vÃ  hiá»‡u quáº£ cho nhá»¯ng thÃ¡ch thá»©c liÃªn quan Ä‘áº¿n quy mÃ´ vÃ  Ä‘á»™ phá»©c táº¡p cá»§a viá»‡c huáº¥n luyá»‡n AI tÃ¡c nhÃ¢n. VÄƒn báº£n trÃ­ch dáº«n khÃ´ng Ä‘á» cáº­p rÃµ rÃ ng Ä‘áº¿n cÃ¡c hÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo.

### V. Brainstorming Space:
#### 1. Publish Papers:
NghiÃªn cá»©u phÃ¡t triá»ƒn cÃ¡c thuáº­t toÃ¡n láº­p lá»‹ch trÃ¬nh Ä‘á»™ng vÃ  thÃ­ch á»©ng trong MegaFlow Ä‘á»ƒ tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t cho cÃ¡c tÃ¡c vá»¥ tÃ¡c nhÃ¢n cÃ³ tÃ­nh cháº¥t ngáº¯t quÃ£ng vÃ  yÃªu cáº§u tÃ i nguyÃªn khÃ´ng Ä‘á»“ng nháº¥t. KhÃ¡m phÃ¡ viá»‡c tÃ­ch há»£p MegaFlow vá»›i cÃ¡c khung há»c tÄƒng cÆ°á»ng phÃ¢n tÃ¡n (distributed RL frameworks) tiÃªn tiáº¿n Ä‘á»ƒ há»— trá»£ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh tÃ¡c nhÃ¢n Ä‘a tÃ¡c nhÃ¢n trÃªn quy mÃ´ lá»›n hÆ¡n ná»¯a. PhÃ¢n tÃ­ch áº£nh hÆ°á»Ÿng cá»§a kiáº¿n trÃºc ba dá»‹ch vá»¥ cá»§a MegaFlow Ä‘áº¿n kháº£ nÄƒng chá»‹u lá»—i vÃ  tÃ­nh bá»n vá»¯ng cá»§a há»‡ thá»‘ng khi Ä‘á»‘i máº·t vá»›i cÃ¡c lá»—i dá»‹ch vá»¥ riÃªng láº» hoáº·c sá»± cá»‘ máº¡ng.

#### 2. Patent:
Há»‡ thá»‘ng Ä‘iá»u phá»‘i tÃ i nguyÃªn AI thÃ´ng minh cho thiáº¿t bá»‹ di Ä‘á»™ng, tá»± Ä‘á»™ng phÃ¢n chia vÃ  chuyá»ƒn giao cÃ¡c tÃ¡c vá»¥ há»c tÄƒng cÆ°á»ng phá»©c táº¡p giá»¯a thiáº¿t bá»‹ vÃ  Ä‘Ã¡m mÃ¢y dá»±a trÃªn má»©c Ä‘á»™ sá»­ dá»¥ng pin vÃ  hiá»‡u nÄƒng. PhÆ°Æ¡ng phÃ¡p cung cáº¥p mÃ´i trÆ°á»ng thá»±c thi áº£o hÃ³a an toÃ n vÃ  theo yÃªu cáº§u cho cÃ¡c á»©ng dá»¥ng AI tÆ°Æ¡ng tÃ¡c trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, giáº£m thiá»ƒu rá»§i ro báº£o máº­t vÃ  tá»‘i Æ°u hÃ³a bá»™ nhá»› cá»¥c bá»™. CÃ´ng nghá»‡ tá»‘i Æ°u hÃ³a lÆ°u trá»¯ dá»¯ liá»‡u AI trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng báº±ng cÃ¡ch sá»­ dá»¥ng cÆ¡ cháº¿ cung cáº¥p áº£nh container theo yÃªu cáº§u tá»« Ä‘Ã¡m mÃ¢y, cho phÃ©p cÃ¡c á»©ng dá»¥ng AI náº·ng hoáº¡t Ä‘á»™ng hiá»‡u quáº£ mÃ  khÃ´ng tá»‘n dung lÆ°á»£ng bá»™ nhá»› cá»‘ Ä‘á»‹nh.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.07526](https://huggingface.co/papers/2601.07526) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.07526](https://arxiv.org/abs/2601.07526) |
| PDF Download | [https://arxiv.org/pdf/2601.07526.pdf](https://arxiv.org/pdf/2601.07526.pdf) |
| Github Repository | N/A |

--- 

## 13. Boosting Latent Diffusion Models via Disentangled Representation Alignment *(14 votes)*

**TÃ¡c giáº£:** John Page, Xuesong Niu, Kai Wu, Kun Gai

**Xuáº¥t báº£n lÃºc:** 2026-01-09

**Tag:** Diffusion, Latent Diffusion Models, VAE, Representation Alignment, Semantic Disentanglement

### I. Main Problem:
CÃ¡c Latent Diffusion Model (LDM) táº¡o ra hÃ¬nh áº£nh cháº¥t lÆ°á»£ng cao báº±ng cÃ¡ch hoáº¡t Ä‘á»™ng trong khÃ´ng gian tiá»m áº©n nÃ©n, thÆ°á»ng thu Ä‘Æ°á»£c qua cÃ¡c VAE. Tuy nhiÃªn, cÃ¡c nghiÃªn cá»©u gáº§n Ä‘Ã¢y thÆ°á»ng sá»­ dá»¥ng cÃ¹ng má»™t má»¥c tiÃªu cÄƒn chá»‰nh (alignment target) cho cáº£ VAE vÃ  LDM vá»›i Vision Foundation Models (VFM), bá» qua cÃ¡c yÃªu cáº§u biá»ƒu diá»…n khÃ¡c biá»‡t cÆ¡ báº£n cá»§a chÃºng. LDM cáº§n cÃ¡c khÃ¡i niá»‡m ngá»¯ nghÄ©a cáº¥p cao Ä‘á»ƒ táº¡o mÃ´ hÃ¬nh sinh, trong khi VAE nÃªn Æ°u viá»‡t trong kháº£ nÄƒng phÃ¢n tÃ¡ch ngá»¯ nghÄ©a (semantic disentanglement) Ä‘á»ƒ mÃ£ hÃ³a thÃ´ng tin chi tiáº¿t cáº¥p thuá»™c tÃ­nh má»™t cÃ¡ch cÃ³ cáº¥u trÃºc. Sá»± bá» qua nÃ y dáº«n Ä‘áº¿n hiá»‡u suáº¥t táº¡o áº£nh vÃ  hiá»‡u quáº£ huáº¥n luyá»‡n chÆ°a tá»‘i Æ°u.

### II. Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t Semantic-disentangled VAE (Send-V AE), Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a rÃµ rÃ ng cho viá»‡c há»c biá»ƒu diá»…n phÃ¢n tÃ¡ch báº±ng cÃ¡ch cÄƒn chá»‰nh khÃ´ng gian tiá»m áº©n cá»§a nÃ³ vá»›i há»‡ thá»‘ng phÃ¢n cáº¥p ngá»¯ nghÄ©a cá»§a cÃ¡c VFM Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c. PhÆ°Æ¡ng phÃ¡p nÃ y sá»­ dá»¥ng má»™t máº¡ng lÆ°á»›i Ã¡nh xáº¡ phi tuyáº¿n tinh vi Ä‘á»ƒ chuyá»ƒn Ä‘á»•i biá»ƒu diá»…n tiá»m áº©n cá»§a VAE, cÄƒn chá»‰nh chÃºng vá»›i biá»ƒu diá»…n tá»« cÃ¡c VFM. Máº¡ng Ã¡nh xáº¡ nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ thu háº¹p khoáº£ng cÃ¡ch biá»ƒu diá»…n giá»¯a viá»‡c phÃ¢n tÃ¡ch cáº¥p thuá»™c tÃ­nh vÃ  ngá»¯ nghÄ©a cáº¥p cao do VFM cung cáº¥p, tá»« Ä‘Ã³ nÃ¢ng cao kháº£ nÄƒng phÃ¢n tÃ¡ch ngá»¯ nghÄ©a cá»§a VAE.

### III. Main Results:
*   XÃ¡c Ä‘á»‹nh kháº£ nÄƒng phÃ¢n tÃ¡ch ngá»¯ nghÄ©a lÃ  má»™t thuá»™c tÃ­nh cá»‘t lÃµi cá»§a cÃ¡c VAE thÃ¢n thiá»‡n vá»›i quÃ¡ trÃ¬nh táº¡o áº£nh, Ä‘Æ°á»£c xÃ¡c minh báº±ng má»‘i tÆ°Æ¡ng quan cháº·t cháº½ giá»¯a Ä‘á»™ chÃ­nh xÃ¡c dá»± Ä‘oÃ¡n thuá»™c tÃ­nh cáº¥p tháº¥p vÃ  hiá»‡u suáº¥t táº¡o áº£nh Ä‘áº§u ra.
*   Send-V AE tÄƒng tá»‘c Ä‘Ã¡ng ká»ƒ quÃ¡ trÃ¬nh huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh khuáº¿ch tÃ¡n dá»±a trÃªn dÃ²ng cháº£y (flow-based transformers) nhÆ° SiTs.
*   Thiáº¿t láº­p ká»· lá»¥c má»›i vá» Ä‘iá»ƒm FID (FrÃ©chet Inception Distance) hiá»‡n Ä‘áº¡i: 1.21 (cÃ³ hÆ°á»›ng dáº«n phÃ¢n loáº¡i miá»…n phÃ­) vÃ  1.75 (khÃ´ng cÃ³ hÆ°á»›ng dáº«n phÃ¢n loáº¡i miá»…n phÃ­) trÃªn ImageNet Ä‘á»™ phÃ¢n giáº£i 256x256.

### IV. Conclusion & Future Works:
BÃ i bÃ¡o kháº³ng Ä‘á»‹nh kháº£ nÄƒng phÃ¢n tÃ¡ch ngá»¯ nghÄ©a lÃ  má»™t thuá»™c tÃ­nh cá»‘t lÃµi cá»§a cÃ¡c VAE thÃ¢n thiá»‡n vá»›i quÃ¡ trÃ¬nh táº¡o áº£nh, vÃ  phÆ°Æ¡ng phÃ¡p Send-V AE Ä‘Ã£ chá»©ng minh Ä‘Æ°á»£c hiá»‡u quáº£ vÆ°á»£t trá»™i. Send-V AE, thÃ´ng qua viá»‡c cÄƒn chá»‰nh vá»›i VFM báº±ng máº¡ng Ã¡nh xáº¡ phi tuyáº¿n, khÃ´ng chá»‰ nÃ¢ng cao kháº£ nÄƒng phÃ¢n tÃ¡ch ngá»¯ nghÄ©a cá»§a VAE mÃ  cÃ²n tÄƒng tá»‘c Ä‘Ã¡ng ká»ƒ quÃ¡ trÃ¬nh huáº¥n luyá»‡n mÃ´ hÃ¬nh khuáº¿ch tÃ¡n vÃ  Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t táº¡o áº£nh hiá»‡n Ä‘áº¡i. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ khÃ¡m phÃ¡ sÃ¢u hÆ¡n cÃ¡ch tá»‘i Æ°u hÃ³a máº¡ng Ã¡nh xáº¡ hoáº·c Ã¡p dá»¥ng nguyÃªn lÃ½ nÃ y cho cÃ¡c loáº¡i bá»™ mÃ£ hÃ³a áº£nh khÃ¡c.

### V. Brainstorming Space:
#### 1. Publish Papers:
*   NghiÃªn cá»©u áº£nh hÆ°á»Ÿng cá»§a cÃ¡c kiáº¿n trÃºc máº¡ng Ã¡nh xáº¡ phi tuyáº¿n khÃ¡c nhau lÃªn kháº£ nÄƒng phÃ¢n tÃ¡ch ngá»¯ nghÄ©a vÃ  hiá»‡u suáº¥t cá»§a VAE.
*   PhÃ¢n tÃ­ch Ä‘á»‹nh lÆ°á»£ng chi tiáº¿t hÆ¡n má»‘i quan há»‡ giá»¯a cÃ¡c loáº¡i thuá»™c tÃ­nh (mÃ u sáº¯c, hÃ¬nh dáº¡ng, texture) vÃ  kháº£ nÄƒng phÃ¢n tÃ¡ch cá»§a VAE, cÅ©ng nhÆ° áº£nh hÆ°á»Ÿng cá»§a chÃºng Ä‘áº¿n cháº¥t lÆ°á»£ng áº£nh táº¡o ra.
*   Ãp dá»¥ng nguyÃªn lÃ½ cÄƒn chá»‰nh biá»ƒu diá»…n phÃ¢n tÃ¡ch cá»§a Send-V AE cho cÃ¡c loáº¡i bá»™ mÃ£ hÃ³a hÃ¬nh áº£nh khÃ¡c ngoÃ i VAE, vÃ­ dá»¥ nhÆ° tokenizer rá»i ráº¡c hoáº·c cÃ¡c mÃ´ hÃ¬nh mÃ£ hÃ³a tá»± Ä‘á»™ng khÃ¡c.

#### 2. Patent:
*   Há»‡ thá»‘ng chá»‰nh sá»­a áº£nh thÃ´ng minh trÃªn Ä‘iá»‡n thoáº¡i di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng Ä‘iá»u chá»‰nh cÃ¡c thuá»™c tÃ­nh cá»¥ thá»ƒ cá»§a Ä‘á»‘i tÆ°á»£ng trong áº£nh (vÃ­ dá»¥: thay Ä‘á»•i mÃ u Ã¡o, kiá»ƒu tÃ³c) má»™t cÃ¡ch Ä‘á»™c láº­p vÃ  chÃ­nh xÃ¡c nhá» VAE phÃ¢n tÃ¡ch ngá»¯ nghÄ©a.
*   CÃ´ng nghá»‡ táº¡o hÃ¬nh Ä‘áº¡i diá»‡n (avatar) cÃ¡ nhÃ¢n hÃ³a cho á»©ng dá»¥ng gá»i video trÃªn Ä‘iá»‡n thoáº¡i, tá»± Ä‘á»™ng táº¡o ra cÃ¡c biá»ƒu cáº£m hoáº·c phá»¥ kiá»‡n dá»±a trÃªn cÃ¡c thuá»™c tÃ­nh riÃªng biá»‡t Ä‘Æ°á»£c há»c tá»« khuÃ´n máº·t ngÆ°á»i dÃ¹ng.
*   PhÆ°Æ¡ng phÃ¡p tÄƒng cÆ°á»ng cháº¥t lÆ°á»£ng video ngáº¯n trÃªn Ä‘iá»‡n thoáº¡i báº±ng cÃ¡ch sá»­ dá»¥ng VAE Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a Ä‘á»ƒ phÃ¢n tÃ¡ch cÃ¡c yáº¿u tá»‘ nhÆ° Ã¡nh sÃ¡ng, mÃ´i trÆ°á»ng vÃ  Ä‘á»‘i tÆ°á»£ng, cho phÃ©p chá»‰nh sá»­a háº­u ká»³ linh hoáº¡t hÆ¡n vÃ  giáº£m nhiá»…u hiá»‡u quáº£.
*   á»¨ng dá»¥ng camera Ä‘iá»‡n thoáº¡i cÃ³ kháº£ nÄƒng tá»‘i Æ°u hÃ³a áº£nh tá»± Ä‘á»™ng báº±ng cÃ¡ch nháº­n diá»‡n vÃ  Ä‘iá»u chá»‰nh cÃ¡c thuá»™c tÃ­nh cá»§a Ä‘á»‘i tÆ°á»£ng trong áº£nh, vÃ­ dá»¥ nhÆ° lÃ m sÃ¡ng da, Ä‘iá»u chá»‰nh mÃ u sáº¯c trang phá»¥c mÃ  khÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c yáº¿u tá»‘ khÃ¡c.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.05823](https://huggingface.co/papers/2601.05823) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.05823](https://arxiv.org/abs/2601.05823) |
| PDF Download | [https://arxiv.org/pdf/2601.05823.pdf](https://arxiv.org/pdf/2601.05823.pdf) |
| Github Repository | N/A |

--- 

## 14. What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models *(14 votes)*

**TÃ¡c giáº£:** Dasol Choi, Guijin Son, Hanwool Lee, Minhyuk Kim, Hyunwoo Ko, Teabin Lim, Ahn Eungyeol, Jungwhan Kim, Seunghyeok Hong, Youngsook Song

**Xuáº¥t báº£n lÃºc:** 2026-01-07

**Tag:** Vision-Language Models, Benchmarking, Under-Specified Queries, HAERAE-Vision

### I. Main Problem:
CÃ¡c mÃ´ hÃ¬nh thá»‹ giÃ¡c-ngÃ´n ngá»¯ (VLM) hiá»‡n táº¡i chá»§ yáº¿u Ä‘Æ°á»£c Ä‘Ã¡nh giÃ¡ trÃªn cÃ¡c bá»™ dá»¯ liá»‡u vá»›i cÃ¡c cÃ¢u há»i rÃµ rÃ ng, cÃ³ cáº¥u trÃºc tá»‘t, trong khi cÃ¡c truy váº¥n cá»§a ngÆ°á»i dÃ¹ng thá»±c táº¿ thÆ°á»ng khÃ´ng chÃ­nh thá»©c, thiáº¿u chi tiáº¿t vÃ  dá»±a nhiá»u vÃ o hÃ¬nh áº£nh Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh. Äiá»u nÃ y táº¡o ra má»™t khoáº£ng cÃ¡ch Ä‘Ã¡ng ká»ƒ giá»¯a hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn cÃ¡c benchmark vÃ  kháº£ nÄƒng á»©ng dá»¥ng trong tháº¿ giá»›i thá»±c, nÆ¡i ngÆ°á»i dÃ¹ng thÆ°á»ng Ä‘á»ƒ láº¡i nhiá»u thÃ´ng tin khÃ´ng Ä‘Æ°á»£c nÃ³i rÃµ.

### II. Main Idea:
NghiÃªn cá»©u giá»›i thiá»‡u HAERAE-Vision, má»™t bá»™ dá»¯ liá»‡u benchmark má»›i gá»“m 653 cÃ¢u há»i hÃ¬nh áº£nh thá»±c táº¿ Ä‘Æ°á»£c thu tháº­p tá»« cÃ¡c cá»™ng Ä‘á»“ng trá»±c tuyáº¿n cá»§a HÃ n Quá»‘c. Äá»ƒ Ä‘á»‹nh lÆ°á»£ng tÃ¡c Ä‘á»™ng cá»§a viá»‡c thiáº¿u chi tiáº¿t trong truy váº¥n, má»—i cÃ¢u há»i gá»‘c (khÃ´ng rÃµ rÃ ng) Ä‘Æ°á»£c ghÃ©p ná»‘i vá»›i má»™t phiÃªn báº£n viáº¿t láº¡i rÃµ rÃ ng, táº¡o ra tá»•ng cá»™ng 1.306 biáº¿n thá»ƒ truy váº¥n. HAERAE-Vision Ä‘Æ°á»£c xÃ¢y dá»±ng thÃ´ng qua má»™t quy trÃ¬nh lá»c sÃ¡u giai Ä‘oáº¡n nghiÃªm ngáº·t tá»« hÆ¡n 86.000 á»©ng cá»­ viÃªn Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng vÃ  tÃ­nh Ä‘áº¡i diá»‡n cho cÃ¡c tÆ°Æ¡ng tÃ¡c Ä‘a phÆ°Æ¡ng thá»©c thá»±c táº¿.

### III. Main Results:
- CÃ¡c mÃ´ hÃ¬nh VLM tiÃªn tiáº¿n nháº¥t (nhÆ° GPT-5 vÃ  Gemini 2.5 Pro) Ä‘áº¡t dÆ°á»›i 50% Ä‘á»™ chÃ­nh xÃ¡c trÃªn cÃ¡c truy váº¥n gá»‘c (khÃ´ng rÃµ rÃ ng) trong HAERAE-Vision.
- Viá»‡c lÃ m rÃµ truy váº¥n (explicitation) giÃºp cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t tá»« 8 Ä‘áº¿n 22 Ä‘iá»ƒm pháº§n trÄƒm, vá»›i cÃ¡c mÃ´ hÃ¬nh nhá» hÆ¡n cÃ³ má»©c cáº£i thiá»‡n lá»›n nháº¥t.
- Ngay cáº£ khi cÃ³ há»— trá»£ tÃ¬m kiáº¿m web, cÃ¡c truy váº¥n thiáº¿u chi tiáº¿t váº«n cho hiá»‡u suáº¥t kÃ©m hÆ¡n so vá»›i cÃ¡c truy váº¥n rÃµ rÃ ng khÃ´ng cáº§n tÃ¬m kiáº¿m, cho tháº¥y cÃ¡c há»‡ thá»‘ng truy xuáº¥t hiá»‡n táº¡i chÆ°a thá»ƒ bÃ¹ Ä‘áº¯p cho nhá»¯ng gÃ¬ ngÆ°á»i dÃ¹ng khÃ´ng nÃ³i rÃµ.
- Má»™t pháº§n Ä‘Ã¡ng ká»ƒ cá»§a khÃ³ khÄƒn trong cÃ¡c VLM khÃ´ng pháº£i do giá»›i háº¡n kháº£ nÄƒng cá»§a mÃ´ hÃ¬nh mÃ  do tÃ­nh cháº¥t thiáº¿u chi tiáº¿t tá»± nhiÃªn cá»§a cÃ¡c truy váº¥n ngÆ°á»i dÃ¹ng.

### IV. Conclusion & Future Works:
NghiÃªn cá»©u káº¿t luáº­n ráº±ng viá»‡c thiáº¿u chi tiáº¿t tá»± nhiÃªn trong cÃ¡c truy váº¥n cá»§a ngÆ°á»i dÃ¹ng lÃ  má»™t thÃ¡ch thá»©c cÆ¡ báº£n Ä‘á»‘i vá»›i cÃ¡c mÃ´ hÃ¬nh thá»‹ giÃ¡c-ngÃ´n ngá»¯, vÃ  cÃ¡c benchmark hiá»‡n táº¡i chÆ°a pháº£n Ã¡nh Ä‘Ãºng thá»±c táº¿ nÃ y. HAERAE-Vision Ä‘Ã³ng vai trÃ² lÃ  má»™t cÃ´ng cá»¥ quan trá»ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¡c VLM trong bá»‘i cáº£nh thá»±c táº¿ hÆ¡n, cho tháº¥y sá»± cáº§n thiáº¿t pháº£i phÃ¡t triá»ƒn cÃ¡c mÃ´ hÃ¬nh cÃ³ thá»ƒ suy luáº­n tá»‘t hÆ¡n Ã½ Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng tá»« cÃ¡c truy váº¥n khÃ´ng rÃµ rÃ ng vÃ  thÃ´ng tin hÃ¬nh áº£nh. HÆ°á»›ng nghiÃªn cá»©u tiáº¿p theo cÃ³ thá»ƒ táº­p trung vÃ o viá»‡c phÃ¡t triá»ƒn cÃ¡c phÆ°Æ¡ng phÃ¡p Ä‘á»ƒ cÃ¡c VLM chá»§ Ä‘á»™ng yÃªu cáº§u lÃ m rÃµ hoáº·c suy luáº­n ngá»¯ cáº£nh cÃ²n thiáº¿u Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t trong cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿.

### V. Brainstorming Space:
#### 1. Publish Papers:
PhÃ¡t triá»ƒn má»™t phÆ°Æ¡ng phÃ¡p VLM má»›i cÃ³ kháº£ nÄƒng tá»± Ä‘á»™ng táº¡o ra cÃ¡c cÃ¢u há»i lÃ m rÃµ Ä‘á»ƒ thu háº¹p khoáº£ng cÃ¡ch thÃ´ng tin tá»« cÃ¡c truy váº¥n khÃ´ng rÃµ rÃ ng. XÃ¢y dá»±ng má»™t benchmark Ä‘a ngÃ´n ngá»¯ tÆ°Æ¡ng tá»± HAERAE-Vision Ä‘á»ƒ nghiÃªn cá»©u tÃ¡c Ä‘á»™ng cá»§a viá»‡c thiáº¿u chi tiáº¿t truy váº¥n trÃªn nhiá»u ná»n vÄƒn hÃ³a vÃ  ngÃ´n ngá»¯ khÃ¡c nhau. NghiÃªn cá»©u cÆ¡ cháº¿ "suy luáº­n Ã½ Ä‘á»‹nh" trong VLM Ä‘á»ƒ cho phÃ©p chÃºng hiá»ƒu ngá»¯ cáº£nh vÃ  má»¥c Ä‘Ã­ch cá»§a ngÆ°á»i dÃ¹ng ngay cáº£ khi truy váº¥n thiáº¿u chi tiáº¿t, khÃ´ng cáº§n Ä‘áº¿n bÆ°á»›c lÃ m rÃµ.

#### 2. Patent:
Má»™t há»‡ thá»‘ng á»©ng dá»¥ng di Ä‘á»™ng cho phÃ©p ngÆ°á»i dÃ¹ng chá»¥p áº£nh vÃ  Ä‘áº·t cÃ¢u há»i khÃ´ng rÃµ rÃ ng, sau Ä‘Ã³ AI trÃªn Ä‘iá»‡n thoáº¡i tá»± Ä‘á»™ng lÃ m rÃµ truy váº¥n vÃ  cung cáº¥p cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c. CÃ´ng nghá»‡ tÃ­ch há»£p vÃ o camera Ä‘iá»‡n thoáº¡i thÃ´ng minh Ä‘á»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh vÃ  gá»£i Ã½ cÃ¡c cÃ¢u há»i lÃ m rÃµ khi ngÆ°á»i dÃ¹ng nháº­p truy váº¥n ngáº¯n gá»n, giÃºp há» nháº­n Ä‘Æ°á»£c thÃ´ng tin chÃ­nh xÃ¡c hÆ¡n. Má»™t giao diá»‡n ngÆ°á»i dÃ¹ng dá»±a trÃªn AI trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh, nÆ¡i cÃ¡c truy váº¥n hÃ¬nh áº£nh thiáº¿u chi tiáº¿t Ä‘Æ°á»£c tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i thÃ nh truy váº¥n rÃµ rÃ ng báº±ng cÃ¡ch phÃ¢n tÃ­ch bá»‘i cáº£nh hÃ¬nh áº£nh vÃ  lá»‹ch sá»­ tÆ°Æ¡ng tÃ¡c cá»§a ngÆ°á»i dÃ¹ng.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.06165](https://huggingface.co/papers/2601.06165) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.06165](https://arxiv.org/abs/2601.06165) |
| PDF Download | [https://arxiv.org/pdf/2601.06165.pdf](https://arxiv.org/pdf/2601.06165.pdf) |
| Github Repository | [https://github.com/HAE-RAE/HAERAE-VISION](https://github.com/HAE-RAE/HAERAE-VISION) |

--- 

## 15. ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration *(13 votes)*

**TÃ¡c giáº£:** Yifei Chen, Guanting Dong, Zhicheng Dou

**Xuáº¥t báº£n lÃºc:** 2026-01-11

**Tag:** LLMs, Tool-Integrated Reasoning (TIR), Agent, Behavior Calibration, Reinforcement Learning

### I. Main Problem:
Váº¥n Ä‘á» cá»‘t lÃµi lÃ  cÃ¡c khung Ä‘Ã o táº¡o tÃ¡c nhÃ¢n dá»±a trÃªn MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLMs) hiá»‡n táº¡i thÆ°á»ng chá»‰ táº­p trung vÃ o Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¢u tráº£ lá»i mÃ  bá» qua viá»‡c hiá»‡u chá»‰nh cÃ¡c máº«u hÃ nh vi cá»¥ thá»ƒ trong cÃ¡c tÃ¡c vá»¥ suy luáº­n tÃ­ch há»£p cÃ´ng cá»¥ (TIR). Äiá»u nÃ y dáº«n Ä‘áº¿n cÃ¡c hÃ nh Ä‘á»™ng khÃ´ng hiá»‡u quáº£ cá»§a tÃ¡c nhÃ¢n nhÆ° gá»i cÃ´ng cá»¥ thá»«a thÃ£i hoáº·c khÃ´ng Ä‘á»§, cÅ©ng nhÆ° logic suy luáº­n bá»‹ lá»—i, gÃ¢y khÃ³ khÄƒn cho viá»‡c khÃ¡m phÃ¡ cÃ¡c quá»¹ Ä‘áº¡o hiá»‡u quáº£.

### II. Main Idea:
BÃ i bÃ¡o Ä‘á» xuáº¥t ET-Agent, má»™t khung Ä‘Ã o táº¡o Ä‘á»ƒ hiá»‡u chá»‰nh hÃ nh vi sá»­ dá»¥ng cÃ´ng cá»¥ cá»§a tÃ¡c nhÃ¢n thÃ´ng qua hai thÃ nh pháº§n phá»‘i há»£p: Self-evolving Data Flywheel vÃ  Behavior Calibration Training. Self-evolving Data Flywheel táº¡o ra dá»¯ liá»‡u nÃ¢ng cao Ä‘á»ƒ tinh chá»‰nh LLM, cáº£i thiá»‡n kháº£ nÄƒng khÃ¡m phÃ¡ cá»§a nÃ³. Dá»±a trÃªn dá»¯ liá»‡u nÃ y, Behavior Calibration Training gá»“m hai pha sáº½ dáº§n dáº§n hiá»‡u chá»‰nh cÃ¡c máº«u hÃ nh vi sai lá»‡ch thÃ nh hÃ nh vi tá»‘i Æ°u. Cá»¥ thá»ƒ, nÃ³ sá»­ dá»¥ng Action Space Exploration Fine-tuning Ä‘á»ƒ má»Ÿ rá»™ng khÃ´ng gian hÃ nh Ä‘á»™ng, sau Ä‘Ã³ lÃ  Iterative Behavior Calibration Reinforcement Learning káº¿t há»£p Group-wise Pareto Sampling vÃ  Curriculum RL Training Ä‘á»ƒ Ä‘iá»u chá»‰nh hÃ nh Ä‘á»™ng.

### III. Main Results:
CÃ¡c thá»­ nghiá»‡m chuyÃªn sÃ¢u xÃ¡c nháº­n ET-Agent vÆ°á»£t trá»™i trÃªn nhiá»u khÃ­a cáº¡nh bao gá»“m Ä‘á»™ chÃ­nh xÃ¡c, hiá»‡u quáº£, sá»± cÃ´ Ä‘á»ng cá»§a suy luáº­n vÃ  Ä‘á»™ chÃ­nh xÃ¡c thá»±c thi cÃ´ng cá»¥. ET-Agent Ä‘áº¡t Ä‘Æ°á»£c hiá»‡u suáº¥t tá»‘t nháº¥t trÃªn táº¥t cáº£ cÃ¡c khÃ­a cáº¡nh Ä‘Ã£ kiá»ƒm tra, cho tháº¥y sá»± thÃ nh cÃ´ng cá»§a viá»‡c hiá»‡u chá»‰nh hÃ nh vi TIR. NÃ³ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u quáº£ hÃ nh vi, sá»± cÃ´ Ä‘á»ng cá»§a suy luáº­n vÃ  tá»· lá»‡ thÃ nh cÃ´ng thá»±c thi trong khi váº«n duy trÃ¬ Ä‘á»™ chÃ­nh xÃ¡c cao.

### IV. Conclusion & Future Works:
ET-Agent cung cáº¥p nhá»¯ng hiá»ƒu biáº¿t thá»±c táº¿ cho nghiÃªn cá»©u trong lÄ©nh vá»±c suy luáº­n tÃ­ch há»£p cÃ´ng cá»¥ (TIR) báº±ng cÃ¡ch giáº£i quyáº¿t triá»‡t Ä‘á»ƒ váº¥n Ä‘á» hiá»‡u chá»‰nh hÃ nh vi sá»­ dá»¥ng cÃ´ng cá»¥ cá»§a tÃ¡c nhÃ¢n LLM, dáº«n Ä‘áº¿n hiá»‡u suáº¥t vÆ°á»£t trá»™i trÃªn nhiá»u tiÃªu chÃ­.

### V. Brainstorming Space:
#### 1. Publish Papers:
1. NghiÃªn cá»©u cÃ¡ch Ã¡p dá»¥ng cÆ¡ cháº¿ tá»± tiáº¿n hÃ³a cá»§a ET-Agent Ä‘á»ƒ táº¡o ra cÃ¡c táº­p dá»¯ liá»‡u tá»± sá»­a lá»—i cho cÃ¡c tÃ¡c vá»¥ suy luáº­n phá»©c táº¡p.
2. KhÃ¡m phÃ¡ cÃ¡c phÆ°Æ¡ng phÃ¡p má»›i Ä‘á»ƒ tÃ­ch há»£p hiá»‡u chá»‰nh hÃ nh vi Ä‘a tÃ¡c nhÃ¢n trong cÃ¡c mÃ´i trÆ°á»ng TIR há»£p tÃ¡c.
3. ÄÃ¡nh giÃ¡ kháº£ nÄƒng cá»§a ET-Agent trong viá»‡c giáº£m thiá»ƒu thiÃªn vá»‹ vÃ  cáº£i thiá»‡n tÃ­nh cÃ´ng báº±ng trong cÃ¡c quyáº¿t Ä‘á»‹nh sá»­ dá»¥ng cÃ´ng cá»¥.
#### 2. Patent:
1. Há»‡ thá»‘ng trá»£ lÃ½ AI trÃªn Ä‘iá»‡n thoáº¡i thÃ´ng minh sá»­ dá»¥ng ET-Agent Ä‘á»ƒ tá»± Ä‘á»™ng tá»‘i Æ°u hÃ³a viá»‡c gá»i cÃ¡c á»©ng dá»¥ng vÃ  chá»©c nÄƒng há»‡ thá»‘ng, giáº£m thá»i gian xá»­ lÃ½ vÃ  tiÃªu thá»¥ pin.
2. PhÆ°Æ¡ng phÃ¡p hiá»‡u chá»‰nh hÃ nh vi cho tÃ¡c nhÃ¢n chatbot trÃªn thiáº¿t bá»‹ di Ä‘á»™ng, giÃºp chatbot Ä‘Æ°a ra cÃ¡c gá»£i Ã½ sá»­ dá»¥ng cÃ´ng cá»¥ (vÃ­ dá»¥: tÃ¬m kiáº¿m thÃ´ng tin, lÃªn lá»‹ch) chÃ­nh xÃ¡c vÃ  hiá»‡u quáº£ hÆ¡n, trÃ¡nh cÃ¡c bÆ°á»›c khÃ´ng cáº§n thiáº¿t.
3. CÃ´ng nghá»‡ pháº§n má»m cho thiáº¿t bá»‹ di Ä‘á»™ng cho phÃ©p cÃ¡c á»©ng dá»¥ng tÃ­ch há»£p cÃ´ng cá»¥ há»c há»i vÃ  Ä‘iá»u chá»‰nh hÃ nh vi sá»­ dá»¥ng tÃ i nguyÃªn (CPU, máº¡ng) cá»§a chÃºng dá»±a trÃªn pháº£n há»“i cá»§a ngÆ°á»i dÃ¹ng vÃ  hiá»‡u suáº¥t thá»±c táº¿, Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a bá»Ÿi khung ET-Agent.

### CÃ¡c Ä‘Æ°á»ng dáº«n liÃªn quan

| Ná»n táº£ng | ÄÆ°á»ng dáº«n |
| :--- | :--- |
| Hugging Face | [https://huggingface.co/papers/2601.06860](https://huggingface.co/papers/2601.06860) |
| ArXiv Abstract | [https://arxiv.org/abs/2601.06860](https://arxiv.org/abs/2601.06860) |
| PDF Download | [https://arxiv.org/pdf/2601.06860.pdf](https://arxiv.org/pdf/2601.06860.pdf) |
| Github Repository | N/A |

